{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2548e321-a145-4cea-8e91-0dfc552501a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import glob\n",
    "import scipy\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (10, 8)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a963c5-32a1-4bea-b7db-8659330e557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.size'] = 9\n",
    "cm = 1/2.54\n",
    "fig_folder = './Figure_3_exports'\n",
    "data_folder = './Figure_3_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f84d9d-148b-4ed4-b90c-0cf15df128a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Neural network training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c760a75-f361-49d1-b0f5-39d245e03c21",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5af02455-531e-4211-adaf-1dcf1900293a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>day</th>\n",
       "      <th>plate</th>\n",
       "      <th>well_name</th>\n",
       "      <th>Supp</th>\n",
       "      <th>DNA_name</th>\n",
       "      <th>DNA_conc</th>\n",
       "      <th>Liposome_name</th>\n",
       "      <th>Liposome_conc</th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>WCE</th>\n",
       "      <th>PEG</th>\n",
       "      <th>pmol</th>\n",
       "      <th>rxn_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>H12</td>\n",
       "      <td>S22</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>5.000</td>\n",
       "      <td>DMPC</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.918</td>\n",
       "      <td>0.000</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>K12</td>\n",
       "      <td>S22</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>5.000</td>\n",
       "      <td>DMPC</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.311</td>\n",
       "      <td>0.000</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>M5</td>\n",
       "      <td>S22</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>5.000</td>\n",
       "      <td>DMPC</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.644</td>\n",
       "      <td>0.000</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>J2</td>\n",
       "      <td>S22</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>5.000</td>\n",
       "      <td>DMPC</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>7.546</td>\n",
       "      <td>0.000</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>N22</td>\n",
       "      <td>S22</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>5.000</td>\n",
       "      <td>DMPC</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>7.527</td>\n",
       "      <td>0.000</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33542</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>A1</td>\n",
       "      <td>S22</td>\n",
       "      <td>Vol</td>\n",
       "      <td>5.000</td>\n",
       "      <td>no_lipo</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.149</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33543</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>B2</td>\n",
       "      <td>S22</td>\n",
       "      <td>Vol</td>\n",
       "      <td>5.000</td>\n",
       "      <td>no_lipo</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.265</td>\n",
       "      <td>3862.000</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33544</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>B2</td>\n",
       "      <td>S22</td>\n",
       "      <td>Vol</td>\n",
       "      <td>5.000</td>\n",
       "      <td>no_lipo</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.265</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33545</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S22</td>\n",
       "      <td>Vol</td>\n",
       "      <td>5.000</td>\n",
       "      <td>no_lipo</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.024</td>\n",
       "      <td>3862.000</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33546</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S22</td>\n",
       "      <td>Vol</td>\n",
       "      <td>5.000</td>\n",
       "      <td>no_lipo</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.024</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11197 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      experiment_id   day  plate well_name Supp DNA_name  DNA_conc  \\\n",
       "0            eCM313 1.000  1.000       H12  S22     AqpZ     5.000   \n",
       "1            eCM313 1.000  1.000       K12  S22     AqpZ     5.000   \n",
       "2            eCM313 1.000  1.000        M5  S22     AqpZ     5.000   \n",
       "3            eCM313 2.000  4.000        J2  S22     AqpZ     5.000   \n",
       "4            eCM313 2.000  4.000       N22  S22     AqpZ     5.000   \n",
       "...             ...   ...    ...       ...  ...      ...       ...   \n",
       "33542        eCM313 2.000  3.000        A1  S22      Vol     5.000   \n",
       "33543        eCM313 2.000  4.000        B2  S22      Vol     5.000   \n",
       "33544        eCM313 2.000  4.000        B2  S22      Vol     5.000   \n",
       "33545        eCM313 2.000  4.000        G6  S22      Vol     5.000   \n",
       "33546        eCM313 2.000  4.000        G6  S22      Vol     5.000   \n",
       "\n",
       "      Liposome_name  Liposome_conc     Mg  SecYE    K   WCE   PEG  pmol  \\\n",
       "0              DMPC              3  8.000  0.000   85  BL62 2.000 4.918   \n",
       "1              DMPC              3  8.000  0.000   85  BL62 2.000 4.311   \n",
       "2              DMPC              3  8.000  0.000   85  BL62 2.000 2.644   \n",
       "3              DMPC              3  8.000  0.000   85  BL62 2.000 7.546   \n",
       "4              DMPC              3  8.000  0.000   85  BL62 2.000 7.527   \n",
       "...             ...            ...    ...    ...  ...   ...   ...   ...   \n",
       "33542       no_lipo              0 20.000  1.250  135  BL62 2.000 1.149   \n",
       "33543       no_lipo              0 20.000  1.250  135  BL62 2.000 1.265   \n",
       "33544       no_lipo              0 20.000  1.250  135  BL62 2.000 1.265   \n",
       "33545       no_lipo              0 20.000  1.250  135  BL62 2.000 2.024   \n",
       "33546       no_lipo              0 20.000  1.250  135  BL62 2.000 2.024   \n",
       "\n",
       "        rxn_id   label  \n",
       "0        0.000  screen  \n",
       "1        0.000  screen  \n",
       "2        0.000  screen  \n",
       "3        0.000  screen  \n",
       "4        0.000  screen  \n",
       "...        ...     ...  \n",
       "33542 3966.000  screen  \n",
       "33543 3862.000  screen  \n",
       "33544 3966.000  screen  \n",
       "33545 3862.000  screen  \n",
       "33546 3966.000  screen  \n",
       "\n",
       "[11197 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('../General_data/screen_active_data.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06fe1a7-42c1-4a9a-ac1c-c0c0a245b517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment_id\n",
       "eCM331    2865\n",
       "eCM316    2303\n",
       "eCM313    1721\n",
       "eCM336    1693\n",
       "eCM314    1376\n",
       "eCM317    1239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.value_counts('experiment_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c418325-44e4-42f7-956f-10e95649e150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>day</th>\n",
       "      <th>plate</th>\n",
       "      <th>well_name</th>\n",
       "      <th>Supp</th>\n",
       "      <th>DNA_name</th>\n",
       "      <th>DNA_conc</th>\n",
       "      <th>Liposome_name</th>\n",
       "      <th>Liposome_conc</th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>WCE</th>\n",
       "      <th>PEG</th>\n",
       "      <th>pmol</th>\n",
       "      <th>rxn_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pmol_sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>H12</td>\n",
       "      <td>S22</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>5.000</td>\n",
       "      <td>DMPC</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.918</td>\n",
       "      <td>0.000</td>\n",
       "      <td>screen</td>\n",
       "      <td>2.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>K12</td>\n",
       "      <td>S22</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>5.000</td>\n",
       "      <td>DMPC</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.311</td>\n",
       "      <td>0.000</td>\n",
       "      <td>screen</td>\n",
       "      <td>2.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>M5</td>\n",
       "      <td>S22</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>5.000</td>\n",
       "      <td>DMPC</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.644</td>\n",
       "      <td>0.000</td>\n",
       "      <td>screen</td>\n",
       "      <td>0.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>J2</td>\n",
       "      <td>S22</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>5.000</td>\n",
       "      <td>DMPC</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>7.546</td>\n",
       "      <td>0.000</td>\n",
       "      <td>screen</td>\n",
       "      <td>5.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>N22</td>\n",
       "      <td>S22</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>5.000</td>\n",
       "      <td>DMPC</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>7.527</td>\n",
       "      <td>0.000</td>\n",
       "      <td>screen</td>\n",
       "      <td>5.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33538</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>C22</td>\n",
       "      <td>S22</td>\n",
       "      <td>Vol</td>\n",
       "      <td>5.000</td>\n",
       "      <td>no_lipo</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.915</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>screen</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33540</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>N11</td>\n",
       "      <td>S22</td>\n",
       "      <td>Vol</td>\n",
       "      <td>5.000</td>\n",
       "      <td>no_lipo</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.529</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>screen</td>\n",
       "      <td>-0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33542</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>A1</td>\n",
       "      <td>S22</td>\n",
       "      <td>Vol</td>\n",
       "      <td>5.000</td>\n",
       "      <td>no_lipo</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.149</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>screen</td>\n",
       "      <td>-0.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33544</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>B2</td>\n",
       "      <td>S22</td>\n",
       "      <td>Vol</td>\n",
       "      <td>5.000</td>\n",
       "      <td>no_lipo</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.265</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>screen</td>\n",
       "      <td>-0.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33546</th>\n",
       "      <td>eCM313</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S22</td>\n",
       "      <td>Vol</td>\n",
       "      <td>5.000</td>\n",
       "      <td>no_lipo</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>BL62</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.024</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>screen</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11197 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      experiment_id   day  plate well_name Supp DNA_name  DNA_conc  \\\n",
       "0            eCM313 1.000  1.000       H12  S22     AqpZ     5.000   \n",
       "1            eCM313 1.000  1.000       K12  S22     AqpZ     5.000   \n",
       "2            eCM313 1.000  1.000        M5  S22     AqpZ     5.000   \n",
       "3            eCM313 2.000  4.000        J2  S22     AqpZ     5.000   \n",
       "4            eCM313 2.000  4.000       N22  S22     AqpZ     5.000   \n",
       "...             ...   ...    ...       ...  ...      ...       ...   \n",
       "33538        eCM313 1.000  2.000       C22  S22      Vol     5.000   \n",
       "33540        eCM313 1.000  2.000       N11  S22      Vol     5.000   \n",
       "33542        eCM313 2.000  3.000        A1  S22      Vol     5.000   \n",
       "33544        eCM313 2.000  4.000        B2  S22      Vol     5.000   \n",
       "33546        eCM313 2.000  4.000        G6  S22      Vol     5.000   \n",
       "\n",
       "      Liposome_name  Liposome_conc     Mg  SecYE    K   WCE   PEG  pmol  \\\n",
       "0              DMPC              3  8.000  0.000   85  BL62 2.000 4.918   \n",
       "1              DMPC              3  8.000  0.000   85  BL62 2.000 4.311   \n",
       "2              DMPC              3  8.000  0.000   85  BL62 2.000 2.644   \n",
       "3              DMPC              3  8.000  0.000   85  BL62 2.000 7.546   \n",
       "4              DMPC              3  8.000  0.000   85  BL62 2.000 7.527   \n",
       "...             ...            ...    ...    ...  ...   ...   ...   ...   \n",
       "33538       no_lipo              0 20.000  1.250  135  BL62 2.000 1.915   \n",
       "33540       no_lipo              0 20.000  1.250  135  BL62 2.000 1.529   \n",
       "33542       no_lipo              0 20.000  1.250  135  BL62 2.000 1.149   \n",
       "33544       no_lipo              0 20.000  1.250  135  BL62 2.000 1.265   \n",
       "33546       no_lipo              0 20.000  1.250  135  BL62 2.000 2.024   \n",
       "\n",
       "        rxn_id   label  pmol_sub  \n",
       "0        0.000  screen     2.688  \n",
       "1        0.000  screen     2.081  \n",
       "2        0.000  screen     0.414  \n",
       "3        0.000  screen     5.316  \n",
       "4        0.000  screen     5.297  \n",
       "...        ...     ...       ...  \n",
       "33538 3966.000  screen     0.238  \n",
       "33540 3966.000  screen    -0.148  \n",
       "33542 3966.000  screen    -0.529  \n",
       "33544 3966.000  screen    -0.413  \n",
       "33546 3966.000  screen     0.347  \n",
       "\n",
       "[11197 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = []\n",
    "\n",
    "for rxn_id,rxn_df in data.groupby('rxn_id'):\n",
    "    lipo = rxn_df[rxn_df['Liposome_conc'] != 0].copy()\n",
    "    nolipo = rxn_df[rxn_df['Liposome_conc'] == 0].copy()\n",
    "    nolipo_mean = np.mean(nolipo['pmol'])\n",
    "    if len(nolipo) == 0:\n",
    "        print(rxn_id)\n",
    "        continue\n",
    "    lipo['pmol_sub'] = lipo['pmol'] - nolipo_mean\n",
    "    nolipo['pmol_sub'] = nolipo['pmol'] - nolipo_mean\n",
    "    \n",
    "    sub_df.append(lipo)\n",
    "    sub_df.append(nolipo)\n",
    "    \n",
    "sub_df = pd.concat(sub_df)\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e2302-8c12-4307-a389-3a02fd0bbc20",
   "metadata": {},
   "source": [
    "### Organize all reaction variables and convert the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cead2a61-82eb-42bc-a1d4-8a4ccaccf0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rxn_id</th>\n",
       "      <th>DNA_name</th>\n",
       "      <th>lipid</th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>PEG</th>\n",
       "      <th>pmol</th>\n",
       "      <th>pmol_sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.918</td>\n",
       "      <td>2.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.311</td>\n",
       "      <td>2.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.644</td>\n",
       "      <td>0.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>7.546</td>\n",
       "      <td>5.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>7.527</td>\n",
       "      <td>5.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15746</th>\n",
       "      <td>3966.000</td>\n",
       "      <td>Vol</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.240</td>\n",
       "      <td>-0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15747</th>\n",
       "      <td>3966.000</td>\n",
       "      <td>Vol</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.230</td>\n",
       "      <td>-0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15748</th>\n",
       "      <td>3966.000</td>\n",
       "      <td>Vol</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.726</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15749</th>\n",
       "      <td>3966.000</td>\n",
       "      <td>Vol</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.145</td>\n",
       "      <td>-0.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15750</th>\n",
       "      <td>3966.000</td>\n",
       "      <td>Vol</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.972</td>\n",
       "      <td>-0.705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5506 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rxn_id DNA_name  lipid     Mg  SecYE    K   PEG  pmol  pmol_sub\n",
       "0        0.000     AqpZ     14  8.000  0.000   85 2.000 4.918     2.688\n",
       "1        0.000     AqpZ     14  8.000  0.000   85 2.000 4.311     2.081\n",
       "2        0.000     AqpZ     14  8.000  0.000   85 2.000 2.644     0.414\n",
       "3        0.000     AqpZ     14  8.000  0.000   85 2.000 7.546     5.316\n",
       "4        0.000     AqpZ     14  8.000  0.000   85 2.000 7.527     5.297\n",
       "...        ...      ...    ...    ...    ...  ...   ...   ...       ...\n",
       "15746 3966.000      Vol     18 20.000  1.250  135 2.000 1.240    -0.438\n",
       "15747 3966.000      Vol     18 20.000  1.250  135 2.000 1.230    -0.447\n",
       "15748 3966.000      Vol     18 20.000  1.250  135 2.000 1.726     0.048\n",
       "15749 3966.000      Vol     18 20.000  1.250  135 2.000 1.145    -0.532\n",
       "15750 3966.000      Vol     18 20.000  1.250  135 2.000 0.972    -0.705\n",
       "\n",
       "[5506 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = sub_df.copy()\n",
    "# training_data = training_data[training_data['label'] == 'screen'].copy()\n",
    "training_data = training_data[training_data['Liposome_name'] != 'no_lipo'].copy()\n",
    "\n",
    "\n",
    "lipo_dict = {'DOPC':18,'DPPC':16,'DMPC':14,'no_lipo':0}\n",
    "\n",
    "training_data['lipid'] = training_data['Liposome_name'].apply(lambda x: lipo_dict[x])\n",
    "training_data = training_data[['rxn_id','DNA_name','lipid','Mg','SecYE','K','PEG','pmol','pmol_sub']].copy()\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31786cf4-17af-493d-818e-dccd54a446a0",
   "metadata": {},
   "source": [
    "### Convert the protein names into unique columns for each protein using OneHot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13e003c2-276e-4f9f-aefb-32d966b56904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DNA_name', 'DNA_name-AqpZ', 'DNA_name-Aux', 'DNA_name-B2AR',\n",
       "       'DNA_name-B3AR', 'DNA_name-Beta', 'DNA_name-CD47', 'DNA_name-CD63',\n",
       "       'DNA_name-CD81', 'DNA_name-CD9', 'DNA_name-CML1', 'DNA_name-CRCM',\n",
       "       'DNA_name-CaM', 'DNA_name-Cx43', 'DNA_name-Dia', 'DNA_name-FFAR4',\n",
       "       'DNA_name-Glut', 'DNA_name-InP', 'DNA_name-Mito', 'DNA_name-Mol',\n",
       "       'DNA_name-MscL', 'DNA_name-MtlA', 'DNA_name-Neu', 'DNA_name-OR1A1',\n",
       "       'DNA_name-OR1D2', 'DNA_name-OR1E1', 'DNA_name-OR2AG1',\n",
       "       'DNA_name-SecYE-G', 'DNA_name-Vol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_one_hot(df,col_name):\n",
    "    temp = df[[col_name]]\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_encoder.fit(temp)\n",
    "\n",
    "    encoded = one_hot_encoder.transform(temp)\n",
    "    encoded = pd.DataFrame(data=encoded, columns=[col_name+'-'+c for c in one_hot_encoder.categories_])\n",
    "    df = df.join(encoded)\n",
    "    targets = list([col_name+'-'+c for c in one_hot_encoder.categories_])[0]\n",
    "    original = [(t,) for t in targets]\n",
    "    df = df.rename(columns=dict(zip(original,targets)))\n",
    "    return df\n",
    "\n",
    "\n",
    "prot_feat = training_data[['DNA_name']].drop_duplicates().reset_index(drop=True)\n",
    "dna_encoded = add_one_hot(prot_feat,'DNA_name')\n",
    "\n",
    "dna_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "322a9042-5e51-4be4-84e1-af260f4aa3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNA_name</th>\n",
       "      <th>rxn_id</th>\n",
       "      <th>lipid</th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>PEG</th>\n",
       "      <th>pmol</th>\n",
       "      <th>pmol_sub</th>\n",
       "      <th>DNA_name-AqpZ</th>\n",
       "      <th>...</th>\n",
       "      <th>DNA_name-Mol</th>\n",
       "      <th>DNA_name-MscL</th>\n",
       "      <th>DNA_name-MtlA</th>\n",
       "      <th>DNA_name-Neu</th>\n",
       "      <th>DNA_name-OR1A1</th>\n",
       "      <th>DNA_name-OR1D2</th>\n",
       "      <th>DNA_name-OR1E1</th>\n",
       "      <th>DNA_name-OR2AG1</th>\n",
       "      <th>DNA_name-SecYE-G</th>\n",
       "      <th>DNA_name-Vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AqpZ</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.918</td>\n",
       "      <td>2.688</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AqpZ</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.311</td>\n",
       "      <td>2.081</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AqpZ</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.644</td>\n",
       "      <td>0.414</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqpZ</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>7.546</td>\n",
       "      <td>5.316</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AqpZ</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>7.527</td>\n",
       "      <td>5.297</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5501</th>\n",
       "      <td>Vol</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.240</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5502</th>\n",
       "      <td>Vol</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.230</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5503</th>\n",
       "      <td>Vol</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.726</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5504</th>\n",
       "      <td>Vol</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.145</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>Vol</td>\n",
       "      <td>3966.000</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.972</td>\n",
       "      <td>-0.705</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5506 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DNA_name   rxn_id  lipid     Mg  SecYE    K   PEG  pmol  pmol_sub  \\\n",
       "0        AqpZ    0.000     14  8.000  0.000   85 2.000 4.918     2.688   \n",
       "1        AqpZ    0.000     14  8.000  0.000   85 2.000 4.311     2.081   \n",
       "2        AqpZ    0.000     14  8.000  0.000   85 2.000 2.644     0.414   \n",
       "3        AqpZ    0.000     14  8.000  0.000   85 2.000 7.546     5.316   \n",
       "4        AqpZ    0.000     14  8.000  0.000   85 2.000 7.527     5.297   \n",
       "...       ...      ...    ...    ...    ...  ...   ...   ...       ...   \n",
       "5501      Vol 3966.000     18 20.000  1.250  135 2.000 1.240    -0.438   \n",
       "5502      Vol 3966.000     18 20.000  1.250  135 2.000 1.230    -0.447   \n",
       "5503      Vol 3966.000     18 20.000  1.250  135 2.000 1.726     0.048   \n",
       "5504      Vol 3966.000     18 20.000  1.250  135 2.000 1.145    -0.532   \n",
       "5505      Vol 3966.000     18 20.000  1.250  135 2.000 0.972    -0.705   \n",
       "\n",
       "      DNA_name-AqpZ  ...  DNA_name-Mol  DNA_name-MscL  DNA_name-MtlA  \\\n",
       "0             1.000  ...         0.000          0.000          0.000   \n",
       "1             1.000  ...         0.000          0.000          0.000   \n",
       "2             1.000  ...         0.000          0.000          0.000   \n",
       "3             1.000  ...         0.000          0.000          0.000   \n",
       "4             1.000  ...         0.000          0.000          0.000   \n",
       "...             ...  ...           ...            ...            ...   \n",
       "5501          0.000  ...         0.000          0.000          0.000   \n",
       "5502          0.000  ...         0.000          0.000          0.000   \n",
       "5503          0.000  ...         0.000          0.000          0.000   \n",
       "5504          0.000  ...         0.000          0.000          0.000   \n",
       "5505          0.000  ...         0.000          0.000          0.000   \n",
       "\n",
       "      DNA_name-Neu  DNA_name-OR1A1  DNA_name-OR1D2  DNA_name-OR1E1  \\\n",
       "0            0.000           0.000           0.000           0.000   \n",
       "1            0.000           0.000           0.000           0.000   \n",
       "2            0.000           0.000           0.000           0.000   \n",
       "3            0.000           0.000           0.000           0.000   \n",
       "4            0.000           0.000           0.000           0.000   \n",
       "...            ...             ...             ...             ...   \n",
       "5501         0.000           0.000           0.000           0.000   \n",
       "5502         0.000           0.000           0.000           0.000   \n",
       "5503         0.000           0.000           0.000           0.000   \n",
       "5504         0.000           0.000           0.000           0.000   \n",
       "5505         0.000           0.000           0.000           0.000   \n",
       "\n",
       "      DNA_name-OR2AG1  DNA_name-SecYE-G  DNA_name-Vol  \n",
       "0               0.000             0.000         0.000  \n",
       "1               0.000             0.000         0.000  \n",
       "2               0.000             0.000         0.000  \n",
       "3               0.000             0.000         0.000  \n",
       "4               0.000             0.000         0.000  \n",
       "...               ...               ...           ...  \n",
       "5501            0.000             0.000         1.000  \n",
       "5502            0.000             0.000         1.000  \n",
       "5503            0.000             0.000         1.000  \n",
       "5504            0.000             0.000         1.000  \n",
       "5505            0.000             0.000         1.000  \n",
       "\n",
       "[5506 rows x 37 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = training_data.set_index('DNA_name').join(dna_encoded.set_index('DNA_name')).reset_index()\n",
    "all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7a16b8-eeae-49d2-9fad-5be765b64089",
   "metadata": {},
   "source": [
    "### Min-Max scaling reaction condition variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d0f4b0-aef5-4279-8cb2-2c1698e8416e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>PEG</th>\n",
       "      <th>lipid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rxn_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953.000</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954.000</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964.000</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3965.000</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966.000</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1251 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Mg  SecYE     K   PEG  lipid\n",
       "rxn_id                                  \n",
       "0.000    0.000  0.000 0.000 1.000  0.000\n",
       "1.000    0.000  0.000 0.000 0.000  0.000\n",
       "2.000    0.000  0.000 0.000 1.000  0.000\n",
       "3.000    0.000  0.000 0.500 1.000  0.000\n",
       "4.000    0.000  0.000 0.500 0.000  0.000\n",
       "...        ...    ...   ...   ...    ...\n",
       "3953.000 1.000  0.000 0.500 1.000  1.000\n",
       "3954.000 1.000  0.000 1.000 0.000  1.000\n",
       "3964.000 1.000  0.500 1.000 0.000  1.000\n",
       "3965.000 1.000  1.000 0.000 1.000  1.000\n",
       "3966.000 1.000  1.000 0.500 1.000  1.000\n",
       "\n",
       "[1251 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bounded = all_features[['Mg', 'SecYE', 'K', 'PEG','lipid']]\n",
    "X_bounded = np.array(data_bounded)\n",
    "MMscalerX = MinMaxScaler()\n",
    "X_bounded = MMscalerX.fit_transform(X_bounded)\n",
    "data_bounded = pd.DataFrame(X_bounded,columns=data_bounded.columns)\n",
    "data_bounded['rxn_id'] = all_features['rxn_id']\n",
    "data_bounded = data_bounded.drop_duplicates().set_index('rxn_id')\n",
    "data_bounded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ada91a-09eb-4b58-8f8d-d586b679d68f",
   "metadata": {},
   "source": [
    "### Standard Scaling\n",
    "* Calculates the z-scored values for each protein to capture the relative impact of reaction conditions on each protein rather than the overall yield of the protein.\n",
    "* Normalizes both the raw pmol value and the no liposome subtracted out pmol values\n",
    "* All final models, however, use the raw pmol values for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee125d8-afc9-4d8a-b704-ee269d3428ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rxn_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>-0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>-0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>-0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>-0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>-0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966.000</th>\n",
       "      <td>-0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966.000</th>\n",
       "      <td>-0.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966.000</th>\n",
       "      <td>-0.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966.000</th>\n",
       "      <td>-0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966.000</th>\n",
       "      <td>-0.910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5506 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label\n",
       "rxn_id         \n",
       "0.000    -0.570\n",
       "0.000    -0.656\n",
       "0.000    -0.891\n",
       "0.000    -0.201\n",
       "0.000    -0.203\n",
       "...         ...\n",
       "3966.000 -0.656\n",
       "3966.000 -0.665\n",
       "3966.000 -0.194\n",
       "3966.000 -0.745\n",
       "3966.000 -0.910\n",
       "\n",
       "[5506 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_col = 'pmol'\n",
    "\n",
    "transformed = []\n",
    "scaler_dict = {}\n",
    "\n",
    "for dna, dna_df in all_features.groupby('DNA_name'):\n",
    "    temp = dna_df.copy()\n",
    "    y_scaled = np.array(dna_df[[y_col]])\n",
    "    scalerY = StandardScaler()\n",
    "    y_scaled = scalerY.fit_transform(y_scaled)\n",
    "    temp['label'] = y_scaled\n",
    "    transformed.append(temp)\n",
    "    scaler_dict.update({dna:scalerY})\n",
    "transformed = pd.concat(transformed)\n",
    "transformed = transformed[['rxn_id','label']].set_index('rxn_id')\n",
    "transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52819e18-8745-412f-a024-677151888f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_sub</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rxn_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>-0.566</td>\n",
       "      <td>-0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>-0.666</td>\n",
       "      <td>-0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966.000</th>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966.000</th>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966.000</th>\n",
       "      <td>0.793</td>\n",
       "      <td>-0.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966.000</th>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966.000</th>\n",
       "      <td>-0.598</td>\n",
       "      <td>-0.910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5506 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label_sub  label\n",
       "rxn_id                    \n",
       "0.000        -0.566 -0.570\n",
       "0.000        -0.666 -0.656\n",
       "0.000        -0.941 -0.891\n",
       "0.000        -0.133 -0.201\n",
       "0.000        -0.136 -0.203\n",
       "...             ...    ...\n",
       "3966.000     -0.104 -0.656\n",
       "3966.000     -0.122 -0.665\n",
       "3966.000      0.793 -0.194\n",
       "3966.000     -0.279 -0.745\n",
       "3966.000     -0.598 -0.910\n",
       "\n",
       "[5506 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_col = 'pmol_sub'\n",
    "\n",
    "transformed_sub = []\n",
    "scaler_dict_sub = {}\n",
    "\n",
    "for dna, dna_df in all_features.groupby('DNA_name'):\n",
    "    temp = dna_df.copy()\n",
    "    y_scaled = np.array(dna_df[[y_col]])\n",
    "    scalerY = StandardScaler()\n",
    "    y_scaled = scalerY.fit_transform(y_scaled)\n",
    "    temp['label_sub'] = y_scaled\n",
    "    transformed_sub.append(temp)\n",
    "    scaler_dict_sub.update({dna:scalerY})\n",
    "transformed_sub = pd.concat(transformed_sub)\n",
    "transformed_sub = transformed_sub[['rxn_id','label_sub']].set_index('rxn_id')\n",
    "transformed_sub['label'] = transformed['label']\n",
    "transformed_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e6fcca-2fb2-4abf-aa11-d5a7c03b2066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNA_name-AqpZ</th>\n",
       "      <th>DNA_name-Aux</th>\n",
       "      <th>DNA_name-B2AR</th>\n",
       "      <th>DNA_name-B3AR</th>\n",
       "      <th>DNA_name-Beta</th>\n",
       "      <th>DNA_name-CD47</th>\n",
       "      <th>DNA_name-CD63</th>\n",
       "      <th>DNA_name-CD81</th>\n",
       "      <th>DNA_name-CD9</th>\n",
       "      <th>DNA_name-CML1</th>\n",
       "      <th>...</th>\n",
       "      <th>DNA_name-MscL</th>\n",
       "      <th>DNA_name-MtlA</th>\n",
       "      <th>DNA_name-Neu</th>\n",
       "      <th>DNA_name-OR1A1</th>\n",
       "      <th>DNA_name-OR1D2</th>\n",
       "      <th>DNA_name-OR1E1</th>\n",
       "      <th>DNA_name-OR2AG1</th>\n",
       "      <th>DNA_name-SecYE-G</th>\n",
       "      <th>DNA_name-Vol</th>\n",
       "      <th>DNA_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rxn_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.000</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.000</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.000</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953.000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Vol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954.000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Vol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964.000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Vol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3965.000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Vol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966.000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Vol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1251 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DNA_name-AqpZ  DNA_name-Aux  DNA_name-B2AR  DNA_name-B3AR  \\\n",
       "rxn_id                                                                \n",
       "0.000             1.000         0.000          0.000          0.000   \n",
       "1.000             1.000         0.000          0.000          0.000   \n",
       "2.000             1.000         0.000          0.000          0.000   \n",
       "3.000             1.000         0.000          0.000          0.000   \n",
       "4.000             1.000         0.000          0.000          0.000   \n",
       "...                 ...           ...            ...            ...   \n",
       "3953.000          0.000         0.000          0.000          0.000   \n",
       "3954.000          0.000         0.000          0.000          0.000   \n",
       "3964.000          0.000         0.000          0.000          0.000   \n",
       "3965.000          0.000         0.000          0.000          0.000   \n",
       "3966.000          0.000         0.000          0.000          0.000   \n",
       "\n",
       "          DNA_name-Beta  DNA_name-CD47  DNA_name-CD63  DNA_name-CD81  \\\n",
       "rxn_id                                                                 \n",
       "0.000             0.000          0.000          0.000          0.000   \n",
       "1.000             0.000          0.000          0.000          0.000   \n",
       "2.000             0.000          0.000          0.000          0.000   \n",
       "3.000             0.000          0.000          0.000          0.000   \n",
       "4.000             0.000          0.000          0.000          0.000   \n",
       "...                 ...            ...            ...            ...   \n",
       "3953.000          0.000          0.000          0.000          0.000   \n",
       "3954.000          0.000          0.000          0.000          0.000   \n",
       "3964.000          0.000          0.000          0.000          0.000   \n",
       "3965.000          0.000          0.000          0.000          0.000   \n",
       "3966.000          0.000          0.000          0.000          0.000   \n",
       "\n",
       "          DNA_name-CD9  DNA_name-CML1  ...  DNA_name-MscL  DNA_name-MtlA  \\\n",
       "rxn_id                                 ...                                 \n",
       "0.000            0.000          0.000  ...          0.000          0.000   \n",
       "1.000            0.000          0.000  ...          0.000          0.000   \n",
       "2.000            0.000          0.000  ...          0.000          0.000   \n",
       "3.000            0.000          0.000  ...          0.000          0.000   \n",
       "4.000            0.000          0.000  ...          0.000          0.000   \n",
       "...                ...            ...  ...            ...            ...   \n",
       "3953.000         0.000          0.000  ...          0.000          0.000   \n",
       "3954.000         0.000          0.000  ...          0.000          0.000   \n",
       "3964.000         0.000          0.000  ...          0.000          0.000   \n",
       "3965.000         0.000          0.000  ...          0.000          0.000   \n",
       "3966.000         0.000          0.000  ...          0.000          0.000   \n",
       "\n",
       "          DNA_name-Neu  DNA_name-OR1A1  DNA_name-OR1D2  DNA_name-OR1E1  \\\n",
       "rxn_id                                                                   \n",
       "0.000            0.000           0.000           0.000           0.000   \n",
       "1.000            0.000           0.000           0.000           0.000   \n",
       "2.000            0.000           0.000           0.000           0.000   \n",
       "3.000            0.000           0.000           0.000           0.000   \n",
       "4.000            0.000           0.000           0.000           0.000   \n",
       "...                ...             ...             ...             ...   \n",
       "3953.000         0.000           0.000           0.000           0.000   \n",
       "3954.000         0.000           0.000           0.000           0.000   \n",
       "3964.000         0.000           0.000           0.000           0.000   \n",
       "3965.000         0.000           0.000           0.000           0.000   \n",
       "3966.000         0.000           0.000           0.000           0.000   \n",
       "\n",
       "          DNA_name-OR2AG1  DNA_name-SecYE-G  DNA_name-Vol  DNA_name  \n",
       "rxn_id                                                               \n",
       "0.000               0.000             0.000         0.000      AqpZ  \n",
       "1.000               0.000             0.000         0.000      AqpZ  \n",
       "2.000               0.000             0.000         0.000      AqpZ  \n",
       "3.000               0.000             0.000         0.000      AqpZ  \n",
       "4.000               0.000             0.000         0.000      AqpZ  \n",
       "...                   ...               ...           ...       ...  \n",
       "3953.000            0.000             0.000         1.000       Vol  \n",
       "3954.000            0.000             0.000         1.000       Vol  \n",
       "3964.000            0.000             0.000         1.000       Vol  \n",
       "3965.000            0.000             0.000         1.000       Vol  \n",
       "3966.000            0.000             0.000         1.000       Vol  \n",
       "\n",
       "[1251 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_cols = [c for c in all_features.columns if '-' in c]\n",
    "encoded_cols = all_features[encoded_cols+['rxn_id','DNA_name']].drop_duplicates().set_index('rxn_id')\n",
    "encoded_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d38cadc-c989-4118-aec2-4263ad3b905e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rxn_id</th>\n",
       "      <th>label_sub</th>\n",
       "      <th>label</th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>PEG</th>\n",
       "      <th>lipid</th>\n",
       "      <th>DNA_name-AqpZ</th>\n",
       "      <th>DNA_name-Aux</th>\n",
       "      <th>...</th>\n",
       "      <th>DNA_name-MscL</th>\n",
       "      <th>DNA_name-MtlA</th>\n",
       "      <th>DNA_name-Neu</th>\n",
       "      <th>DNA_name-OR1A1</th>\n",
       "      <th>DNA_name-OR1D2</th>\n",
       "      <th>DNA_name-OR1E1</th>\n",
       "      <th>DNA_name-OR2AG1</th>\n",
       "      <th>DNA_name-SecYE-G</th>\n",
       "      <th>DNA_name-Vol</th>\n",
       "      <th>DNA_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>-0.570</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-0.656</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5501</th>\n",
       "      <td>3966.000</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.656</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Vol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5502</th>\n",
       "      <td>3966.000</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Vol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5503</th>\n",
       "      <td>3966.000</td>\n",
       "      <td>0.793</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Vol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5504</th>\n",
       "      <td>3966.000</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Vol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>3966.000</td>\n",
       "      <td>-0.598</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Vol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5506 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rxn_id  label_sub  label    Mg  SecYE     K   PEG  lipid  \\\n",
       "0       0.000     -0.566 -0.570 0.000  0.000 0.000 1.000  0.000   \n",
       "1       0.000     -0.666 -0.656 0.000  0.000 0.000 1.000  0.000   \n",
       "2       0.000     -0.941 -0.891 0.000  0.000 0.000 1.000  0.000   \n",
       "3       0.000     -0.133 -0.201 0.000  0.000 0.000 1.000  0.000   \n",
       "4       0.000     -0.136 -0.203 0.000  0.000 0.000 1.000  0.000   \n",
       "...       ...        ...    ...   ...    ...   ...   ...    ...   \n",
       "5501 3966.000     -0.104 -0.656 1.000  1.000 0.500 1.000  1.000   \n",
       "5502 3966.000     -0.122 -0.665 1.000  1.000 0.500 1.000  1.000   \n",
       "5503 3966.000      0.793 -0.194 1.000  1.000 0.500 1.000  1.000   \n",
       "5504 3966.000     -0.279 -0.745 1.000  1.000 0.500 1.000  1.000   \n",
       "5505 3966.000     -0.598 -0.910 1.000  1.000 0.500 1.000  1.000   \n",
       "\n",
       "      DNA_name-AqpZ  DNA_name-Aux  ...  DNA_name-MscL  DNA_name-MtlA  \\\n",
       "0             1.000         0.000  ...          0.000          0.000   \n",
       "1             1.000         0.000  ...          0.000          0.000   \n",
       "2             1.000         0.000  ...          0.000          0.000   \n",
       "3             1.000         0.000  ...          0.000          0.000   \n",
       "4             1.000         0.000  ...          0.000          0.000   \n",
       "...             ...           ...  ...            ...            ...   \n",
       "5501          0.000         0.000  ...          0.000          0.000   \n",
       "5502          0.000         0.000  ...          0.000          0.000   \n",
       "5503          0.000         0.000  ...          0.000          0.000   \n",
       "5504          0.000         0.000  ...          0.000          0.000   \n",
       "5505          0.000         0.000  ...          0.000          0.000   \n",
       "\n",
       "      DNA_name-Neu  DNA_name-OR1A1  DNA_name-OR1D2  DNA_name-OR1E1  \\\n",
       "0            0.000           0.000           0.000           0.000   \n",
       "1            0.000           0.000           0.000           0.000   \n",
       "2            0.000           0.000           0.000           0.000   \n",
       "3            0.000           0.000           0.000           0.000   \n",
       "4            0.000           0.000           0.000           0.000   \n",
       "...            ...             ...             ...             ...   \n",
       "5501         0.000           0.000           0.000           0.000   \n",
       "5502         0.000           0.000           0.000           0.000   \n",
       "5503         0.000           0.000           0.000           0.000   \n",
       "5504         0.000           0.000           0.000           0.000   \n",
       "5505         0.000           0.000           0.000           0.000   \n",
       "\n",
       "      DNA_name-OR2AG1  DNA_name-SecYE-G  DNA_name-Vol  DNA_name  \n",
       "0               0.000             0.000         0.000      AqpZ  \n",
       "1               0.000             0.000         0.000      AqpZ  \n",
       "2               0.000             0.000         0.000      AqpZ  \n",
       "3               0.000             0.000         0.000      AqpZ  \n",
       "4               0.000             0.000         0.000      AqpZ  \n",
       "...               ...               ...           ...       ...  \n",
       "5501            0.000             0.000         1.000       Vol  \n",
       "5502            0.000             0.000         1.000       Vol  \n",
       "5503            0.000             0.000         1.000       Vol  \n",
       "5504            0.000             0.000         1.000       Vol  \n",
       "5505            0.000             0.000         1.000       Vol  \n",
       "\n",
       "[5506 rows x 37 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_data = transformed_sub.join(data_bounded).join(encoded_cols).reset_index()\n",
    "norm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61958fc2-866c-4c13-9190-9bf53ff23834",
   "metadata": {},
   "source": [
    "### Design feature sets for ensembles\n",
    "* Here is where the features included in the input layer of the neural network are set. \n",
    "* Any modification to the inputs are defined as new ensembles and all the column names for the included data need to be combined as a single list\n",
    "* This could include protein metadata like their length, organism of origin, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5629b50-81ae-44d8-9e92-66d026aa26e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn_features = ['Mg','SecYE','K','PEG','lipid']\n",
    "dna_features = [c for c in norm_data.columns if 'DNA_name-' in c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58aa6daf-9751-4a36-9d2d-b8352ed5d199",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_dict = {\n",
    "    'dna_encoded':rxn_features+dna_features,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae040dd5-82dc-4f80-86cd-c20dc905c785",
   "metadata": {},
   "source": [
    "### Specification of the model architecture\n",
    "* The neural network implemented here is a simple sequential neural network\n",
    "* The input layer is dynamically generated to match the input data\n",
    "* The other layers are Densely connected layers which are defined by a number of node and an activation function\n",
    "* The make_model function takes in a list of nodes that will be used to define all the hidden layers\n",
    "* All models have a single node output layer that uses a linear activation function\n",
    "* All models also use Adam optimization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d75c9bf1-f9b2-4421-afb0-3b0ae15fd3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=1e-3,nodes=[256,128,64,32,16],loss='mean_absolute_error'):\n",
    "    temp = [tf.keras.layers.Dense(n, activation='relu') for n in nodes] + [tf.keras.layers.Dense(1, activation=\"linear\")]\n",
    "    model = tf.keras.Sequential([*temp])\n",
    "    \n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "    return model\n",
    "\n",
    "def prep_data(train,test,target='label'):\n",
    "    to_drop = 'rxn_id'\n",
    "    train = train.drop(columns=to_drop)\n",
    "    test = test.drop(columns=to_drop)\n",
    "    \n",
    "    cols = [col for col in train.columns.values if col not in ['label','label_sub']]\n",
    "    print('Current target label:',target)\n",
    "    X_train = np.array(train[cols])\n",
    "    y_train = train[target].values.reshape(-1, 1)\n",
    "\n",
    "    X_test = np.array(test[cols])\n",
    "    y_test = test[target].values.reshape(-1, 1)\n",
    "    \n",
    "    return train,test,X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b734c230-477d-4ff7-baf0-2f52a00ea73e",
   "metadata": {},
   "source": [
    "### Defines the parameters to change in each model of the ensemble\n",
    "* Specifies the number of hidden layers and the number of nodes in each layer\n",
    "* Defines the learning rate and batch sizes\n",
    "* Whether to use the raw pmol value (label) or the subtracted pmol value (label_sub)\n",
    "* Defines the loss metric\n",
    "* Defines the number of ways to split the data (folds)\n",
    "    * The folds are designed so that the every reaction composition ends up in only one test set\n",
    "    * If the number of folds is set to 5 then the algorithm will generate 5x 80:20 train:test data splits\n",
    "    * The test and training data keeps all replicate reactions within the same set\n",
    "* The algorithm then makes all combinations of these variables to make a new dataframe to coordinate the training of all models in each ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "119bbe10-6281-4807-b8b2-5e4e6f9b57f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>model_id</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>loss</th>\n",
       "      <th>label_type</th>\n",
       "      <th>batch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>nodes</th>\n",
       "      <th>cols</th>\n",
       "      <th>test_ids</th>\n",
       "      <th>train_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...</td>\n",
       "      <td>[2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...</td>\n",
       "      <td>[2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...</td>\n",
       "      <td>[2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...</td>\n",
       "      <td>[2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...</td>\n",
       "      <td>[2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...</td>\n",
       "      <td>[1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...</td>\n",
       "      <td>[1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...</td>\n",
       "      <td>[1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...</td>\n",
       "      <td>[1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...</td>\n",
       "      <td>[1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold  model_id     ensemble                loss label_type  batch  \\\n",
       "0      0         0  dna_encoded  mean_squared_error  label_sub     10   \n",
       "1      0         1  dna_encoded  mean_squared_error  label_sub     10   \n",
       "2      0         2  dna_encoded  mean_squared_error  label_sub     10   \n",
       "3      0         3  dna_encoded  mean_squared_error  label_sub     50   \n",
       "4      0         4  dna_encoded  mean_squared_error  label_sub     50   \n",
       "..   ...       ...          ...                 ...        ...    ...   \n",
       "40     4        40  dna_encoded  mean_squared_error  label_sub     50   \n",
       "41     4        41  dna_encoded  mean_squared_error  label_sub     50   \n",
       "42     4        42  dna_encoded  mean_squared_error  label_sub    200   \n",
       "43     4        43  dna_encoded  mean_squared_error  label_sub    200   \n",
       "44     4        44  dna_encoded  mean_squared_error  label_sub    200   \n",
       "\n",
       "    learning_rate                        nodes  \\\n",
       "0           0.001            [128, 64, 32, 16]   \n",
       "1           0.001       [256, 128, 64, 32, 16]   \n",
       "2           0.001  [512, 256, 128, 64, 32, 16]   \n",
       "3           0.001            [128, 64, 32, 16]   \n",
       "4           0.001       [256, 128, 64, 32, 16]   \n",
       "..            ...                          ...   \n",
       "40          0.001       [256, 128, 64, 32, 16]   \n",
       "41          0.001  [512, 256, 128, 64, 32, 16]   \n",
       "42          0.001            [128, 64, 32, 16]   \n",
       "43          0.001       [256, 128, 64, 32, 16]   \n",
       "44          0.001  [512, 256, 128, 64, 32, 16]   \n",
       "\n",
       "                                                 cols  \\\n",
       "0   [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "1   [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "2   [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "3   [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "4   [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "..                                                ...   \n",
       "40  [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "41  [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "42  [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "43  [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "44  [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "\n",
       "                                             test_ids  \\\n",
       "0   [1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...   \n",
       "1   [1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...   \n",
       "2   [1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...   \n",
       "3   [1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...   \n",
       "4   [1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...   \n",
       "..                                                ...   \n",
       "40  [2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...   \n",
       "41  [2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...   \n",
       "42  [2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...   \n",
       "43  [2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...   \n",
       "44  [2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...   \n",
       "\n",
       "                                            train_ids  \n",
       "0   [2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....  \n",
       "1   [2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....  \n",
       "2   [2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....  \n",
       "3   [2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....  \n",
       "4   [2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....  \n",
       "..                                                ...  \n",
       "40  [1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...  \n",
       "41  [1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...  \n",
       "42  [1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...  \n",
       "43  [1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...  \n",
       "44  [1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...  \n",
       "\n",
       "[45 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "layer_arr = []\n",
    "num_layers = [4,5,6]\n",
    "\n",
    "nodes = [2**i for i in range(4,12)][::-1]\n",
    "start = 'low'\n",
    "for num in num_layers:\n",
    "    if start == 'high':\n",
    "        layers = [nodes[i] for i in range(num)]\n",
    "    elif start == 'low':\n",
    "        layers = [nodes[len(nodes)-i-1] for i in range(num)][::-1]\n",
    "    layer_arr.append(layers)\n",
    "\n",
    "learning_rates = [1e-3]\n",
    "batch_sizes = [10,50,200]\n",
    "\n",
    "ensemble = ['dna_encoded']\n",
    "# ensemble = ['no_prot_features']\n",
    "\n",
    "# loss_metrics = ['mean_absolute_error','mean_squared_error']\n",
    "loss_metrics = ['mean_squared_error']\n",
    "\n",
    "# label_names = ['label','label_sub']\n",
    "# label_names = ['label']\n",
    "label_names = ['label_sub']\n",
    "\n",
    "\n",
    "folds = range(5)\n",
    "\n",
    "combinations = list(itertools.product(ensemble,loss_metrics,label_names,folds,batch_sizes,learning_rates,layer_arr))\n",
    "combinations = pd.DataFrame(combinations,columns=['ensemble','loss','label_type','fold','batch','learning_rate','nodes']).reset_index().rename(columns={'index':'model_id'}).set_index('model_id')\n",
    "combinations = combinations.reset_index()\n",
    "combinations['cols'] = combinations['ensemble'].apply(lambda x: col_dict[x])\n",
    "combinations\n",
    "\n",
    "\n",
    "def partition (list_in, n,random_seed=0):\n",
    "    random.Random(random_seed).shuffle(list_in)\n",
    "    return [[i,list_in[i::n]] for i in range(n)]\n",
    "\n",
    "def get_train_ids(test_ids,available_ids):\n",
    "    return [i for i in available_ids if i not in test_ids]\n",
    "\n",
    "subset_ids = norm_data['rxn_id'].drop_duplicates().tolist()\n",
    "test_ids = partition(subset_ids,len(folds))\n",
    "test_ids = pd.DataFrame(test_ids,columns=['fold','test_ids'])\n",
    "test_ids['train_ids'] = test_ids['test_ids'].apply(get_train_ids,available_ids=subset_ids)\n",
    "    \n",
    "combinations = combinations.set_index('fold').join(test_ids.set_index('fold')).reset_index()\n",
    "\n",
    "combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb77a2c5-895c-40c3-9b6e-ae4124e53627",
   "metadata": {},
   "source": [
    "### Train all the models\n",
    "* Each iteration uses all the parameters specified by the row in the combinations dataframe\n",
    "* A directory is created to store all models created based on the defined combinations\n",
    "* Each complete training run is saved before the algorithm moves to the next model\n",
    "* The model specification is stored in the model_id_info file that is saved in the top level directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec7c502a-130d-4fdb-8efa-0e80d68dfce6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0:mean_squared_error-label_sub 0.0%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.7438 - val_loss: 0.6956\n",
      "Epoch 2/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.6389 - val_loss: 0.6712\n",
      "Epoch 3/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 0.6156 - val_loss: 0.6469\n",
      "Epoch 4/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 0.5884 - val_loss: 0.6520\n",
      "Epoch 5/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 0.5663 - val_loss: 0.6465\n",
      "Epoch 6/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.5579 - val_loss: 0.6744\n",
      "Epoch 7/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5580 - val_loss: 0.6545\n",
      "Epoch 8/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.5481 - val_loss: 0.6549\n",
      "Epoch 9/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.5419 - val_loss: 0.6520\n",
      "Epoch 10/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5051 - val_loss: 0.6761\n",
      "Epoch 11/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5254 - val_loss: 0.6517\n",
      "Epoch 12/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.5213 - val_loss: 0.6672\n",
      "Epoch 13/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5076 - val_loss: 0.6692\n",
      "Epoch 14/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 0.5134 - val_loss: 0.6741\n",
      "Epoch 15/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 0.5122 - val_loss: 0.7052\n",
      "Epoch 16/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.5021 - val_loss: 0.6608\n",
      "Epoch 17/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4866 - val_loss: 0.6794\n",
      "Epoch 18/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.5038 - val_loss: 0.6688\n",
      "Epoch 19/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.4905 - val_loss: 0.6671\n",
      "Epoch 20/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.4759 - val_loss: 0.6766\n",
      "Epoch 21/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.4760 - val_loss: 0.6750\n",
      "Epoch 22/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.4781 - val_loss: 0.6963\n",
      "Epoch 23/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.4806 - val_loss: 0.6888\n",
      "Epoch 24/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.4837 - val_loss: 0.6964\n",
      "Epoch 25/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.4818 - val_loss: 0.6812\n",
      "Epoch 26/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.4694 - val_loss: 0.6976\n",
      "Epoch 27/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.4562 - val_loss: 0.6760\n",
      "Epoch 28/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.4704 - val_loss: 0.6799\n",
      "Epoch 29/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.4639 - val_loss: 0.6900\n",
      "Epoch 30/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4679 - val_loss: 0.7048\n",
      "Epoch 31/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.4584 - val_loss: 0.6869\n",
      "Epoch 32/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.4633 - val_loss: 0.7037\n",
      "Epoch 33/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.4551 - val_loss: 0.6863\n",
      "Epoch 34/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.4623 - val_loss: 0.7000\n",
      "Epoch 35/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 0.4625 - val_loss: 0.6955\n",
      "Epoch 36/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.4511 - val_loss: 0.6858\n",
      "Epoch 37/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.4519 - val_loss: 0.7016\n",
      "Epoch 38/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.4679 - val_loss: 0.6891\n",
      "Epoch 39/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.4564 - val_loss: 0.6820\n",
      "Epoch 40/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.4533 - val_loss: 0.6962\n",
      "Epoch 41/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.4554 - val_loss: 0.6865\n",
      "Epoch 42/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.4385 - val_loss: 0.6952\n",
      "Epoch 43/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.4535 - val_loss: 0.6736\n",
      "Epoch 44/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.4419 - val_loss: 0.6945\n",
      "Epoch 45/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.4478 - val_loss: 0.7005\n",
      "Epoch 46/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.4328 - val_loss: 0.6795\n",
      "Epoch 47/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.4481 - val_loss: 0.7017\n",
      "Epoch 48/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 0.4461 - val_loss: 0.6854\n",
      "Epoch 49/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.4436 - val_loss: 0.7017\n",
      "Epoch 50/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 0.4550 - val_loss: 0.6880\n",
      "Epoch 51/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.4620 - val_loss: 0.7039\n",
      "Epoch 52/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.4571 - val_loss: 0.7023\n",
      "Epoch 53/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.4419 - val_loss: 0.6913\n",
      "Epoch 54/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4380 - val_loss: 0.6970\n",
      "Epoch 55/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.4318 - val_loss: 0.6977\n",
      "Epoch 56/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.4356 - val_loss: 0.6813\n",
      "Epoch 57/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.4363 - val_loss: 0.6941\n",
      "Epoch 58/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.4544 - val_loss: 0.6922\n",
      "Epoch 59/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.4327 - val_loss: 0.6821\n",
      "Epoch 60/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.4268 - val_loss: 0.6934\n",
      "Epoch 61/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.4434 - val_loss: 0.6850\n",
      "Epoch 62/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.4496 - val_loss: 0.6973\n",
      "Epoch 63/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.4328 - val_loss: 0.6898\n",
      "Epoch 64/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 0.4440 - val_loss: 0.6973\n",
      "Epoch 65/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.4446 - val_loss: 0.6962\n",
      "Epoch 66/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.4381 - val_loss: 0.6788\n",
      "Epoch 67/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.4309 - val_loss: 0.6941\n",
      "Epoch 68/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.4380 - val_loss: 0.7027\n",
      "Epoch 69/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.4410 - val_loss: 0.7105\n",
      "Epoch 70/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.4341 - val_loss: 0.6930\n",
      "Epoch 71/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.4308 - val_loss: 0.6925\n",
      "Epoch 72/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.4447 - val_loss: 0.6947\n",
      "Epoch 73/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.4186 - val_loss: 0.6947\n",
      "Epoch 74/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.4601 - val_loss: 0.6932\n",
      "Epoch 75/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.4355 - val_loss: 0.6964\n",
      "Epoch 76/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.4376 - val_loss: 0.6919\n",
      "Epoch 77/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.4409 - val_loss: 0.7007\n",
      "Epoch 78/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.4252 - val_loss: 0.7001\n",
      "Epoch 79/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.4381 - val_loss: 0.6926\n",
      "Epoch 80/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.4404 - val_loss: 0.7097\n",
      "Epoch 81/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.4458 - val_loss: 0.7113\n",
      "Epoch 82/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.4534 - val_loss: 0.7016\n",
      "Epoch 83/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.4374 - val_loss: 0.6974\n",
      "Epoch 84/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.4303 - val_loss: 0.7078\n",
      "Epoch 85/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.4336 - val_loss: 0.6995\n",
      "Epoch 86/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 0.4335 - val_loss: 0.6982\n",
      "Epoch 87/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 0.4314 - val_loss: 0.7090\n",
      "Epoch 88/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.4275 - val_loss: 0.6999\n",
      "Epoch 89/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.4265 - val_loss: 0.6958\n",
      "Epoch 90/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.4295 - val_loss: 0.7021\n",
      "Epoch 91/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 0.4388 - val_loss: 0.7034\n",
      "Epoch 92/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 0.4349 - val_loss: 0.7130\n",
      "Epoch 93/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.4403 - val_loss: 0.7165\n",
      "Epoch 94/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.4318 - val_loss: 0.6946\n",
      "Epoch 95/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.4248 - val_loss: 0.6943\n",
      "Epoch 96/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.4434 - val_loss: 0.7191\n",
      "Epoch 97/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.4330 - val_loss: 0.7149\n",
      "Epoch 98/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.4364 - val_loss: 0.6997\n",
      "Epoch 99/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.4331 - val_loss: 0.7047\n",
      "Epoch 100/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.4312 - val_loss: 0.7108\n",
      "current time:  2024-06-28_19-06\n",
      "\n",
      "\n",
      "1:mean_squared_error-label_sub 2.2%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.7198 - val_loss: 0.6932\n",
      "Epoch 2/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6357 - val_loss: 0.6692\n",
      "Epoch 3/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6207 - val_loss: 0.6740\n",
      "Epoch 4/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6096 - val_loss: 0.6467\n",
      "Epoch 5/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5742 - val_loss: 0.6519\n",
      "Epoch 6/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5674 - val_loss: 0.6826\n",
      "Epoch 7/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5427 - val_loss: 0.6452\n",
      "Epoch 8/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5378 - val_loss: 0.6501\n",
      "Epoch 9/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5247 - val_loss: 0.6777\n",
      "Epoch 10/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5200 - val_loss: 0.6595\n",
      "Epoch 11/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5247 - val_loss: 0.6659\n",
      "Epoch 12/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5141 - val_loss: 0.6664\n",
      "Epoch 13/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5024 - val_loss: 0.6788\n",
      "Epoch 14/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4908 - val_loss: 0.6838\n",
      "Epoch 15/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4908 - val_loss: 0.6765\n",
      "Epoch 16/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4894 - val_loss: 0.6819\n",
      "Epoch 17/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4840 - val_loss: 0.6964\n",
      "Epoch 18/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4768 - val_loss: 0.6711\n",
      "Epoch 19/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4740 - val_loss: 0.6783\n",
      "Epoch 20/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4775 - val_loss: 0.6928\n",
      "Epoch 21/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4566 - val_loss: 0.6841\n",
      "Epoch 22/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4623 - val_loss: 0.6902\n",
      "Epoch 23/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4742 - val_loss: 0.6772\n",
      "Epoch 24/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4701 - val_loss: 0.6805\n",
      "Epoch 25/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4696 - val_loss: 0.6801\n",
      "Epoch 26/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4620 - val_loss: 0.6986\n",
      "Epoch 27/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4601 - val_loss: 0.6885\n",
      "Epoch 28/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4432 - val_loss: 0.6877\n",
      "Epoch 29/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4528 - val_loss: 0.7307\n",
      "Epoch 30/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4649 - val_loss: 0.6784\n",
      "Epoch 31/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4489 - val_loss: 0.6838\n",
      "Epoch 32/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4563 - val_loss: 0.6733\n",
      "Epoch 33/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4511 - val_loss: 0.6863\n",
      "Epoch 34/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4488 - val_loss: 0.7033\n",
      "Epoch 35/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4350 - val_loss: 0.6783\n",
      "Epoch 36/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4477 - val_loss: 0.6977\n",
      "Epoch 37/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4495 - val_loss: 0.6883\n",
      "Epoch 38/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4381 - val_loss: 0.7004\n",
      "Epoch 39/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4368 - val_loss: 0.7070\n",
      "Epoch 40/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4611 - val_loss: 0.6850\n",
      "Epoch 41/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4483 - val_loss: 0.6942\n",
      "Epoch 42/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4309 - val_loss: 0.7184\n",
      "Epoch 43/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4387 - val_loss: 0.6932\n",
      "Epoch 44/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4365 - val_loss: 0.6905\n",
      "Epoch 45/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4370 - val_loss: 0.6933\n",
      "Epoch 46/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4277 - val_loss: 0.7022\n",
      "Epoch 47/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4356 - val_loss: 0.7119\n",
      "Epoch 48/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4459 - val_loss: 0.7159\n",
      "Epoch 49/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4534 - val_loss: 0.7194\n",
      "Epoch 50/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4453 - val_loss: 0.6941\n",
      "Epoch 51/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4386 - val_loss: 0.7065\n",
      "Epoch 52/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4255 - val_loss: 0.6965\n",
      "Epoch 53/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4417 - val_loss: 0.6969\n",
      "Epoch 54/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4191 - val_loss: 0.6899\n",
      "Epoch 55/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4225 - val_loss: 0.6814\n",
      "Epoch 56/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4199 - val_loss: 0.6871\n",
      "Epoch 57/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4300 - val_loss: 0.6944\n",
      "Epoch 58/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4331 - val_loss: 0.7097\n",
      "Epoch 59/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4263 - val_loss: 0.7113\n",
      "Epoch 60/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4302 - val_loss: 0.7084\n",
      "Epoch 61/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4141 - val_loss: 0.7243\n",
      "Epoch 62/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4297 - val_loss: 0.7117\n",
      "Epoch 63/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4260 - val_loss: 0.6974\n",
      "Epoch 64/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4279 - val_loss: 0.7081\n",
      "Epoch 65/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4332 - val_loss: 0.7029\n",
      "Epoch 66/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4314 - val_loss: 0.7150\n",
      "Epoch 67/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4308 - val_loss: 0.7138\n",
      "Epoch 68/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4255 - val_loss: 0.7097\n",
      "Epoch 69/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.4283 - val_loss: 0.7024\n",
      "Epoch 70/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4397 - val_loss: 0.6950\n",
      "Epoch 71/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4229 - val_loss: 0.6873\n",
      "Epoch 72/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4385 - val_loss: 0.7059\n",
      "Epoch 73/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.4324 - val_loss: 0.7023\n",
      "Epoch 74/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4261 - val_loss: 0.6876\n",
      "Epoch 75/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4250 - val_loss: 0.6935\n",
      "Epoch 76/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4357 - val_loss: 0.6920\n",
      "Epoch 77/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4286 - val_loss: 0.7005\n",
      "Epoch 78/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4367 - val_loss: 0.6952\n",
      "Epoch 79/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4222 - val_loss: 0.7186\n",
      "Epoch 80/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4214 - val_loss: 0.7060\n",
      "Epoch 81/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4277 - val_loss: 0.7157\n",
      "Epoch 82/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4277 - val_loss: 0.7134\n",
      "Epoch 83/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4372 - val_loss: 0.7072\n",
      "Epoch 84/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4259 - val_loss: 0.6949\n",
      "Epoch 85/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4325 - val_loss: 0.7233\n",
      "Epoch 86/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4225 - val_loss: 0.7191\n",
      "Epoch 87/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4198 - val_loss: 0.7127\n",
      "Epoch 88/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4214 - val_loss: 0.7018\n",
      "Epoch 89/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.4254 - val_loss: 0.7051\n",
      "Epoch 90/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.4164 - val_loss: 0.6940\n",
      "Epoch 91/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4179 - val_loss: 0.7164\n",
      "Epoch 92/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4194 - val_loss: 0.6986\n",
      "Epoch 93/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4217 - val_loss: 0.7044\n",
      "Epoch 94/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4222 - val_loss: 0.6853\n",
      "Epoch 95/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4249 - val_loss: 0.7147\n",
      "Epoch 96/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4258 - val_loss: 0.6990\n",
      "Epoch 97/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4286 - val_loss: 0.6994\n",
      "Epoch 98/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4227 - val_loss: 0.6973\n",
      "Epoch 99/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4280 - val_loss: 0.7163\n",
      "Epoch 100/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4178 - val_loss: 0.7194\n",
      "current time:  2024-06-28_19-07\n",
      "\n",
      "\n",
      "2:mean_squared_error-label_sub 4.4%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.7159 - val_loss: 0.6992\n",
      "Epoch 2/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6372 - val_loss: 0.6794\n",
      "Epoch 3/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6279 - val_loss: 0.6923\n",
      "Epoch 4/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6061 - val_loss: 0.6552\n",
      "Epoch 5/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5877 - val_loss: 0.6566\n",
      "Epoch 6/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5501 - val_loss: 0.6516\n",
      "Epoch 7/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5386 - val_loss: 0.6708\n",
      "Epoch 8/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5479 - val_loss: 0.6689\n",
      "Epoch 9/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5242 - val_loss: 0.6702\n",
      "Epoch 10/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5165 - val_loss: 0.6986\n",
      "Epoch 11/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5112 - val_loss: 0.7068\n",
      "Epoch 12/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4914 - val_loss: 0.6991\n",
      "Epoch 13/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5006 - val_loss: 0.6878\n",
      "Epoch 14/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4934 - val_loss: 0.6999\n",
      "Epoch 15/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4690 - val_loss: 0.7232\n",
      "Epoch 16/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4818 - val_loss: 0.6788\n",
      "Epoch 17/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4815 - val_loss: 0.7190\n",
      "Epoch 18/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4769 - val_loss: 0.7009\n",
      "Epoch 19/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4746 - val_loss: 0.7021\n",
      "Epoch 20/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4798 - val_loss: 0.6966\n",
      "Epoch 21/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4680 - val_loss: 0.7013\n",
      "Epoch 22/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4815 - val_loss: 0.7162\n",
      "Epoch 23/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4647 - val_loss: 0.6982\n",
      "Epoch 24/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4586 - val_loss: 0.6990\n",
      "Epoch 25/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4666 - val_loss: 0.7093\n",
      "Epoch 26/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4531 - val_loss: 0.7052\n",
      "Epoch 27/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4585 - val_loss: 0.7027\n",
      "Epoch 28/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4577 - val_loss: 0.7276\n",
      "Epoch 29/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4502 - val_loss: 0.7099\n",
      "Epoch 30/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4597 - val_loss: 0.6970\n",
      "Epoch 31/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4470 - val_loss: 0.7176\n",
      "Epoch 32/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4547 - val_loss: 0.7074\n",
      "Epoch 33/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4552 - val_loss: 0.7238\n",
      "Epoch 34/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4464 - val_loss: 0.7031\n",
      "Epoch 35/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4400 - val_loss: 0.7049\n",
      "Epoch 36/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4488 - val_loss: 0.7097\n",
      "Epoch 37/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4482 - val_loss: 0.7335\n",
      "Epoch 38/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4534 - val_loss: 0.7154\n",
      "Epoch 39/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4365 - val_loss: 0.7114\n",
      "Epoch 40/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4433 - val_loss: 0.7140\n",
      "Epoch 41/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4499 - val_loss: 0.7253\n",
      "Epoch 42/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4495 - val_loss: 0.7110\n",
      "Epoch 43/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4378 - val_loss: 0.6857\n",
      "Epoch 44/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4502 - val_loss: 0.7182\n",
      "Epoch 45/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4394 - val_loss: 0.7118\n",
      "Epoch 46/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4464 - val_loss: 0.7148\n",
      "Epoch 47/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4283 - val_loss: 0.7246\n",
      "Epoch 48/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4380 - val_loss: 0.7143\n",
      "Epoch 49/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4317 - val_loss: 0.7110\n",
      "Epoch 50/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4313 - val_loss: 0.7137\n",
      "Epoch 51/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4384 - val_loss: 0.6882\n",
      "Epoch 52/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4263 - val_loss: 0.7297\n",
      "Epoch 53/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4385 - val_loss: 0.7237\n",
      "Epoch 54/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4328 - val_loss: 0.7159\n",
      "Epoch 55/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4241 - val_loss: 0.7324\n",
      "Epoch 56/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4362 - val_loss: 0.7295\n",
      "Epoch 57/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4314 - val_loss: 0.7126\n",
      "Epoch 58/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4478 - val_loss: 0.6986\n",
      "Epoch 59/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4435 - val_loss: 0.7095\n",
      "Epoch 60/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4427 - val_loss: 0.7193\n",
      "Epoch 61/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4337 - val_loss: 0.7041\n",
      "Epoch 62/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4274 - val_loss: 0.7192\n",
      "Epoch 63/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4228 - val_loss: 0.7236\n",
      "Epoch 64/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4167 - val_loss: 0.7158\n",
      "Epoch 65/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4292 - val_loss: 0.7320\n",
      "Epoch 66/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4369 - val_loss: 0.7028\n",
      "Epoch 67/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4233 - val_loss: 0.7134\n",
      "Epoch 68/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4289 - val_loss: 0.7052\n",
      "Epoch 69/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4318 - val_loss: 0.7359\n",
      "Epoch 70/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4348 - val_loss: 0.7156\n",
      "Epoch 71/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4259 - val_loss: 0.7111\n",
      "Epoch 72/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4267 - val_loss: 0.7190\n",
      "Epoch 73/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4193 - val_loss: 0.7123\n",
      "Epoch 74/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4218 - val_loss: 0.7073\n",
      "Epoch 75/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4390 - val_loss: 0.6921\n",
      "Epoch 76/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4249 - val_loss: 0.7171\n",
      "Epoch 77/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4177 - val_loss: 0.6959\n",
      "Epoch 78/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4292 - val_loss: 0.7154\n",
      "Epoch 79/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4213 - val_loss: 0.7343\n",
      "Epoch 80/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4374 - val_loss: 0.7114\n",
      "Epoch 81/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4204 - val_loss: 0.6999\n",
      "Epoch 82/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4220 - val_loss: 0.7071\n",
      "Epoch 83/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4202 - val_loss: 0.7182\n",
      "Epoch 84/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4220 - val_loss: 0.7148\n",
      "Epoch 85/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4247 - val_loss: 0.7190\n",
      "Epoch 86/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4333 - val_loss: 0.7093\n",
      "Epoch 87/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4289 - val_loss: 0.6969\n",
      "Epoch 88/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4302 - val_loss: 0.7248\n",
      "Epoch 89/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4275 - val_loss: 0.6902\n",
      "Epoch 90/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4169 - val_loss: 0.7182\n",
      "Epoch 91/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4250 - val_loss: 0.7189\n",
      "Epoch 92/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4248 - val_loss: 0.7065\n",
      "Epoch 93/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4279 - val_loss: 0.7131\n",
      "Epoch 94/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4223 - val_loss: 0.7230\n",
      "Epoch 95/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4137 - val_loss: 0.7318\n",
      "Epoch 96/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4230 - val_loss: 0.7359\n",
      "Epoch 97/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4329 - val_loss: 0.7062\n",
      "Epoch 98/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4297 - val_loss: 0.7330\n",
      "Epoch 99/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4296 - val_loss: 0.7210\n",
      "Epoch 100/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4283 - val_loss: 0.7127\n",
      "current time:  2024-06-28_19-08\n",
      "\n",
      "\n",
      "3:mean_squared_error-label_sub 6.7%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7212 - val_loss: 0.7017\n",
      "Epoch 2/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6557 - val_loss: 0.6824\n",
      "Epoch 3/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6423 - val_loss: 0.6698\n",
      "Epoch 4/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6113 - val_loss: 0.6697\n",
      "Epoch 5/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5968 - val_loss: 0.6618\n",
      "Epoch 6/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5596 - val_loss: 0.6716\n",
      "Epoch 7/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5737 - val_loss: 0.6590\n",
      "Epoch 8/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5517 - val_loss: 0.6746\n",
      "Epoch 9/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5555 - val_loss: 0.6626\n",
      "Epoch 10/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5521 - val_loss: 0.6706\n",
      "Epoch 11/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5311 - val_loss: 0.6738\n",
      "Epoch 12/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5330 - val_loss: 0.6710\n",
      "Epoch 13/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5276 - val_loss: 0.6701\n",
      "Epoch 14/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5078 - val_loss: 0.6751\n",
      "Epoch 15/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5008 - val_loss: 0.6847\n",
      "Epoch 16/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5037 - val_loss: 0.6851\n",
      "Epoch 17/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5013 - val_loss: 0.6775\n",
      "Epoch 18/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4929 - val_loss: 0.6974\n",
      "Epoch 19/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4815 - val_loss: 0.6763\n",
      "Epoch 20/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4955 - val_loss: 0.6953\n",
      "Epoch 21/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4959 - val_loss: 0.6943\n",
      "Epoch 22/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4895 - val_loss: 0.7000\n",
      "Epoch 23/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4824 - val_loss: 0.6950\n",
      "Epoch 24/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4761 - val_loss: 0.6931\n",
      "Epoch 25/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4682 - val_loss: 0.7028\n",
      "Epoch 26/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4847 - val_loss: 0.7066\n",
      "Epoch 27/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4674 - val_loss: 0.7006\n",
      "Epoch 28/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4611 - val_loss: 0.7087\n",
      "Epoch 29/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4812 - val_loss: 0.7244\n",
      "Epoch 30/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4755 - val_loss: 0.7063\n",
      "Epoch 31/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4704 - val_loss: 0.6982\n",
      "Epoch 32/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4605 - val_loss: 0.7150\n",
      "Epoch 33/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4693 - val_loss: 0.6956\n",
      "Epoch 34/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4511 - val_loss: 0.7090\n",
      "Epoch 35/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4663 - val_loss: 0.7134\n",
      "Epoch 36/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4588 - val_loss: 0.7133\n",
      "Epoch 37/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4659 - val_loss: 0.7125\n",
      "Epoch 38/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4462 - val_loss: 0.7080\n",
      "Epoch 39/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4530 - val_loss: 0.7137\n",
      "Epoch 40/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4600 - val_loss: 0.7042\n",
      "Epoch 41/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4624 - val_loss: 0.7042\n",
      "Epoch 42/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4649 - val_loss: 0.7107\n",
      "Epoch 43/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4409 - val_loss: 0.7228\n",
      "Epoch 44/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4544 - val_loss: 0.7245\n",
      "Epoch 45/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4533 - val_loss: 0.7215\n",
      "Epoch 46/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4559 - val_loss: 0.7158\n",
      "Epoch 47/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4653 - val_loss: 0.7154\n",
      "Epoch 48/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4365 - val_loss: 0.7069\n",
      "Epoch 49/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4584 - val_loss: 0.7116\n",
      "Epoch 50/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4491 - val_loss: 0.7229\n",
      "Epoch 51/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4495 - val_loss: 0.7020\n",
      "Epoch 52/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4415 - val_loss: 0.7223\n",
      "Epoch 53/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4451 - val_loss: 0.7197\n",
      "Epoch 54/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4624 - val_loss: 0.7199\n",
      "Epoch 55/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4339 - val_loss: 0.7291\n",
      "Epoch 56/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4509 - val_loss: 0.7059\n",
      "Epoch 57/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4514 - val_loss: 0.7196\n",
      "Epoch 58/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4414 - val_loss: 0.7191\n",
      "Epoch 59/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4381 - val_loss: 0.7176\n",
      "Epoch 60/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4515 - val_loss: 0.7210\n",
      "Epoch 61/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4442 - val_loss: 0.7148\n",
      "Epoch 62/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4422 - val_loss: 0.7204\n",
      "Epoch 63/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4475 - val_loss: 0.7225\n",
      "Epoch 64/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4286 - val_loss: 0.7165\n",
      "Epoch 65/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4387 - val_loss: 0.7168\n",
      "Epoch 66/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4287 - val_loss: 0.7178\n",
      "Epoch 67/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4365 - val_loss: 0.7159\n",
      "Epoch 68/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4419 - val_loss: 0.7054\n",
      "Epoch 69/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4356 - val_loss: 0.7449\n",
      "Epoch 70/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4391 - val_loss: 0.7201\n",
      "Epoch 71/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4358 - val_loss: 0.7219\n",
      "Epoch 72/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4358 - val_loss: 0.7170\n",
      "Epoch 73/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4385 - val_loss: 0.7192\n",
      "Epoch 74/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4385 - val_loss: 0.7248\n",
      "Epoch 75/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4299 - val_loss: 0.7308\n",
      "Epoch 76/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4395 - val_loss: 0.7324\n",
      "Epoch 77/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4333 - val_loss: 0.7243\n",
      "Epoch 78/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4332 - val_loss: 0.7270\n",
      "Epoch 79/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4438 - val_loss: 0.7335\n",
      "Epoch 80/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4469 - val_loss: 0.7404\n",
      "Epoch 81/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4420 - val_loss: 0.7173\n",
      "Epoch 82/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4494 - val_loss: 0.7280\n",
      "Epoch 83/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4228 - val_loss: 0.7208\n",
      "Epoch 84/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4226 - val_loss: 0.7170\n",
      "Epoch 85/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4333 - val_loss: 0.7328\n",
      "Epoch 86/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4208 - val_loss: 0.7325\n",
      "Epoch 87/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4454 - val_loss: 0.7250\n",
      "Epoch 88/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4426 - val_loss: 0.7195\n",
      "Epoch 89/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4329 - val_loss: 0.7143\n",
      "Epoch 90/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4246 - val_loss: 0.7239\n",
      "Epoch 91/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4318 - val_loss: 0.7299\n",
      "Epoch 92/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4289 - val_loss: 0.7188\n",
      "Epoch 93/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4236 - val_loss: 0.7247\n",
      "Epoch 94/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4312 - val_loss: 0.7265\n",
      "Epoch 95/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4361 - val_loss: 0.7189\n",
      "Epoch 96/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4346 - val_loss: 0.7202\n",
      "Epoch 97/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4196 - val_loss: 0.7240\n",
      "Epoch 98/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4373 - val_loss: 0.7187\n",
      "Epoch 99/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4348 - val_loss: 0.7309\n",
      "Epoch 100/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4324 - val_loss: 0.7164\n",
      "current time:  2024-06-28_19-08\n",
      "\n",
      "\n",
      "4:mean_squared_error-label_sub 8.9%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.7271 - val_loss: 0.6934\n",
      "Epoch 2/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6578 - val_loss: 0.6606\n",
      "Epoch 3/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6022 - val_loss: 0.6580\n",
      "Epoch 4/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5881 - val_loss: 0.6622\n",
      "Epoch 5/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5749 - val_loss: 0.6571\n",
      "Epoch 6/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5656 - val_loss: 0.6606\n",
      "Epoch 7/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5328 - val_loss: 0.6552\n",
      "Epoch 8/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5342 - val_loss: 0.6610\n",
      "Epoch 9/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5259 - val_loss: 0.6666\n",
      "Epoch 10/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5181 - val_loss: 0.6861\n",
      "Epoch 11/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5093 - val_loss: 0.6640\n",
      "Epoch 12/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5091 - val_loss: 0.6673\n",
      "Epoch 13/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4853 - val_loss: 0.6685\n",
      "Epoch 14/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4947 - val_loss: 0.6747\n",
      "Epoch 15/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4970 - val_loss: 0.6679\n",
      "Epoch 16/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4780 - val_loss: 0.6672\n",
      "Epoch 17/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4742 - val_loss: 0.6650\n",
      "Epoch 18/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4801 - val_loss: 0.6704\n",
      "Epoch 19/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4865 - val_loss: 0.6816\n",
      "Epoch 20/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4783 - val_loss: 0.6908\n",
      "Epoch 21/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4561 - val_loss: 0.6707\n",
      "Epoch 22/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4586 - val_loss: 0.6887\n",
      "Epoch 23/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4626 - val_loss: 0.6951\n",
      "Epoch 24/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4704 - val_loss: 0.6781\n",
      "Epoch 25/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4628 - val_loss: 0.6712\n",
      "Epoch 26/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4503 - val_loss: 0.6904\n",
      "Epoch 27/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4620 - val_loss: 0.6933\n",
      "Epoch 28/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4490 - val_loss: 0.6842\n",
      "Epoch 29/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4556 - val_loss: 0.6833\n",
      "Epoch 30/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4611 - val_loss: 0.6699\n",
      "Epoch 31/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4596 - val_loss: 0.6755\n",
      "Epoch 32/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4434 - val_loss: 0.6917\n",
      "Epoch 33/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4534 - val_loss: 0.7016\n",
      "Epoch 34/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4610 - val_loss: 0.6949\n",
      "Epoch 35/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4493 - val_loss: 0.6884\n",
      "Epoch 36/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4358 - val_loss: 0.7087\n",
      "Epoch 37/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4406 - val_loss: 0.6854\n",
      "Epoch 38/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4527 - val_loss: 0.6947\n",
      "Epoch 39/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4622 - val_loss: 0.6876\n",
      "Epoch 40/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4482 - val_loss: 0.6985\n",
      "Epoch 41/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4384 - val_loss: 0.7007\n",
      "Epoch 42/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4581 - val_loss: 0.6948\n",
      "Epoch 43/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4455 - val_loss: 0.6932\n",
      "Epoch 44/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4525 - val_loss: 0.7053\n",
      "Epoch 45/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4352 - val_loss: 0.7045\n",
      "Epoch 46/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4383 - val_loss: 0.7036\n",
      "Epoch 47/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4380 - val_loss: 0.6894\n",
      "Epoch 48/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4434 - val_loss: 0.7032\n",
      "Epoch 49/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4493 - val_loss: 0.7071\n",
      "Epoch 50/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4308 - val_loss: 0.6962\n",
      "Epoch 51/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4281 - val_loss: 0.6807\n",
      "Epoch 52/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4347 - val_loss: 0.6949\n",
      "Epoch 53/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4385 - val_loss: 0.6916\n",
      "Epoch 54/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4432 - val_loss: 0.7018\n",
      "Epoch 55/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4282 - val_loss: 0.6885\n",
      "Epoch 56/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4346 - val_loss: 0.6964\n",
      "Epoch 57/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4159 - val_loss: 0.6961\n",
      "Epoch 58/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4327 - val_loss: 0.7003\n",
      "Epoch 59/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4415 - val_loss: 0.7033\n",
      "Epoch 60/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4360 - val_loss: 0.6955\n",
      "Epoch 61/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4426 - val_loss: 0.7103\n",
      "Epoch 62/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4211 - val_loss: 0.6963\n",
      "Epoch 63/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4399 - val_loss: 0.7044\n",
      "Epoch 64/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4410 - val_loss: 0.7015\n",
      "Epoch 65/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4346 - val_loss: 0.6939\n",
      "Epoch 66/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4394 - val_loss: 0.7022\n",
      "Epoch 67/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4325 - val_loss: 0.6977\n",
      "Epoch 68/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4170 - val_loss: 0.7106\n",
      "Epoch 69/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4236 - val_loss: 0.6898\n",
      "Epoch 70/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4287 - val_loss: 0.6909\n",
      "Epoch 71/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4056 - val_loss: 0.7122\n",
      "Epoch 72/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4341 - val_loss: 0.7043\n",
      "Epoch 73/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4269 - val_loss: 0.6974\n",
      "Epoch 74/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4352 - val_loss: 0.7081\n",
      "Epoch 75/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4310 - val_loss: 0.6976\n",
      "Epoch 76/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4204 - val_loss: 0.7014\n",
      "Epoch 77/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4313 - val_loss: 0.7131\n",
      "Epoch 78/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4206 - val_loss: 0.6962\n",
      "Epoch 79/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4286 - val_loss: 0.7005\n",
      "Epoch 80/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4389 - val_loss: 0.7137\n",
      "Epoch 81/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4363 - val_loss: 0.7033\n",
      "Epoch 82/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4323 - val_loss: 0.7019\n",
      "Epoch 83/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4405 - val_loss: 0.7201\n",
      "Epoch 84/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4189 - val_loss: 0.6993\n",
      "Epoch 85/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4238 - val_loss: 0.6994\n",
      "Epoch 86/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4125 - val_loss: 0.7048\n",
      "Epoch 87/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4395 - val_loss: 0.7136\n",
      "Epoch 88/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4246 - val_loss: 0.7004\n",
      "Epoch 89/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4377 - val_loss: 0.7086\n",
      "Epoch 90/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4194 - val_loss: 0.7097\n",
      "Epoch 91/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4261 - val_loss: 0.7023\n",
      "Epoch 92/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4249 - val_loss: 0.7058\n",
      "Epoch 93/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4206 - val_loss: 0.7018\n",
      "Epoch 94/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4181 - val_loss: 0.7055\n",
      "Epoch 95/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4258 - val_loss: 0.7125\n",
      "Epoch 96/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4245 - val_loss: 0.7112\n",
      "Epoch 97/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4274 - val_loss: 0.7010\n",
      "Epoch 98/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4202 - val_loss: 0.6946\n",
      "Epoch 99/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4323 - val_loss: 0.7081\n",
      "Epoch 100/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4373 - val_loss: 0.7116\n",
      "current time:  2024-06-28_19-09\n",
      "\n",
      "\n",
      "5:mean_squared_error-label_sub 11.1%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7165 - val_loss: 0.6889\n",
      "Epoch 2/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6523 - val_loss: 0.6760\n",
      "Epoch 3/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5991 - val_loss: 0.6576\n",
      "Epoch 4/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5789 - val_loss: 0.6594\n",
      "Epoch 5/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5809 - val_loss: 0.6652\n",
      "Epoch 6/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5461 - val_loss: 0.6611\n",
      "Epoch 7/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5373 - val_loss: 0.6788\n",
      "Epoch 8/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5303 - val_loss: 0.6426\n",
      "Epoch 9/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5318 - val_loss: 0.6701\n",
      "Epoch 10/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5226 - val_loss: 0.6730\n",
      "Epoch 11/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5038 - val_loss: 0.6881\n",
      "Epoch 12/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5055 - val_loss: 0.6764\n",
      "Epoch 13/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4931 - val_loss: 0.6661\n",
      "Epoch 14/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4900 - val_loss: 0.6772\n",
      "Epoch 15/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4870 - val_loss: 0.6777\n",
      "Epoch 16/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5007 - val_loss: 0.6752\n",
      "Epoch 17/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4828 - val_loss: 0.6799\n",
      "Epoch 18/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4784 - val_loss: 0.6661\n",
      "Epoch 19/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4885 - val_loss: 0.6962\n",
      "Epoch 20/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4704 - val_loss: 0.6800\n",
      "Epoch 21/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4783 - val_loss: 0.6751\n",
      "Epoch 22/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4538 - val_loss: 0.6867\n",
      "Epoch 23/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4516 - val_loss: 0.6903\n",
      "Epoch 24/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4687 - val_loss: 0.6894\n",
      "Epoch 25/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4491 - val_loss: 0.6738\n",
      "Epoch 26/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4590 - val_loss: 0.6867\n",
      "Epoch 27/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4557 - val_loss: 0.6829\n",
      "Epoch 28/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4607 - val_loss: 0.6944\n",
      "Epoch 29/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4444 - val_loss: 0.6997\n",
      "Epoch 30/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4446 - val_loss: 0.6858\n",
      "Epoch 31/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4472 - val_loss: 0.6914\n",
      "Epoch 32/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4492 - val_loss: 0.6789\n",
      "Epoch 33/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4542 - val_loss: 0.7036\n",
      "Epoch 34/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4581 - val_loss: 0.6830\n",
      "Epoch 35/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4415 - val_loss: 0.6837\n",
      "Epoch 36/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4396 - val_loss: 0.6871\n",
      "Epoch 37/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4429 - val_loss: 0.6968\n",
      "Epoch 38/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4396 - val_loss: 0.7009\n",
      "Epoch 39/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4515 - val_loss: 0.7011\n",
      "Epoch 40/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4442 - val_loss: 0.6874\n",
      "Epoch 41/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4324 - val_loss: 0.6883\n",
      "Epoch 42/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4410 - val_loss: 0.6927\n",
      "Epoch 43/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4421 - val_loss: 0.6931\n",
      "Epoch 44/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4386 - val_loss: 0.6951\n",
      "Epoch 45/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4314 - val_loss: 0.6963\n",
      "Epoch 46/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4112 - val_loss: 0.6984\n",
      "Epoch 47/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4353 - val_loss: 0.6845\n",
      "Epoch 48/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4150 - val_loss: 0.6982\n",
      "Epoch 49/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4321 - val_loss: 0.6955\n",
      "Epoch 50/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4307 - val_loss: 0.6961\n",
      "Epoch 51/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4244 - val_loss: 0.6960\n",
      "Epoch 52/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4372 - val_loss: 0.6949\n",
      "Epoch 53/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4249 - val_loss: 0.6942\n",
      "Epoch 54/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4236 - val_loss: 0.6999\n",
      "Epoch 55/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4345 - val_loss: 0.7000\n",
      "Epoch 56/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4285 - val_loss: 0.7082\n",
      "Epoch 57/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4239 - val_loss: 0.6992\n",
      "Epoch 58/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4323 - val_loss: 0.6872\n",
      "Epoch 59/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4435 - val_loss: 0.7014\n",
      "Epoch 60/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4255 - val_loss: 0.7040\n",
      "Epoch 61/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4161 - val_loss: 0.6871\n",
      "Epoch 62/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4338 - val_loss: 0.7036\n",
      "Epoch 63/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4240 - val_loss: 0.6997\n",
      "Epoch 64/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4316 - val_loss: 0.7094\n",
      "Epoch 65/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4199 - val_loss: 0.7178\n",
      "Epoch 66/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4349 - val_loss: 0.7136\n",
      "Epoch 67/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4187 - val_loss: 0.7058\n",
      "Epoch 68/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4296 - val_loss: 0.7065\n",
      "Epoch 69/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4329 - val_loss: 0.6948\n",
      "Epoch 70/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4151 - val_loss: 0.7135\n",
      "Epoch 71/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4270 - val_loss: 0.7073\n",
      "Epoch 72/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4322 - val_loss: 0.7022\n",
      "Epoch 73/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4226 - val_loss: 0.6975\n",
      "Epoch 74/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4198 - val_loss: 0.7058\n",
      "Epoch 75/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4322 - val_loss: 0.7027\n",
      "Epoch 76/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4188 - val_loss: 0.7061\n",
      "Epoch 77/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4209 - val_loss: 0.7050\n",
      "Epoch 78/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4254 - val_loss: 0.7078\n",
      "Epoch 79/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4260 - val_loss: 0.7032\n",
      "Epoch 80/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4187 - val_loss: 0.7089\n",
      "Epoch 81/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4179 - val_loss: 0.7012\n",
      "Epoch 82/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4091 - val_loss: 0.7062\n",
      "Epoch 83/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4331 - val_loss: 0.6987\n",
      "Epoch 84/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4278 - val_loss: 0.6981\n",
      "Epoch 85/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4297 - val_loss: 0.7138\n",
      "Epoch 86/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4190 - val_loss: 0.7048\n",
      "Epoch 87/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4232 - val_loss: 0.7182\n",
      "Epoch 88/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4242 - val_loss: 0.7188\n",
      "Epoch 89/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4219 - val_loss: 0.7116\n",
      "Epoch 90/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4180 - val_loss: 0.7105\n",
      "Epoch 91/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4293 - val_loss: 0.7199\n",
      "Epoch 92/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4221 - val_loss: 0.7015\n",
      "Epoch 93/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4204 - val_loss: 0.7133\n",
      "Epoch 94/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4227 - val_loss: 0.7124\n",
      "Epoch 95/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4115 - val_loss: 0.7271\n",
      "Epoch 96/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4202 - val_loss: 0.7130\n",
      "Epoch 97/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4186 - val_loss: 0.7130\n",
      "Epoch 98/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4344 - val_loss: 0.7106\n",
      "Epoch 99/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4179 - val_loss: 0.7065\n",
      "Epoch 100/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4232 - val_loss: 0.7180\n",
      "current time:  2024-06-28_19-09\n",
      "\n",
      "\n",
      "6:mean_squared_error-label_sub 13.3%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7575 - val_loss: 0.7445\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7134 - val_loss: 0.7171\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6816 - val_loss: 0.7148\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6899 - val_loss: 0.6875\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6554 - val_loss: 0.6880\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6317 - val_loss: 0.6679\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6119 - val_loss: 0.6659\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5987 - val_loss: 0.6666\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5763 - val_loss: 0.6593\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5577 - val_loss: 0.6650\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5692 - val_loss: 0.6649\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5642 - val_loss: 0.6563\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5462 - val_loss: 0.6729\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5447 - val_loss: 0.6610\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5125 - val_loss: 0.6650\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5253 - val_loss: 0.6662\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5157 - val_loss: 0.6606\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5117 - val_loss: 0.6683\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5069 - val_loss: 0.6638\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5085 - val_loss: 0.6671\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5020 - val_loss: 0.6655\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4947 - val_loss: 0.6791\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4900 - val_loss: 0.6783\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4943 - val_loss: 0.6839\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4780 - val_loss: 0.6813\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4949 - val_loss: 0.6940\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4935 - val_loss: 0.7003\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5118 - val_loss: 0.6851\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4877 - val_loss: 0.6821\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4848 - val_loss: 0.6896\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4777 - val_loss: 0.6945\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4621 - val_loss: 0.6938\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4719 - val_loss: 0.6963\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4717 - val_loss: 0.7038\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4626 - val_loss: 0.7009\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4657 - val_loss: 0.6979\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4544 - val_loss: 0.6984\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4633 - val_loss: 0.7119\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4740 - val_loss: 0.7118\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4571 - val_loss: 0.7005\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4779 - val_loss: 0.7109\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4639 - val_loss: 0.7063\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4654 - val_loss: 0.7068\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4584 - val_loss: 0.7068\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4593 - val_loss: 0.7163\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4533 - val_loss: 0.7225\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4659 - val_loss: 0.7051\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4550 - val_loss: 0.7179\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4686 - val_loss: 0.7274\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4615 - val_loss: 0.7125\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4540 - val_loss: 0.7127\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4516 - val_loss: 0.7164\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4566 - val_loss: 0.7168\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4497 - val_loss: 0.7187\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4590 - val_loss: 0.7286\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4511 - val_loss: 0.7149\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4445 - val_loss: 0.7126\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4510 - val_loss: 0.7141\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4481 - val_loss: 0.7184\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4337 - val_loss: 0.7124\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4420 - val_loss: 0.7230\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4491 - val_loss: 0.7130\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4269 - val_loss: 0.7180\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4403 - val_loss: 0.7235\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4402 - val_loss: 0.7161\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4336 - val_loss: 0.7230\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4404 - val_loss: 0.7229\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4407 - val_loss: 0.7286\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4578 - val_loss: 0.7170\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4471 - val_loss: 0.7172\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4382 - val_loss: 0.7250\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4438 - val_loss: 0.7238\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4398 - val_loss: 0.7254\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4382 - val_loss: 0.7236\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4396 - val_loss: 0.7253\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4366 - val_loss: 0.7147\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4431 - val_loss: 0.7196\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4323 - val_loss: 0.7326\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4413 - val_loss: 0.7154\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4454 - val_loss: 0.7318\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4343 - val_loss: 0.7304\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4366 - val_loss: 0.7224\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4248 - val_loss: 0.7286\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4254 - val_loss: 0.7277\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4384 - val_loss: 0.7242\n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4434 - val_loss: 0.7305\n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4314 - val_loss: 0.7272\n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4379 - val_loss: 0.7296\n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4284 - val_loss: 0.7293\n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4292 - val_loss: 0.7304\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4290 - val_loss: 0.7230\n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4359 - val_loss: 0.7220\n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4311 - val_loss: 0.7356\n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4429 - val_loss: 0.7321\n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4237 - val_loss: 0.7335\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4320 - val_loss: 0.7339\n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4254 - val_loss: 0.7320\n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4322 - val_loss: 0.7290\n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4278 - val_loss: 0.7314\n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4439 - val_loss: 0.7278\n",
      "current time:  2024-06-28_19-09\n",
      "\n",
      "\n",
      "7:mean_squared_error-label_sub 15.6%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7440 - val_loss: 0.7217\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7117 - val_loss: 0.6976\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6612 - val_loss: 0.6776\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6398 - val_loss: 0.6717\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6008 - val_loss: 0.6558\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5757 - val_loss: 0.6502\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5586 - val_loss: 0.6592\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5482 - val_loss: 0.6426\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5469 - val_loss: 0.6683\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5555 - val_loss: 0.6533\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5188 - val_loss: 0.6664\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5264 - val_loss: 0.6561\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5210 - val_loss: 0.6485\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5114 - val_loss: 0.6573\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5057 - val_loss: 0.6628\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5001 - val_loss: 0.6533\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4807 - val_loss: 0.6539\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4954 - val_loss: 0.6677\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4808 - val_loss: 0.6642\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4754 - val_loss: 0.6736\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4815 - val_loss: 0.6684\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4844 - val_loss: 0.6607\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4729 - val_loss: 0.6658\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4641 - val_loss: 0.6617\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4627 - val_loss: 0.6659\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4668 - val_loss: 0.6579\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4696 - val_loss: 0.6764\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4629 - val_loss: 0.6630\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4595 - val_loss: 0.6837\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4617 - val_loss: 0.6653\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4467 - val_loss: 0.6799\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4456 - val_loss: 0.6849\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4625 - val_loss: 0.6747\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4682 - val_loss: 0.6751\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4562 - val_loss: 0.6794\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4525 - val_loss: 0.6711\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4405 - val_loss: 0.6896\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4550 - val_loss: 0.6787\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4453 - val_loss: 0.6798\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4443 - val_loss: 0.6730\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4411 - val_loss: 0.6680\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4482 - val_loss: 0.6919\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4382 - val_loss: 0.6793\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4498 - val_loss: 0.6752\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4507 - val_loss: 0.6792\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4439 - val_loss: 0.6876\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4364 - val_loss: 0.6951\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4450 - val_loss: 0.6914\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4281 - val_loss: 0.6812\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4369 - val_loss: 0.6803\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4497 - val_loss: 0.6925\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4269 - val_loss: 0.6700\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4413 - val_loss: 0.6714\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4494 - val_loss: 0.6949\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4350 - val_loss: 0.6902\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4330 - val_loss: 0.6866\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4303 - val_loss: 0.6777\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4280 - val_loss: 0.6996\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4404 - val_loss: 0.6908\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4313 - val_loss: 0.6849\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4376 - val_loss: 0.6790\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4399 - val_loss: 0.6782\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4243 - val_loss: 0.6833\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4324 - val_loss: 0.6725\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4209 - val_loss: 0.6845\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4249 - val_loss: 0.6826\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4214 - val_loss: 0.6783\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4355 - val_loss: 0.6857\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4337 - val_loss: 0.6790\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4300 - val_loss: 0.6877\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4086 - val_loss: 0.6893\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4402 - val_loss: 0.6819\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4273 - val_loss: 0.6783\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4368 - val_loss: 0.6830\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4248 - val_loss: 0.6842\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4389 - val_loss: 0.6788\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4256 - val_loss: 0.6797\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4309 - val_loss: 0.6709\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4292 - val_loss: 0.6866\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4222 - val_loss: 0.6861\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4152 - val_loss: 0.6783\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4234 - val_loss: 0.6856\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4190 - val_loss: 0.6803\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4414 - val_loss: 0.6721\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4400 - val_loss: 0.6788\n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4314 - val_loss: 0.6874\n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4186 - val_loss: 0.6879\n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4364 - val_loss: 0.6757\n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4252 - val_loss: 0.6762\n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4384 - val_loss: 0.6790\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4270 - val_loss: 0.6801\n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4269 - val_loss: 0.6870\n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4222 - val_loss: 0.6721\n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4107 - val_loss: 0.6854\n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4278 - val_loss: 0.6844\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4292 - val_loss: 0.6838\n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4183 - val_loss: 0.6911\n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4287 - val_loss: 0.6820\n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4200 - val_loss: 0.6789\n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4357 - val_loss: 0.6853\n",
      "current time:  2024-06-28_19-09\n",
      "\n",
      "\n",
      "8:mean_squared_error-label_sub 17.8%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.7184 - val_loss: 0.6921\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6518 - val_loss: 0.6646\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6050 - val_loss: 0.6672\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5961 - val_loss: 0.6565\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5632 - val_loss: 0.6651\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5549 - val_loss: 0.6690\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5471 - val_loss: 0.6585\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5420 - val_loss: 0.6807\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5376 - val_loss: 0.6659\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5261 - val_loss: 0.6786\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5109 - val_loss: 0.6720\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5095 - val_loss: 0.7135\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5186 - val_loss: 0.6722\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4990 - val_loss: 0.6940\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5097 - val_loss: 0.6861\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4735 - val_loss: 0.6865\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4723 - val_loss: 0.6813\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4808 - val_loss: 0.6829\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4700 - val_loss: 0.6815\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4588 - val_loss: 0.6882\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4714 - val_loss: 0.6922\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4670 - val_loss: 0.6770\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4546 - val_loss: 0.6848\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4495 - val_loss: 0.6842\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4656 - val_loss: 0.6868\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4758 - val_loss: 0.7028\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4637 - val_loss: 0.6938\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4446 - val_loss: 0.6849\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4474 - val_loss: 0.7016\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4547 - val_loss: 0.6938\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4468 - val_loss: 0.6972\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4461 - val_loss: 0.6983\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4336 - val_loss: 0.6888\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4508 - val_loss: 0.7145\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4461 - val_loss: 0.6940\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4504 - val_loss: 0.7162\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4437 - val_loss: 0.6870\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4349 - val_loss: 0.6897\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4399 - val_loss: 0.7062\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4464 - val_loss: 0.6993\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4405 - val_loss: 0.6850\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4424 - val_loss: 0.6876\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4355 - val_loss: 0.6845\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4560 - val_loss: 0.6859\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4401 - val_loss: 0.6932\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4300 - val_loss: 0.6914\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4355 - val_loss: 0.7098\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4403 - val_loss: 0.7017\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4337 - val_loss: 0.6952\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4282 - val_loss: 0.7094\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4391 - val_loss: 0.6898\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4288 - val_loss: 0.7075\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4313 - val_loss: 0.6981\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4302 - val_loss: 0.7015\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4208 - val_loss: 0.7019\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4314 - val_loss: 0.6951\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4348 - val_loss: 0.6940\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4342 - val_loss: 0.6924\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4271 - val_loss: 0.7041\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4284 - val_loss: 0.6973\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4261 - val_loss: 0.6991\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4280 - val_loss: 0.7083\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4270 - val_loss: 0.7040\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4222 - val_loss: 0.6981\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4427 - val_loss: 0.7038\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4319 - val_loss: 0.7159\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4335 - val_loss: 0.7036\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4297 - val_loss: 0.7035\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4153 - val_loss: 0.7022\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4208 - val_loss: 0.6980\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4299 - val_loss: 0.6928\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4214 - val_loss: 0.7006\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4352 - val_loss: 0.6953\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4194 - val_loss: 0.7036\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4350 - val_loss: 0.7018\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4263 - val_loss: 0.7141\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4275 - val_loss: 0.7166\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4234 - val_loss: 0.6957\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4390 - val_loss: 0.6965\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4259 - val_loss: 0.6991\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4379 - val_loss: 0.7206\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4190 - val_loss: 0.7135\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4265 - val_loss: 0.7058\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4275 - val_loss: 0.7059\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4184 - val_loss: 0.7031\n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4179 - val_loss: 0.7153\n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4200 - val_loss: 0.7162\n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4266 - val_loss: 0.7172\n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4226 - val_loss: 0.7042\n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4207 - val_loss: 0.7030\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4222 - val_loss: 0.7019\n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4285 - val_loss: 0.7052\n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4155 - val_loss: 0.7146\n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4217 - val_loss: 0.7198\n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4162 - val_loss: 0.6929\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4178 - val_loss: 0.7061\n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4093 - val_loss: 0.6997\n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4188 - val_loss: 0.7006\n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4241 - val_loss: 0.7198\n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4248 - val_loss: 0.7103\n",
      "current time:  2024-06-28_19-10\n",
      "\n",
      "\n",
      "9:mean_squared_error-label_sub 20.0%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.7228 - val_loss: 0.6593\n",
      "Epoch 2/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.6276 - val_loss: 0.6486\n",
      "Epoch 3/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6058 - val_loss: 0.6579\n",
      "Epoch 4/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6020 - val_loss: 0.6476\n",
      "Epoch 5/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5988 - val_loss: 0.6352\n",
      "Epoch 6/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.5695 - val_loss: 0.6783\n",
      "Epoch 7/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5657 - val_loss: 0.6489\n",
      "Epoch 8/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5533 - val_loss: 0.6557\n",
      "Epoch 9/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5314 - val_loss: 0.6666\n",
      "Epoch 10/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.5312 - val_loss: 0.6733\n",
      "Epoch 11/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.5136 - val_loss: 0.6505\n",
      "Epoch 12/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.5143 - val_loss: 0.6669\n",
      "Epoch 13/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.5131 - val_loss: 0.6641\n",
      "Epoch 14/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.5210 - val_loss: 0.6760\n",
      "Epoch 15/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.4944 - val_loss: 0.6759\n",
      "Epoch 16/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.4915 - val_loss: 0.6658\n",
      "Epoch 17/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.4912 - val_loss: 0.6542\n",
      "Epoch 18/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4969 - val_loss: 0.6880\n",
      "Epoch 19/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 0.4959 - val_loss: 0.6731\n",
      "Epoch 20/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.4785 - val_loss: 0.6726\n",
      "Epoch 21/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.4977 - val_loss: 0.6714\n",
      "Epoch 22/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4746 - val_loss: 0.6827\n",
      "Epoch 23/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5011 - val_loss: 0.6900\n",
      "Epoch 24/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.4689 - val_loss: 0.6902\n",
      "Epoch 25/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.4746 - val_loss: 0.6601\n",
      "Epoch 26/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.4773 - val_loss: 0.6957\n",
      "Epoch 27/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4806 - val_loss: 0.6778\n",
      "Epoch 28/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.4651 - val_loss: 0.6793\n",
      "Epoch 29/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.4676 - val_loss: 0.6670\n",
      "Epoch 30/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4818 - val_loss: 0.6610\n",
      "Epoch 31/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4566 - val_loss: 0.6724\n",
      "Epoch 32/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.4583 - val_loss: 0.6740\n",
      "Epoch 33/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.4596 - val_loss: 0.6815\n",
      "Epoch 34/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.4612 - val_loss: 0.6842\n",
      "Epoch 35/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.4678 - val_loss: 0.6679\n",
      "Epoch 36/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4659 - val_loss: 0.6727\n",
      "Epoch 37/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.4583 - val_loss: 0.6783\n",
      "Epoch 38/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.4757 - val_loss: 0.7042\n",
      "Epoch 39/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 0.4563 - val_loss: 0.6674\n",
      "Epoch 40/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4528 - val_loss: 0.6706\n",
      "Epoch 41/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.4593 - val_loss: 0.6736\n",
      "Epoch 42/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.4549 - val_loss: 0.6810\n",
      "Epoch 43/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.4509 - val_loss: 0.6855\n",
      "Epoch 44/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.4548 - val_loss: 0.6575\n",
      "Epoch 45/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4394 - val_loss: 0.6802\n",
      "Epoch 46/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.4468 - val_loss: 0.6887\n",
      "Epoch 47/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 0.4319 - val_loss: 0.6786\n",
      "Epoch 48/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.4547 - val_loss: 0.6797\n",
      "Epoch 49/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4501 - val_loss: 0.6697\n",
      "Epoch 50/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.4594 - val_loss: 0.6788\n",
      "Epoch 51/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.4553 - val_loss: 0.6616\n",
      "Epoch 52/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.4648 - val_loss: 0.6757\n",
      "Epoch 53/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.4554 - val_loss: 0.6645\n",
      "Epoch 54/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4564 - val_loss: 0.6699\n",
      "Epoch 55/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.4423 - val_loss: 0.6731\n",
      "Epoch 56/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.4493 - val_loss: 0.6686\n",
      "Epoch 57/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 0.4535 - val_loss: 0.6826\n",
      "Epoch 58/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4612 - val_loss: 0.6724\n",
      "Epoch 59/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 0.4490 - val_loss: 0.6740\n",
      "Epoch 60/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.4392 - val_loss: 0.6779\n",
      "Epoch 61/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4430 - val_loss: 0.6697\n",
      "Epoch 62/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.4420 - val_loss: 0.6914\n",
      "Epoch 63/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4303 - val_loss: 0.6685\n",
      "Epoch 64/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.4371 - val_loss: 0.6728\n",
      "Epoch 65/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.4417 - val_loss: 0.6765\n",
      "Epoch 66/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 0.4368 - val_loss: 0.6656\n",
      "Epoch 67/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.4263 - val_loss: 0.6663\n",
      "Epoch 68/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.4501 - val_loss: 0.6829\n",
      "Epoch 69/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.4468 - val_loss: 0.6784\n",
      "Epoch 70/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.4275 - val_loss: 0.6911\n",
      "Epoch 71/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.4352 - val_loss: 0.6792\n",
      "Epoch 72/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.4461 - val_loss: 0.6744\n",
      "Epoch 73/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4588 - val_loss: 0.6659\n",
      "Epoch 74/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.4466 - val_loss: 0.6658\n",
      "Epoch 75/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.4378 - val_loss: 0.6820\n",
      "Epoch 76/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4277 - val_loss: 0.6778\n",
      "Epoch 77/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.4466 - val_loss: 0.6732\n",
      "Epoch 78/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.4365 - val_loss: 0.6641\n",
      "Epoch 79/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.4271 - val_loss: 0.6577\n",
      "Epoch 80/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.4448 - val_loss: 0.6895\n",
      "Epoch 81/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4339 - val_loss: 0.6807\n",
      "Epoch 82/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4471 - val_loss: 0.6670\n",
      "Epoch 83/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4483 - val_loss: 0.6712\n",
      "Epoch 84/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.4359 - val_loss: 0.6823\n",
      "Epoch 85/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4292 - val_loss: 0.6728\n",
      "Epoch 86/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.4463 - val_loss: 0.6944\n",
      "Epoch 87/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.4366 - val_loss: 0.6798\n",
      "Epoch 88/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.4413 - val_loss: 0.6716\n",
      "Epoch 89/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.4412 - val_loss: 0.6784\n",
      "Epoch 90/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4429 - val_loss: 0.6958\n",
      "Epoch 91/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4377 - val_loss: 0.6815\n",
      "Epoch 92/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4319 - val_loss: 0.6835\n",
      "Epoch 93/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4562 - val_loss: 0.6682\n",
      "Epoch 94/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4365 - val_loss: 0.6910\n",
      "Epoch 95/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4362 - val_loss: 0.6911\n",
      "Epoch 96/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4441 - val_loss: 0.6915\n",
      "Epoch 97/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4313 - val_loss: 0.6780\n",
      "Epoch 98/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4372 - val_loss: 0.6792\n",
      "Epoch 99/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4478 - val_loss: 0.6823\n",
      "Epoch 100/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.4379 - val_loss: 0.6892\n",
      "current time:  2024-06-28_19-11\n",
      "\n",
      "\n",
      "10:mean_squared_error-label_sub 22.2%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.7085 - val_loss: 0.6510\n",
      "Epoch 2/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6431 - val_loss: 0.6529\n",
      "Epoch 3/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5931 - val_loss: 0.6274\n",
      "Epoch 4/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5797 - val_loss: 0.6428\n",
      "Epoch 5/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5647 - val_loss: 0.6337\n",
      "Epoch 6/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5782 - val_loss: 0.6745\n",
      "Epoch 7/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5416 - val_loss: 0.6633\n",
      "Epoch 8/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5528 - val_loss: 0.6503\n",
      "Epoch 9/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5318 - val_loss: 0.6653\n",
      "Epoch 10/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5222 - val_loss: 0.6565\n",
      "Epoch 11/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5355 - val_loss: 0.6297\n",
      "Epoch 12/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5149 - val_loss: 0.6395\n",
      "Epoch 13/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5060 - val_loss: 0.6650\n",
      "Epoch 14/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4828 - val_loss: 0.6480\n",
      "Epoch 15/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5039 - val_loss: 0.6673\n",
      "Epoch 16/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4843 - val_loss: 0.6721\n",
      "Epoch 17/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4922 - val_loss: 0.6601\n",
      "Epoch 18/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4885 - val_loss: 0.6491\n",
      "Epoch 19/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4754 - val_loss: 0.6599\n",
      "Epoch 20/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4817 - val_loss: 0.6692\n",
      "Epoch 21/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4723 - val_loss: 0.6633\n",
      "Epoch 22/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4643 - val_loss: 0.6845\n",
      "Epoch 23/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4775 - val_loss: 0.6628\n",
      "Epoch 24/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4742 - val_loss: 0.6743\n",
      "Epoch 25/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4565 - val_loss: 0.6599\n",
      "Epoch 26/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4604 - val_loss: 0.6705\n",
      "Epoch 27/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4570 - val_loss: 0.6715\n",
      "Epoch 28/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4664 - val_loss: 0.6739\n",
      "Epoch 29/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4497 - val_loss: 0.6932\n",
      "Epoch 30/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4583 - val_loss: 0.6522\n",
      "Epoch 31/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4529 - val_loss: 0.6745\n",
      "Epoch 32/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4536 - val_loss: 0.6845\n",
      "Epoch 33/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4550 - val_loss: 0.7027\n",
      "Epoch 34/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.4502 - val_loss: 0.6758\n",
      "Epoch 35/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4611 - val_loss: 0.7071\n",
      "Epoch 36/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4566 - val_loss: 0.6611\n",
      "Epoch 37/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4458 - val_loss: 0.6673\n",
      "Epoch 38/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4485 - val_loss: 0.6599\n",
      "Epoch 39/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4495 - val_loss: 0.6716\n",
      "Epoch 40/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4520 - val_loss: 0.6766\n",
      "Epoch 41/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4383 - val_loss: 0.6691\n",
      "Epoch 42/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.4516 - val_loss: 0.6826\n",
      "Epoch 43/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4450 - val_loss: 0.6887\n",
      "Epoch 44/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4467 - val_loss: 0.6979\n",
      "Epoch 45/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4362 - val_loss: 0.6716\n",
      "Epoch 46/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4386 - val_loss: 0.6998\n",
      "Epoch 47/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4460 - val_loss: 0.6680\n",
      "Epoch 48/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4451 - val_loss: 0.6711\n",
      "Epoch 49/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4562 - val_loss: 0.7035\n",
      "Epoch 50/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.4392 - val_loss: 0.6824\n",
      "Epoch 51/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.4420 - val_loss: 0.6669\n",
      "Epoch 52/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4400 - val_loss: 0.6841\n",
      "Epoch 53/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4434 - val_loss: 0.6699\n",
      "Epoch 54/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4397 - val_loss: 0.6725\n",
      "Epoch 55/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.4433 - val_loss: 0.6737\n",
      "Epoch 56/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.4393 - val_loss: 0.6757\n",
      "Epoch 57/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4363 - val_loss: 0.6730\n",
      "Epoch 58/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4434 - val_loss: 0.6708\n",
      "Epoch 59/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4513 - val_loss: 0.6823\n",
      "Epoch 60/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4305 - val_loss: 0.7192\n",
      "Epoch 61/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4295 - val_loss: 0.7005\n",
      "Epoch 62/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4316 - val_loss: 0.6992\n",
      "Epoch 63/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4445 - val_loss: 0.6716\n",
      "Epoch 64/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4372 - val_loss: 0.6816\n",
      "Epoch 65/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4437 - val_loss: 0.6754\n",
      "Epoch 66/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4265 - val_loss: 0.6682\n",
      "Epoch 67/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4352 - val_loss: 0.6881\n",
      "Epoch 68/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4233 - val_loss: 0.6740\n",
      "Epoch 69/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4305 - val_loss: 0.6757\n",
      "Epoch 70/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4405 - val_loss: 0.6870\n",
      "Epoch 71/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4219 - val_loss: 0.6935\n",
      "Epoch 72/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4217 - val_loss: 0.6819\n",
      "Epoch 73/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4141 - val_loss: 0.6893\n",
      "Epoch 74/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4391 - val_loss: 0.6917\n",
      "Epoch 75/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4313 - val_loss: 0.6941\n",
      "Epoch 76/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4429 - val_loss: 0.6829\n",
      "Epoch 77/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4294 - val_loss: 0.6934\n",
      "Epoch 78/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4399 - val_loss: 0.6825\n",
      "Epoch 79/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4146 - val_loss: 0.6841\n",
      "Epoch 80/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4265 - val_loss: 0.7007\n",
      "Epoch 81/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4228 - val_loss: 0.6850\n",
      "Epoch 82/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4353 - val_loss: 0.6950\n",
      "Epoch 83/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4292 - val_loss: 0.6873\n",
      "Epoch 84/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4295 - val_loss: 0.7067\n",
      "Epoch 85/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4376 - val_loss: 0.6940\n",
      "Epoch 86/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4204 - val_loss: 0.6805\n",
      "Epoch 87/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4330 - val_loss: 0.6967\n",
      "Epoch 88/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4193 - val_loss: 0.6850\n",
      "Epoch 89/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4251 - val_loss: 0.7052\n",
      "Epoch 90/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4393 - val_loss: 0.6861\n",
      "Epoch 91/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4133 - val_loss: 0.6994\n",
      "Epoch 92/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4204 - val_loss: 0.6882\n",
      "Epoch 93/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4233 - val_loss: 0.6864\n",
      "Epoch 94/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4179 - val_loss: 0.6850\n",
      "Epoch 95/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4216 - val_loss: 0.6869\n",
      "Epoch 96/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4272 - val_loss: 0.6726\n",
      "Epoch 97/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4300 - val_loss: 0.6977\n",
      "Epoch 98/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4137 - val_loss: 0.6779\n",
      "Epoch 99/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4129 - val_loss: 0.6890\n",
      "Epoch 100/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4288 - val_loss: 0.6810\n",
      "current time:  2024-06-28_19-11\n",
      "\n",
      "\n",
      "11:mean_squared_error-label_sub 24.4%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.7210 - val_loss: 0.7075\n",
      "Epoch 2/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6643 - val_loss: 0.6448\n",
      "Epoch 3/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6156 - val_loss: 0.6389\n",
      "Epoch 4/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6137 - val_loss: 0.6367\n",
      "Epoch 5/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5930 - val_loss: 0.6338\n",
      "Epoch 6/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5680 - val_loss: 0.6632\n",
      "Epoch 7/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5608 - val_loss: 0.6578\n",
      "Epoch 8/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5372 - val_loss: 0.6421\n",
      "Epoch 9/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5297 - val_loss: 0.6367\n",
      "Epoch 10/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5353 - val_loss: 0.6560\n",
      "Epoch 11/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5118 - val_loss: 0.6577\n",
      "Epoch 12/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5071 - val_loss: 0.6731\n",
      "Epoch 13/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4975 - val_loss: 0.6491\n",
      "Epoch 14/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5073 - val_loss: 0.6590\n",
      "Epoch 15/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4952 - val_loss: 0.6578\n",
      "Epoch 16/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4864 - val_loss: 0.6671\n",
      "Epoch 17/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4701 - val_loss: 0.6789\n",
      "Epoch 18/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4951 - val_loss: 0.6685\n",
      "Epoch 19/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4726 - val_loss: 0.6548\n",
      "Epoch 20/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4650 - val_loss: 0.7038\n",
      "Epoch 21/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4798 - val_loss: 0.6635\n",
      "Epoch 22/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4619 - val_loss: 0.6680\n",
      "Epoch 23/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4613 - val_loss: 0.6643\n",
      "Epoch 24/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4694 - val_loss: 0.6585\n",
      "Epoch 25/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4489 - val_loss: 0.6761\n",
      "Epoch 26/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4575 - val_loss: 0.6645\n",
      "Epoch 27/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4479 - val_loss: 0.6810\n",
      "Epoch 28/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4633 - val_loss: 0.6785\n",
      "Epoch 29/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4537 - val_loss: 0.6861\n",
      "Epoch 30/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4522 - val_loss: 0.6910\n",
      "Epoch 31/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4593 - val_loss: 0.6968\n",
      "Epoch 32/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4513 - val_loss: 0.6754\n",
      "Epoch 33/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4519 - val_loss: 0.6865\n",
      "Epoch 34/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4517 - val_loss: 0.6741\n",
      "Epoch 35/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4480 - val_loss: 0.6887\n",
      "Epoch 36/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4425 - val_loss: 0.6724\n",
      "Epoch 37/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4448 - val_loss: 0.6733\n",
      "Epoch 38/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4461 - val_loss: 0.6782\n",
      "Epoch 39/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4366 - val_loss: 0.7142\n",
      "Epoch 40/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4532 - val_loss: 0.6957\n",
      "Epoch 41/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4475 - val_loss: 0.6996\n",
      "Epoch 42/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4464 - val_loss: 0.6879\n",
      "Epoch 43/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4532 - val_loss: 0.6849\n",
      "Epoch 44/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4446 - val_loss: 0.6802\n",
      "Epoch 45/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4445 - val_loss: 0.6945\n",
      "Epoch 46/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4391 - val_loss: 0.6885\n",
      "Epoch 47/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4396 - val_loss: 0.6873\n",
      "Epoch 48/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4319 - val_loss: 0.7034\n",
      "Epoch 49/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4447 - val_loss: 0.6757\n",
      "Epoch 50/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4344 - val_loss: 0.6823\n",
      "Epoch 51/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4310 - val_loss: 0.6800\n",
      "Epoch 52/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4358 - val_loss: 0.6837\n",
      "Epoch 53/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4257 - val_loss: 0.6903\n",
      "Epoch 54/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4294 - val_loss: 0.6864\n",
      "Epoch 55/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4300 - val_loss: 0.6767\n",
      "Epoch 56/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4254 - val_loss: 0.7105\n",
      "Epoch 57/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4333 - val_loss: 0.7010\n",
      "Epoch 58/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4356 - val_loss: 0.6970\n",
      "Epoch 59/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4383 - val_loss: 0.7024\n",
      "Epoch 60/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4362 - val_loss: 0.6902\n",
      "Epoch 61/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4281 - val_loss: 0.7100\n",
      "Epoch 62/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4393 - val_loss: 0.7042\n",
      "Epoch 63/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4290 - val_loss: 0.6735\n",
      "Epoch 64/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4360 - val_loss: 0.6864\n",
      "Epoch 65/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4187 - val_loss: 0.6953\n",
      "Epoch 66/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4404 - val_loss: 0.7019\n",
      "Epoch 67/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4298 - val_loss: 0.7325\n",
      "Epoch 68/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4107 - val_loss: 0.7071\n",
      "Epoch 69/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4246 - val_loss: 0.6943\n",
      "Epoch 70/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4235 - val_loss: 0.6764\n",
      "Epoch 71/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4316 - val_loss: 0.7169\n",
      "Epoch 72/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4280 - val_loss: 0.6962\n",
      "Epoch 73/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4178 - val_loss: 0.6979\n",
      "Epoch 74/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4368 - val_loss: 0.6890\n",
      "Epoch 75/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4315 - val_loss: 0.7201\n",
      "Epoch 76/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4335 - val_loss: 0.6839\n",
      "Epoch 77/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4288 - val_loss: 0.7000\n",
      "Epoch 78/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4283 - val_loss: 0.7073\n",
      "Epoch 79/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4293 - val_loss: 0.7044\n",
      "Epoch 80/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4243 - val_loss: 0.6969\n",
      "Epoch 81/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4315 - val_loss: 0.6996\n",
      "Epoch 82/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4157 - val_loss: 0.6839\n",
      "Epoch 83/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4196 - val_loss: 0.6740\n",
      "Epoch 84/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4150 - val_loss: 0.6956\n",
      "Epoch 85/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4184 - val_loss: 0.6978\n",
      "Epoch 86/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4227 - val_loss: 0.6841\n",
      "Epoch 87/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4279 - val_loss: 0.6965\n",
      "Epoch 88/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4160 - val_loss: 0.7045\n",
      "Epoch 89/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4086 - val_loss: 0.6956\n",
      "Epoch 90/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4192 - val_loss: 0.6841\n",
      "Epoch 91/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4295 - val_loss: 0.6931\n",
      "Epoch 92/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4091 - val_loss: 0.7143\n",
      "Epoch 93/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4198 - val_loss: 0.7140\n",
      "Epoch 94/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4118 - val_loss: 0.7181\n",
      "Epoch 95/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4323 - val_loss: 0.7123\n",
      "Epoch 96/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4361 - val_loss: 0.6959\n",
      "Epoch 97/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4180 - val_loss: 0.7141\n",
      "Epoch 98/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4319 - val_loss: 0.6904\n",
      "Epoch 99/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4347 - val_loss: 0.7189\n",
      "Epoch 100/100\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4149 - val_loss: 0.7218\n",
      "current time:  2024-06-28_19-13\n",
      "\n",
      "\n",
      "12:mean_squared_error-label_sub 26.7%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7176 - val_loss: 0.6640\n",
      "Epoch 2/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6584 - val_loss: 0.6457\n",
      "Epoch 3/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6237 - val_loss: 0.6630\n",
      "Epoch 4/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6091 - val_loss: 0.6429\n",
      "Epoch 5/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5742 - val_loss: 0.6484\n",
      "Epoch 6/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5595 - val_loss: 0.6564\n",
      "Epoch 7/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5496 - val_loss: 0.6535\n",
      "Epoch 8/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5490 - val_loss: 0.6498\n",
      "Epoch 9/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5377 - val_loss: 0.6606\n",
      "Epoch 10/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5354 - val_loss: 0.6597\n",
      "Epoch 11/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5266 - val_loss: 0.6528\n",
      "Epoch 12/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5245 - val_loss: 0.6857\n",
      "Epoch 13/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5114 - val_loss: 0.6606\n",
      "Epoch 14/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5221 - val_loss: 0.6567\n",
      "Epoch 15/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5206 - val_loss: 0.6621\n",
      "Epoch 16/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4929 - val_loss: 0.6650\n",
      "Epoch 17/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5027 - val_loss: 0.6510\n",
      "Epoch 18/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5039 - val_loss: 0.6883\n",
      "Epoch 19/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5068 - val_loss: 0.6782\n",
      "Epoch 20/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4986 - val_loss: 0.6777\n",
      "Epoch 21/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4981 - val_loss: 0.6608\n",
      "Epoch 22/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4814 - val_loss: 0.6683\n",
      "Epoch 23/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4848 - val_loss: 0.6705\n",
      "Epoch 24/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4777 - val_loss: 0.6630\n",
      "Epoch 25/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4712 - val_loss: 0.6761\n",
      "Epoch 26/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4675 - val_loss: 0.6938\n",
      "Epoch 27/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4880 - val_loss: 0.6842\n",
      "Epoch 28/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4876 - val_loss: 0.6720\n",
      "Epoch 29/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4612 - val_loss: 0.6901\n",
      "Epoch 30/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4822 - val_loss: 0.6585\n",
      "Epoch 31/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4672 - val_loss: 0.6766\n",
      "Epoch 32/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4594 - val_loss: 0.6821\n",
      "Epoch 33/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4577 - val_loss: 0.6812\n",
      "Epoch 34/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4717 - val_loss: 0.6812\n",
      "Epoch 35/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4658 - val_loss: 0.6997\n",
      "Epoch 36/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4574 - val_loss: 0.6869\n",
      "Epoch 37/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4668 - val_loss: 0.6905\n",
      "Epoch 38/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4594 - val_loss: 0.6902\n",
      "Epoch 39/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4515 - val_loss: 0.6890\n",
      "Epoch 40/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4498 - val_loss: 0.6912\n",
      "Epoch 41/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4519 - val_loss: 0.6791\n",
      "Epoch 42/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4539 - val_loss: 0.6835\n",
      "Epoch 43/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4502 - val_loss: 0.6844\n",
      "Epoch 44/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4484 - val_loss: 0.6886\n",
      "Epoch 45/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4581 - val_loss: 0.7076\n",
      "Epoch 46/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4382 - val_loss: 0.7123\n",
      "Epoch 47/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4454 - val_loss: 0.6731\n",
      "Epoch 48/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4481 - val_loss: 0.6940\n",
      "Epoch 49/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4407 - val_loss: 0.7094\n",
      "Epoch 50/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4436 - val_loss: 0.7013\n",
      "Epoch 51/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4608 - val_loss: 0.7040\n",
      "Epoch 52/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4484 - val_loss: 0.6920\n",
      "Epoch 53/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4586 - val_loss: 0.6954\n",
      "Epoch 54/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4412 - val_loss: 0.6852\n",
      "Epoch 55/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4472 - val_loss: 0.7055\n",
      "Epoch 56/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4480 - val_loss: 0.6927\n",
      "Epoch 57/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4479 - val_loss: 0.6891\n",
      "Epoch 58/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4451 - val_loss: 0.6943\n",
      "Epoch 59/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4432 - val_loss: 0.6927\n",
      "Epoch 60/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4401 - val_loss: 0.6889\n",
      "Epoch 61/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4453 - val_loss: 0.6852\n",
      "Epoch 62/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4633 - val_loss: 0.6885\n",
      "Epoch 63/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4467 - val_loss: 0.6851\n",
      "Epoch 64/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4404 - val_loss: 0.6861\n",
      "Epoch 65/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4347 - val_loss: 0.7137\n",
      "Epoch 66/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4351 - val_loss: 0.7035\n",
      "Epoch 67/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4463 - val_loss: 0.7003\n",
      "Epoch 68/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4488 - val_loss: 0.6908\n",
      "Epoch 69/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4427 - val_loss: 0.7052\n",
      "Epoch 70/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4507 - val_loss: 0.6854\n",
      "Epoch 71/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4361 - val_loss: 0.7028\n",
      "Epoch 72/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4530 - val_loss: 0.6923\n",
      "Epoch 73/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4293 - val_loss: 0.6825\n",
      "Epoch 74/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4368 - val_loss: 0.7031\n",
      "Epoch 75/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4417 - val_loss: 0.7059\n",
      "Epoch 76/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4341 - val_loss: 0.6926\n",
      "Epoch 77/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4431 - val_loss: 0.6851\n",
      "Epoch 78/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4358 - val_loss: 0.6982\n",
      "Epoch 79/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4353 - val_loss: 0.6931\n",
      "Epoch 80/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4356 - val_loss: 0.6999\n",
      "Epoch 81/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4438 - val_loss: 0.7092\n",
      "Epoch 82/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4519 - val_loss: 0.6981\n",
      "Epoch 83/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4390 - val_loss: 0.6953\n",
      "Epoch 84/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4257 - val_loss: 0.7005\n",
      "Epoch 85/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4351 - val_loss: 0.7045\n",
      "Epoch 86/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4425 - val_loss: 0.7055\n",
      "Epoch 87/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4351 - val_loss: 0.6869\n",
      "Epoch 88/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4351 - val_loss: 0.6936\n",
      "Epoch 89/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4243 - val_loss: 0.6828\n",
      "Epoch 90/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4239 - val_loss: 0.6972\n",
      "Epoch 91/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4324 - val_loss: 0.6934\n",
      "Epoch 92/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4221 - val_loss: 0.7040\n",
      "Epoch 93/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4404 - val_loss: 0.7020\n",
      "Epoch 94/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4373 - val_loss: 0.6973\n",
      "Epoch 95/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4447 - val_loss: 0.6898\n",
      "Epoch 96/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4350 - val_loss: 0.7047\n",
      "Epoch 97/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4321 - val_loss: 0.7048\n",
      "Epoch 98/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4262 - val_loss: 0.7066\n",
      "Epoch 99/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4300 - val_loss: 0.7005\n",
      "Epoch 100/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4313 - val_loss: 0.7048\n",
      "current time:  2024-06-28_19-13\n",
      "\n",
      "\n",
      "13:mean_squared_error-label_sub 28.9%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.7350 - val_loss: 0.6499\n",
      "Epoch 2/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6495 - val_loss: 0.6516\n",
      "Epoch 3/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6188 - val_loss: 0.6471\n",
      "Epoch 4/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5926 - val_loss: 0.6523\n",
      "Epoch 5/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5582 - val_loss: 0.6395\n",
      "Epoch 6/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5689 - val_loss: 0.6442\n",
      "Epoch 7/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5495 - val_loss: 0.6399\n",
      "Epoch 8/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5339 - val_loss: 0.6510\n",
      "Epoch 9/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5255 - val_loss: 0.6479\n",
      "Epoch 10/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5155 - val_loss: 0.6481\n",
      "Epoch 11/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5056 - val_loss: 0.6574\n",
      "Epoch 12/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4880 - val_loss: 0.6649\n",
      "Epoch 13/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5100 - val_loss: 0.6592\n",
      "Epoch 14/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4763 - val_loss: 0.6510\n",
      "Epoch 15/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4952 - val_loss: 0.6774\n",
      "Epoch 16/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5058 - val_loss: 0.6652\n",
      "Epoch 17/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4835 - val_loss: 0.6669\n",
      "Epoch 18/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4810 - val_loss: 0.6575\n",
      "Epoch 19/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4817 - val_loss: 0.6581\n",
      "Epoch 20/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4635 - val_loss: 0.6625\n",
      "Epoch 21/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4773 - val_loss: 0.6606\n",
      "Epoch 22/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4660 - val_loss: 0.6827\n",
      "Epoch 23/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4651 - val_loss: 0.6627\n",
      "Epoch 24/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4654 - val_loss: 0.6712\n",
      "Epoch 25/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4592 - val_loss: 0.6680\n",
      "Epoch 26/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4556 - val_loss: 0.6784\n",
      "Epoch 27/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4753 - val_loss: 0.6687\n",
      "Epoch 28/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4546 - val_loss: 0.6729\n",
      "Epoch 29/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4533 - val_loss: 0.6741\n",
      "Epoch 30/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4573 - val_loss: 0.6798\n",
      "Epoch 31/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4501 - val_loss: 0.6647\n",
      "Epoch 32/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4520 - val_loss: 0.6586\n",
      "Epoch 33/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4675 - val_loss: 0.6790\n",
      "Epoch 34/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4694 - val_loss: 0.6864\n",
      "Epoch 35/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4568 - val_loss: 0.6787\n",
      "Epoch 36/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4440 - val_loss: 0.6807\n",
      "Epoch 37/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4502 - val_loss: 0.6670\n",
      "Epoch 38/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4477 - val_loss: 0.6822\n",
      "Epoch 39/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4515 - val_loss: 0.6856\n",
      "Epoch 40/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4485 - val_loss: 0.6775\n",
      "Epoch 41/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4338 - val_loss: 0.6874\n",
      "Epoch 42/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4618 - val_loss: 0.6726\n",
      "Epoch 43/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4349 - val_loss: 0.6741\n",
      "Epoch 44/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4338 - val_loss: 0.6931\n",
      "Epoch 45/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4427 - val_loss: 0.6824\n",
      "Epoch 46/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4351 - val_loss: 0.6858\n",
      "Epoch 47/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4488 - val_loss: 0.6830\n",
      "Epoch 48/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4329 - val_loss: 0.6735\n",
      "Epoch 49/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4381 - val_loss: 0.6809\n",
      "Epoch 50/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4348 - val_loss: 0.6799\n",
      "Epoch 51/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4371 - val_loss: 0.6752\n",
      "Epoch 52/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4331 - val_loss: 0.6752\n",
      "Epoch 53/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4258 - val_loss: 0.6708\n",
      "Epoch 54/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4305 - val_loss: 0.6811\n",
      "Epoch 55/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4493 - val_loss: 0.6741\n",
      "Epoch 56/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4358 - val_loss: 0.6759\n",
      "Epoch 57/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4404 - val_loss: 0.6927\n",
      "Epoch 58/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4483 - val_loss: 0.6810\n",
      "Epoch 59/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4274 - val_loss: 0.6638\n",
      "Epoch 60/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4374 - val_loss: 0.6829\n",
      "Epoch 61/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4349 - val_loss: 0.6813\n",
      "Epoch 62/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4171 - val_loss: 0.6821\n",
      "Epoch 63/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4236 - val_loss: 0.7013\n",
      "Epoch 64/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4296 - val_loss: 0.6676\n",
      "Epoch 65/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4288 - val_loss: 0.6905\n",
      "Epoch 66/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4312 - val_loss: 0.7067\n",
      "Epoch 67/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4414 - val_loss: 0.6695\n",
      "Epoch 68/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4276 - val_loss: 0.6818\n",
      "Epoch 69/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4208 - val_loss: 0.6808\n",
      "Epoch 70/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4388 - val_loss: 0.6758\n",
      "Epoch 71/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4284 - val_loss: 0.6787\n",
      "Epoch 72/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4417 - val_loss: 0.6664\n",
      "Epoch 73/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4284 - val_loss: 0.6771\n",
      "Epoch 74/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4310 - val_loss: 0.6730\n",
      "Epoch 75/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4297 - val_loss: 0.6829\n",
      "Epoch 76/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4311 - val_loss: 0.6788\n",
      "Epoch 77/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4396 - val_loss: 0.6702\n",
      "Epoch 78/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4357 - val_loss: 0.6866\n",
      "Epoch 79/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4332 - val_loss: 0.6853\n",
      "Epoch 80/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4315 - val_loss: 0.6794\n",
      "Epoch 81/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4218 - val_loss: 0.6985\n",
      "Epoch 82/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4389 - val_loss: 0.6718\n",
      "Epoch 83/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4308 - val_loss: 0.6710\n",
      "Epoch 84/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4289 - val_loss: 0.6782\n",
      "Epoch 85/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4244 - val_loss: 0.6759\n",
      "Epoch 86/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4191 - val_loss: 0.6895\n",
      "Epoch 87/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4311 - val_loss: 0.6927\n",
      "Epoch 88/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4181 - val_loss: 0.6750\n",
      "Epoch 89/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4268 - val_loss: 0.6884\n",
      "Epoch 90/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4428 - val_loss: 0.6806\n",
      "Epoch 91/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4268 - val_loss: 0.6773\n",
      "Epoch 92/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4338 - val_loss: 0.6857\n",
      "Epoch 93/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4238 - val_loss: 0.6818\n",
      "Epoch 94/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4321 - val_loss: 0.6701\n",
      "Epoch 95/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4330 - val_loss: 0.6793\n",
      "Epoch 96/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4327 - val_loss: 0.6784\n",
      "Epoch 97/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4256 - val_loss: 0.6903\n",
      "Epoch 98/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4197 - val_loss: 0.6898\n",
      "Epoch 99/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4207 - val_loss: 0.6812\n",
      "Epoch 100/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4216 - val_loss: 0.6735\n",
      "current time:  2024-06-28_19-14\n",
      "\n",
      "\n",
      "14:mean_squared_error-label_sub 31.1%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.7359 - val_loss: 0.6764\n",
      "Epoch 2/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6718 - val_loss: 0.6656\n",
      "Epoch 3/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6134 - val_loss: 0.6501\n",
      "Epoch 4/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5854 - val_loss: 0.6402\n",
      "Epoch 5/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5710 - val_loss: 0.6283\n",
      "Epoch 6/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5573 - val_loss: 0.6536\n",
      "Epoch 7/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5502 - val_loss: 0.6465\n",
      "Epoch 8/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5514 - val_loss: 0.6482\n",
      "Epoch 9/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5488 - val_loss: 0.6526\n",
      "Epoch 10/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5237 - val_loss: 0.6504\n",
      "Epoch 11/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5088 - val_loss: 0.6404\n",
      "Epoch 12/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5160 - val_loss: 0.6481\n",
      "Epoch 13/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4998 - val_loss: 0.6637\n",
      "Epoch 14/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5137 - val_loss: 0.6642\n",
      "Epoch 15/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5123 - val_loss: 0.6454\n",
      "Epoch 16/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4817 - val_loss: 0.6508\n",
      "Epoch 17/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4921 - val_loss: 0.6596\n",
      "Epoch 18/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4753 - val_loss: 0.6753\n",
      "Epoch 19/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4656 - val_loss: 0.6543\n",
      "Epoch 20/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4780 - val_loss: 0.6696\n",
      "Epoch 21/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4749 - val_loss: 0.6475\n",
      "Epoch 22/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4542 - val_loss: 0.6721\n",
      "Epoch 23/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4633 - val_loss: 0.6584\n",
      "Epoch 24/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4808 - val_loss: 0.6703\n",
      "Epoch 25/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4632 - val_loss: 0.6351\n",
      "Epoch 26/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4568 - val_loss: 0.6644\n",
      "Epoch 27/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4498 - val_loss: 0.6679\n",
      "Epoch 28/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4642 - val_loss: 0.6578\n",
      "Epoch 29/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4631 - val_loss: 0.6694\n",
      "Epoch 30/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4554 - val_loss: 0.6592\n",
      "Epoch 31/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4541 - val_loss: 0.6599\n",
      "Epoch 32/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4476 - val_loss: 0.6617\n",
      "Epoch 33/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4392 - val_loss: 0.6682\n",
      "Epoch 34/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4456 - val_loss: 0.6856\n",
      "Epoch 35/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4481 - val_loss: 0.6737\n",
      "Epoch 36/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4488 - val_loss: 0.6559\n",
      "Epoch 37/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4444 - val_loss: 0.6948\n",
      "Epoch 38/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4484 - val_loss: 0.6825\n",
      "Epoch 39/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4484 - val_loss: 0.6826\n",
      "Epoch 40/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4341 - val_loss: 0.6925\n",
      "Epoch 41/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4438 - val_loss: 0.6590\n",
      "Epoch 42/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4359 - val_loss: 0.6661\n",
      "Epoch 43/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4298 - val_loss: 0.6735\n",
      "Epoch 44/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4378 - val_loss: 0.6740\n",
      "Epoch 45/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4359 - val_loss: 0.6719\n",
      "Epoch 46/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4438 - val_loss: 0.6773\n",
      "Epoch 47/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4310 - val_loss: 0.7220\n",
      "Epoch 48/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4438 - val_loss: 0.6758\n",
      "Epoch 49/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4288 - val_loss: 0.6869\n",
      "Epoch 50/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4322 - val_loss: 0.6922\n",
      "Epoch 51/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4385 - val_loss: 0.6808\n",
      "Epoch 52/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4256 - val_loss: 0.6818\n",
      "Epoch 53/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4371 - val_loss: 0.6792\n",
      "Epoch 54/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4267 - val_loss: 0.6757\n",
      "Epoch 55/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4352 - val_loss: 0.6704\n",
      "Epoch 56/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4300 - val_loss: 0.6666\n",
      "Epoch 57/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4310 - val_loss: 0.6927\n",
      "Epoch 58/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4324 - val_loss: 0.6835\n",
      "Epoch 59/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4344 - val_loss: 0.6770\n",
      "Epoch 60/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4283 - val_loss: 0.6701\n",
      "Epoch 61/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4381 - val_loss: 0.6760\n",
      "Epoch 62/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4227 - val_loss: 0.6966\n",
      "Epoch 63/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4231 - val_loss: 0.6796\n",
      "Epoch 64/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4276 - val_loss: 0.6757\n",
      "Epoch 65/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4294 - val_loss: 0.6817\n",
      "Epoch 66/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4214 - val_loss: 0.6621\n",
      "Epoch 67/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4283 - val_loss: 0.6693\n",
      "Epoch 68/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4366 - val_loss: 0.6859\n",
      "Epoch 69/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4234 - val_loss: 0.6761\n",
      "Epoch 70/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4196 - val_loss: 0.6920\n",
      "Epoch 71/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4318 - val_loss: 0.7034\n",
      "Epoch 72/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4180 - val_loss: 0.6874\n",
      "Epoch 73/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4299 - val_loss: 0.6933\n",
      "Epoch 74/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4196 - val_loss: 0.6833\n",
      "Epoch 75/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4250 - val_loss: 0.6843\n",
      "Epoch 76/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4158 - val_loss: 0.6894\n",
      "Epoch 77/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4130 - val_loss: 0.6778\n",
      "Epoch 78/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4259 - val_loss: 0.6897\n",
      "Epoch 79/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4283 - val_loss: 0.6920\n",
      "Epoch 80/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4109 - val_loss: 0.6933\n",
      "Epoch 81/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4202 - val_loss: 0.6839\n",
      "Epoch 82/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4264 - val_loss: 0.6803\n",
      "Epoch 83/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4300 - val_loss: 0.6732\n",
      "Epoch 84/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4223 - val_loss: 0.6903\n",
      "Epoch 85/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4220 - val_loss: 0.6920\n",
      "Epoch 86/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4254 - val_loss: 0.7017\n",
      "Epoch 87/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4292 - val_loss: 0.6826\n",
      "Epoch 88/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4107 - val_loss: 0.7043\n",
      "Epoch 89/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4204 - val_loss: 0.6867\n",
      "Epoch 90/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4055 - val_loss: 0.6827\n",
      "Epoch 91/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4182 - val_loss: 0.6937\n",
      "Epoch 92/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4065 - val_loss: 0.6844\n",
      "Epoch 93/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4266 - val_loss: 0.7121\n",
      "Epoch 94/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4283 - val_loss: 0.6903\n",
      "Epoch 95/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4041 - val_loss: 0.6996\n",
      "Epoch 96/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4133 - val_loss: 0.6964\n",
      "Epoch 97/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4312 - val_loss: 0.6901\n",
      "Epoch 98/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4261 - val_loss: 0.7024\n",
      "Epoch 99/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4110 - val_loss: 0.6989\n",
      "Epoch 100/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4312 - val_loss: 0.6939\n",
      "current time:  2024-06-28_19-14\n",
      "\n",
      "\n",
      "15:mean_squared_error-label_sub 33.3%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.7635 - val_loss: 0.6763\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7063 - val_loss: 0.6663\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6785 - val_loss: 0.6623\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6538 - val_loss: 0.6568\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6472 - val_loss: 0.6512\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5840 - val_loss: 0.6518\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5705 - val_loss: 0.6588\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5782 - val_loss: 0.6618\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5617 - val_loss: 0.6591\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5482 - val_loss: 0.6548\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5349 - val_loss: 0.6613\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5399 - val_loss: 0.6784\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5330 - val_loss: 0.6681\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5293 - val_loss: 0.6685\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5146 - val_loss: 0.6660\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5183 - val_loss: 0.6707\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5114 - val_loss: 0.6750\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5223 - val_loss: 0.6673\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4896 - val_loss: 0.6792\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5131 - val_loss: 0.6718\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4819 - val_loss: 0.6793\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5021 - val_loss: 0.6747\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4871 - val_loss: 0.6773\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4876 - val_loss: 0.6856\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4857 - val_loss: 0.6772\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4958 - val_loss: 0.6870\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4816 - val_loss: 0.6855\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4710 - val_loss: 0.6844\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4719 - val_loss: 0.6858\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4599 - val_loss: 0.6867\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4654 - val_loss: 0.6926\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4766 - val_loss: 0.6897\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4720 - val_loss: 0.6879\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4726 - val_loss: 0.6900\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4660 - val_loss: 0.6894\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4647 - val_loss: 0.6889\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4532 - val_loss: 0.6980\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4567 - val_loss: 0.7030\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4647 - val_loss: 0.6956\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4535 - val_loss: 0.6966\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4645 - val_loss: 0.7122\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4648 - val_loss: 0.7088\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4617 - val_loss: 0.7014\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4529 - val_loss: 0.7063\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4607 - val_loss: 0.7050\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4426 - val_loss: 0.7073\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4489 - val_loss: 0.7032\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4524 - val_loss: 0.7046\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4447 - val_loss: 0.7056\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4554 - val_loss: 0.7095\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4459 - val_loss: 0.6924\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4353 - val_loss: 0.6940\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4456 - val_loss: 0.7039\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4533 - val_loss: 0.7041\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4457 - val_loss: 0.7024\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4337 - val_loss: 0.7174\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4503 - val_loss: 0.7254\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4561 - val_loss: 0.7019\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4551 - val_loss: 0.7129\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4329 - val_loss: 0.7059\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4500 - val_loss: 0.7081\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4381 - val_loss: 0.7160\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4421 - val_loss: 0.7041\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4340 - val_loss: 0.7097\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4346 - val_loss: 0.7021\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4488 - val_loss: 0.7083\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4334 - val_loss: 0.7154\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4401 - val_loss: 0.6961\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4398 - val_loss: 0.7111\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4405 - val_loss: 0.7169\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4387 - val_loss: 0.7131\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4213 - val_loss: 0.7081\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4418 - val_loss: 0.7155\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4379 - val_loss: 0.7131\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4377 - val_loss: 0.7023\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4328 - val_loss: 0.7133\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4403 - val_loss: 0.7133\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4385 - val_loss: 0.7169\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4330 - val_loss: 0.7142\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4401 - val_loss: 0.7255\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4250 - val_loss: 0.7122\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4421 - val_loss: 0.7184\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4350 - val_loss: 0.7285\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4330 - val_loss: 0.7121\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4464 - val_loss: 0.7079\n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4261 - val_loss: 0.7017\n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4369 - val_loss: 0.7131\n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4242 - val_loss: 0.7091\n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4168 - val_loss: 0.7161\n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4371 - val_loss: 0.7202\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4387 - val_loss: 0.7209\n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4407 - val_loss: 0.7190\n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4309 - val_loss: 0.7158\n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4221 - val_loss: 0.7204\n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4317 - val_loss: 0.7182\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4141 - val_loss: 0.7219\n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4235 - val_loss: 0.7098\n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4293 - val_loss: 0.7215\n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4069 - val_loss: 0.7120\n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4329 - val_loss: 0.7227\n",
      "current time:  2024-06-28_19-14\n",
      "\n",
      "\n",
      "16:mean_squared_error-label_sub 35.6%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.7770 - val_loss: 0.6824\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6941 - val_loss: 0.6601\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6696 - val_loss: 0.6519\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6338 - val_loss: 0.6432\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6099 - val_loss: 0.6490\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5990 - val_loss: 0.6407\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5877 - val_loss: 0.6608\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5663 - val_loss: 0.6654\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5622 - val_loss: 0.6450\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5556 - val_loss: 0.6414\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5384 - val_loss: 0.6526\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5444 - val_loss: 0.6604\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5228 - val_loss: 0.6455\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5129 - val_loss: 0.6561\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5066 - val_loss: 0.6498\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5067 - val_loss: 0.6444\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5062 - val_loss: 0.6556\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5063 - val_loss: 0.6633\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4925 - val_loss: 0.6693\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5094 - val_loss: 0.6571\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4989 - val_loss: 0.6437\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4880 - val_loss: 0.6677\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4750 - val_loss: 0.6626\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4944 - val_loss: 0.6759\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4670 - val_loss: 0.6714\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4740 - val_loss: 0.6739\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4746 - val_loss: 0.6645\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4721 - val_loss: 0.6687\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4656 - val_loss: 0.6692\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4713 - val_loss: 0.6701\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4629 - val_loss: 0.6609\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4669 - val_loss: 0.6690\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4552 - val_loss: 0.6726\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4666 - val_loss: 0.6779\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4406 - val_loss: 0.6752\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4540 - val_loss: 0.6817\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4520 - val_loss: 0.6874\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4440 - val_loss: 0.6693\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4681 - val_loss: 0.6967\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4569 - val_loss: 0.6612\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4448 - val_loss: 0.6705\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4614 - val_loss: 0.6816\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4566 - val_loss: 0.6920\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4538 - val_loss: 0.6775\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4453 - val_loss: 0.6856\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4577 - val_loss: 0.6765\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4510 - val_loss: 0.6756\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4423 - val_loss: 0.6860\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4401 - val_loss: 0.6861\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4323 - val_loss: 0.6924\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4435 - val_loss: 0.6807\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4458 - val_loss: 0.6905\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4364 - val_loss: 0.6819\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4285 - val_loss: 0.6792\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4414 - val_loss: 0.6993\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4453 - val_loss: 0.6872\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4403 - val_loss: 0.6831\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4257 - val_loss: 0.6814\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4256 - val_loss: 0.6945\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4249 - val_loss: 0.7029\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4520 - val_loss: 0.6789\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4364 - val_loss: 0.6815\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4241 - val_loss: 0.6780\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4369 - val_loss: 0.6880\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4256 - val_loss: 0.6798\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4336 - val_loss: 0.6722\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4449 - val_loss: 0.6810\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4481 - val_loss: 0.6693\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4346 - val_loss: 0.6736\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4344 - val_loss: 0.6846\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4216 - val_loss: 0.6963\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4335 - val_loss: 0.6740\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4286 - val_loss: 0.6774\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4261 - val_loss: 0.6906\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4295 - val_loss: 0.6765\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4314 - val_loss: 0.6848\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4399 - val_loss: 0.6807\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4300 - val_loss: 0.6946\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4247 - val_loss: 0.6864\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4350 - val_loss: 0.7005\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4369 - val_loss: 0.6829\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4213 - val_loss: 0.6963\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4338 - val_loss: 0.6782\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4281 - val_loss: 0.6729\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4207 - val_loss: 0.6789\n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4088 - val_loss: 0.6847\n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4179 - val_loss: 0.6842\n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4334 - val_loss: 0.6877\n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4246 - val_loss: 0.6920\n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4282 - val_loss: 0.6771\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4150 - val_loss: 0.6792\n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4335 - val_loss: 0.6737\n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4322 - val_loss: 0.6775\n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4226 - val_loss: 0.6807\n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4281 - val_loss: 0.6790\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4403 - val_loss: 0.6754\n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4316 - val_loss: 0.6730\n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4300 - val_loss: 0.6711\n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4226 - val_loss: 0.6826\n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4328 - val_loss: 0.6911\n",
      "current time:  2024-06-28_19-14\n",
      "\n",
      "\n",
      "17:mean_squared_error-label_sub 37.8%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.7700 - val_loss: 0.6713\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7056 - val_loss: 0.6715\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6498 - val_loss: 0.6649\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6210 - val_loss: 0.6589\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5862 - val_loss: 0.6419\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5664 - val_loss: 0.6687\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5716 - val_loss: 0.6520\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5532 - val_loss: 0.6682\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5414 - val_loss: 0.6579\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5321 - val_loss: 0.6389\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5269 - val_loss: 0.6553\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5101 - val_loss: 0.6590\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5226 - val_loss: 0.6557\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5015 - val_loss: 0.6621\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4926 - val_loss: 0.6578\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5098 - val_loss: 0.6507\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4862 - val_loss: 0.6496\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4763 - val_loss: 0.6547\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4938 - val_loss: 0.6523\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4841 - val_loss: 0.6713\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4722 - val_loss: 0.6567\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4520 - val_loss: 0.6676\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4605 - val_loss: 0.6735\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4863 - val_loss: 0.6573\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4613 - val_loss: 0.6749\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4716 - val_loss: 0.6627\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4558 - val_loss: 0.6708\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4571 - val_loss: 0.6694\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4531 - val_loss: 0.6783\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4512 - val_loss: 0.6723\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4489 - val_loss: 0.6716\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4636 - val_loss: 0.6844\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4453 - val_loss: 0.6765\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4458 - val_loss: 0.6777\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4425 - val_loss: 0.6957\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4499 - val_loss: 0.6738\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4424 - val_loss: 0.6720\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4446 - val_loss: 0.6781\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4370 - val_loss: 0.7011\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4372 - val_loss: 0.6581\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4383 - val_loss: 0.6720\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4329 - val_loss: 0.6715\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4463 - val_loss: 0.6644\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4452 - val_loss: 0.6888\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4374 - val_loss: 0.6835\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4447 - val_loss: 0.6643\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4390 - val_loss: 0.6770\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4290 - val_loss: 0.6802\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4352 - val_loss: 0.6799\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4270 - val_loss: 0.6638\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4321 - val_loss: 0.6831\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4234 - val_loss: 0.6847\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4367 - val_loss: 0.6777\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4257 - val_loss: 0.6651\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4285 - val_loss: 0.6736\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4358 - val_loss: 0.6826\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4279 - val_loss: 0.6866\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4327 - val_loss: 0.6716\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4316 - val_loss: 0.6688\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4267 - val_loss: 0.6665\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4269 - val_loss: 0.6815\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4256 - val_loss: 0.6824\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4322 - val_loss: 0.6744\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4138 - val_loss: 0.6642\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4412 - val_loss: 0.6968\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4311 - val_loss: 0.6698\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4295 - val_loss: 0.6783\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4242 - val_loss: 0.6773\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4223 - val_loss: 0.6765\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4222 - val_loss: 0.6747\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4121 - val_loss: 0.6777\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4205 - val_loss: 0.6796\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4223 - val_loss: 0.6840\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4254 - val_loss: 0.6811\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4295 - val_loss: 0.6719\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4190 - val_loss: 0.6743\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4197 - val_loss: 0.6791\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4235 - val_loss: 0.6765\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4208 - val_loss: 0.6810\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4149 - val_loss: 0.6808\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4151 - val_loss: 0.6645\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4219 - val_loss: 0.6722\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4242 - val_loss: 0.6855\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4323 - val_loss: 0.6719\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4153 - val_loss: 0.6826\n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4129 - val_loss: 0.6815\n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4313 - val_loss: 0.6924\n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4305 - val_loss: 0.6852\n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4310 - val_loss: 0.6805\n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4220 - val_loss: 0.6774\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4063 - val_loss: 0.6918\n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4299 - val_loss: 0.6813\n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4256 - val_loss: 0.6803\n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4183 - val_loss: 0.6783\n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4156 - val_loss: 0.6823\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4082 - val_loss: 0.6885\n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4194 - val_loss: 0.6785\n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4256 - val_loss: 0.6753\n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4240 - val_loss: 0.6877\n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4231 - val_loss: 0.6930\n",
      "current time:  2024-06-28_19-15\n",
      "\n",
      "\n",
      "18:mean_squared_error-label_sub 40.0%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.7047 - val_loss: 0.6902\n",
      "Epoch 2/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.6336 - val_loss: 0.6849\n",
      "Epoch 3/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.5923 - val_loss: 0.6737\n",
      "Epoch 4/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.5889 - val_loss: 0.6850\n",
      "Epoch 5/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 0.5657 - val_loss: 0.6752\n",
      "Epoch 6/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.5491 - val_loss: 0.6571\n",
      "Epoch 7/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.5550 - val_loss: 0.6532\n",
      "Epoch 8/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5261 - val_loss: 0.6929\n",
      "Epoch 9/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.5403 - val_loss: 0.6845\n",
      "Epoch 10/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5164 - val_loss: 0.6771\n",
      "Epoch 11/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.5260 - val_loss: 0.6764\n",
      "Epoch 12/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5029 - val_loss: 0.6991\n",
      "Epoch 13/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5155 - val_loss: 0.6994\n",
      "Epoch 14/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4987 - val_loss: 0.7152\n",
      "Epoch 15/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.4985 - val_loss: 0.7069\n",
      "Epoch 16/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4848 - val_loss: 0.6937\n",
      "Epoch 17/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4807 - val_loss: 0.7162\n",
      "Epoch 18/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4946 - val_loss: 0.7072\n",
      "Epoch 19/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4766 - val_loss: 0.7036\n",
      "Epoch 20/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.4785 - val_loss: 0.7131\n",
      "Epoch 21/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4889 - val_loss: 0.6924\n",
      "Epoch 22/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4740 - val_loss: 0.7059\n",
      "Epoch 23/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4727 - val_loss: 0.7129\n",
      "Epoch 24/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4560 - val_loss: 0.7124\n",
      "Epoch 25/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4633 - val_loss: 0.7254\n",
      "Epoch 26/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.4724 - val_loss: 0.7273\n",
      "Epoch 27/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.4572 - val_loss: 0.7112\n",
      "Epoch 28/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.4640 - val_loss: 0.7090\n",
      "Epoch 29/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4669 - val_loss: 0.7174\n",
      "Epoch 30/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.4503 - val_loss: 0.7306\n",
      "Epoch 31/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.4717 - val_loss: 0.7091\n",
      "Epoch 32/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.4625 - val_loss: 0.7229\n",
      "Epoch 33/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.4685 - val_loss: 0.7285\n",
      "Epoch 34/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4495 - val_loss: 0.6885\n",
      "Epoch 35/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.4485 - val_loss: 0.7404\n",
      "Epoch 36/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.4639 - val_loss: 0.7307\n",
      "Epoch 37/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.4601 - val_loss: 0.7110\n",
      "Epoch 38/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4515 - val_loss: 0.7005\n",
      "Epoch 39/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4643 - val_loss: 0.7104\n",
      "Epoch 40/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.4538 - val_loss: 0.7256\n",
      "Epoch 41/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 0.4643 - val_loss: 0.7041\n",
      "Epoch 42/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.4455 - val_loss: 0.7095\n",
      "Epoch 43/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4546 - val_loss: 0.7126\n",
      "Epoch 44/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.4594 - val_loss: 0.7281\n",
      "Epoch 45/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4507 - val_loss: 0.7123\n",
      "Epoch 46/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.4565 - val_loss: 0.7347\n",
      "Epoch 47/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4514 - val_loss: 0.7223\n",
      "Epoch 48/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4616 - val_loss: 0.7203\n",
      "Epoch 49/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.4398 - val_loss: 0.7176\n",
      "Epoch 50/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.4521 - val_loss: 0.7195\n",
      "Epoch 51/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4585 - val_loss: 0.7261\n",
      "Epoch 52/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4395 - val_loss: 0.7286\n",
      "Epoch 53/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4588 - val_loss: 0.7059\n",
      "Epoch 54/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.4423 - val_loss: 0.7255\n",
      "Epoch 55/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.4408 - val_loss: 0.7280\n",
      "Epoch 56/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4569 - val_loss: 0.7215\n",
      "Epoch 57/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.4311 - val_loss: 0.7181\n",
      "Epoch 58/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.4415 - val_loss: 0.7381\n",
      "Epoch 59/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.4545 - val_loss: 0.7206\n",
      "Epoch 60/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.4518 - val_loss: 0.7255\n",
      "Epoch 61/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.4475 - val_loss: 0.7228\n",
      "Epoch 62/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4492 - val_loss: 0.7263\n",
      "Epoch 63/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.4336 - val_loss: 0.7187\n",
      "Epoch 64/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.4511 - val_loss: 0.7419\n",
      "Epoch 65/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.4346 - val_loss: 0.7067\n",
      "Epoch 66/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4428 - val_loss: 0.7263\n",
      "Epoch 67/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4475 - val_loss: 0.7340\n",
      "Epoch 68/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4388 - val_loss: 0.7348\n",
      "Epoch 69/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4448 - val_loss: 0.7223\n",
      "Epoch 70/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4461 - val_loss: 0.7328\n",
      "Epoch 71/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4418 - val_loss: 0.7326\n",
      "Epoch 72/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4438 - val_loss: 0.7510\n",
      "Epoch 73/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.4130 - val_loss: 0.7405\n",
      "Epoch 74/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4494 - val_loss: 0.7243\n",
      "Epoch 75/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.4324 - val_loss: 0.7384\n",
      "Epoch 76/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.4475 - val_loss: 0.7258\n",
      "Epoch 77/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.4304 - val_loss: 0.7183\n",
      "Epoch 78/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.4363 - val_loss: 0.7288\n",
      "Epoch 79/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4283 - val_loss: 0.7422\n",
      "Epoch 80/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4324 - val_loss: 0.7293\n",
      "Epoch 81/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4240 - val_loss: 0.7287\n",
      "Epoch 82/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4349 - val_loss: 0.7317\n",
      "Epoch 83/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4360 - val_loss: 0.7301\n",
      "Epoch 84/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4440 - val_loss: 0.7505\n",
      "Epoch 85/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4403 - val_loss: 0.7326\n",
      "Epoch 86/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.4394 - val_loss: 0.7211\n",
      "Epoch 87/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4350 - val_loss: 0.7376\n",
      "Epoch 88/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4355 - val_loss: 0.7336\n",
      "Epoch 89/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4400 - val_loss: 0.7312\n",
      "Epoch 90/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4407 - val_loss: 0.7357\n",
      "Epoch 91/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4414 - val_loss: 0.7133\n",
      "Epoch 92/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4153 - val_loss: 0.7381\n",
      "Epoch 93/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4291 - val_loss: 0.7409\n",
      "Epoch 94/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4271 - val_loss: 0.7201\n",
      "Epoch 95/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4248 - val_loss: 0.7231\n",
      "Epoch 96/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4247 - val_loss: 0.7360\n",
      "Epoch 97/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4320 - val_loss: 0.7364\n",
      "Epoch 98/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.4360 - val_loss: 0.7340\n",
      "Epoch 99/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4163 - val_loss: 0.7310\n",
      "Epoch 100/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4279 - val_loss: 0.7258\n",
      "current time:  2024-06-28_19-15\n",
      "\n",
      "\n",
      "19:mean_squared_error-label_sub 42.2%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.7314 - val_loss: 0.6885\n",
      "Epoch 2/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6409 - val_loss: 0.6801\n",
      "Epoch 3/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6117 - val_loss: 0.6578\n",
      "Epoch 4/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5834 - val_loss: 0.6791\n",
      "Epoch 5/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5634 - val_loss: 0.6629\n",
      "Epoch 6/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5536 - val_loss: 0.6741\n",
      "Epoch 7/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5506 - val_loss: 0.6961\n",
      "Epoch 8/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5321 - val_loss: 0.6799\n",
      "Epoch 9/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5354 - val_loss: 0.6985\n",
      "Epoch 10/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5111 - val_loss: 0.6927\n",
      "Epoch 11/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5259 - val_loss: 0.7331\n",
      "Epoch 12/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5047 - val_loss: 0.6958\n",
      "Epoch 13/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5084 - val_loss: 0.6976\n",
      "Epoch 14/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4911 - val_loss: 0.6962\n",
      "Epoch 15/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4783 - val_loss: 0.7271\n",
      "Epoch 16/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4905 - val_loss: 0.7325\n",
      "Epoch 17/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4928 - val_loss: 0.7229\n",
      "Epoch 18/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4747 - val_loss: 0.7330\n",
      "Epoch 19/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4655 - val_loss: 0.7134\n",
      "Epoch 20/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4829 - val_loss: 0.7119\n",
      "Epoch 21/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4696 - val_loss: 0.7153\n",
      "Epoch 22/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4860 - val_loss: 0.7242\n",
      "Epoch 23/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4682 - val_loss: 0.7453\n",
      "Epoch 24/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4511 - val_loss: 0.7404\n",
      "Epoch 25/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4839 - val_loss: 0.7348\n",
      "Epoch 26/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4663 - val_loss: 0.7344\n",
      "Epoch 27/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4520 - val_loss: 0.7205\n",
      "Epoch 28/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4455 - val_loss: 0.7103\n",
      "Epoch 29/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4573 - val_loss: 0.7194\n",
      "Epoch 30/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4747 - val_loss: 0.7366\n",
      "Epoch 31/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4500 - val_loss: 0.7196\n",
      "Epoch 32/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4670 - val_loss: 0.7347\n",
      "Epoch 33/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4571 - val_loss: 0.7233\n",
      "Epoch 34/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4463 - val_loss: 0.7261\n",
      "Epoch 35/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4469 - val_loss: 0.7301\n",
      "Epoch 36/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4474 - val_loss: 0.7354\n",
      "Epoch 37/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4421 - val_loss: 0.7118\n",
      "Epoch 38/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4562 - val_loss: 0.7335\n",
      "Epoch 39/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4480 - val_loss: 0.7321\n",
      "Epoch 40/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4582 - val_loss: 0.7293\n",
      "Epoch 41/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4413 - val_loss: 0.7651\n",
      "Epoch 42/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4372 - val_loss: 0.7289\n",
      "Epoch 43/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4453 - val_loss: 0.7317\n",
      "Epoch 44/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4414 - val_loss: 0.7244\n",
      "Epoch 45/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4436 - val_loss: 0.7701\n",
      "Epoch 46/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4460 - val_loss: 0.7137\n",
      "Epoch 47/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4248 - val_loss: 0.7437\n",
      "Epoch 48/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4402 - val_loss: 0.7431\n",
      "Epoch 49/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4243 - val_loss: 0.7093\n",
      "Epoch 50/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4342 - val_loss: 0.7509\n",
      "Epoch 51/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4299 - val_loss: 0.7316\n",
      "Epoch 52/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4329 - val_loss: 0.7317\n",
      "Epoch 53/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4429 - val_loss: 0.7390\n",
      "Epoch 54/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4380 - val_loss: 0.7490\n",
      "Epoch 55/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4321 - val_loss: 0.7147\n",
      "Epoch 56/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4293 - val_loss: 0.7440\n",
      "Epoch 57/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4253 - val_loss: 0.7233\n",
      "Epoch 58/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4311 - val_loss: 0.7415\n",
      "Epoch 59/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4216 - val_loss: 0.7373\n",
      "Epoch 60/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4365 - val_loss: 0.7392\n",
      "Epoch 61/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4364 - val_loss: 0.7386\n",
      "Epoch 62/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4233 - val_loss: 0.7322\n",
      "Epoch 63/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4309 - val_loss: 0.7374\n",
      "Epoch 64/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4217 - val_loss: 0.7425\n",
      "Epoch 65/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4174 - val_loss: 0.7264\n",
      "Epoch 66/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4362 - val_loss: 0.7223\n",
      "Epoch 67/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4354 - val_loss: 0.7431\n",
      "Epoch 68/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4405 - val_loss: 0.7570\n",
      "Epoch 69/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4292 - val_loss: 0.7426\n",
      "Epoch 70/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4316 - val_loss: 0.7434\n",
      "Epoch 71/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4367 - val_loss: 0.7531\n",
      "Epoch 72/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4328 - val_loss: 0.7359\n",
      "Epoch 73/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4477 - val_loss: 0.7405\n",
      "Epoch 74/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4332 - val_loss: 0.7328\n",
      "Epoch 75/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4261 - val_loss: 0.7535\n",
      "Epoch 76/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4314 - val_loss: 0.7564\n",
      "Epoch 77/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4415 - val_loss: 0.7478\n",
      "Epoch 78/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4281 - val_loss: 0.7365\n",
      "Epoch 79/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4286 - val_loss: 0.7283\n",
      "Epoch 80/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4349 - val_loss: 0.7540\n",
      "Epoch 81/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4467 - val_loss: 0.7271\n",
      "Epoch 82/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4305 - val_loss: 0.7459\n",
      "Epoch 83/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4285 - val_loss: 0.7428\n",
      "Epoch 84/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4108 - val_loss: 0.7506\n",
      "Epoch 85/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4264 - val_loss: 0.7346\n",
      "Epoch 86/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4318 - val_loss: 0.7348\n",
      "Epoch 87/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4282 - val_loss: 0.7355\n",
      "Epoch 88/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4277 - val_loss: 0.7344\n",
      "Epoch 89/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4336 - val_loss: 0.7462\n",
      "Epoch 90/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4181 - val_loss: 0.7483\n",
      "Epoch 91/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4201 - val_loss: 0.7151\n",
      "Epoch 92/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4324 - val_loss: 0.7426\n",
      "Epoch 93/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4295 - val_loss: 0.7630\n",
      "Epoch 94/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4280 - val_loss: 0.7490\n",
      "Epoch 95/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4097 - val_loss: 0.7397\n",
      "Epoch 96/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4127 - val_loss: 0.7448\n",
      "Epoch 97/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4372 - val_loss: 0.7555\n",
      "Epoch 98/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4260 - val_loss: 0.7435\n",
      "Epoch 99/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4158 - val_loss: 0.7439\n",
      "Epoch 100/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4276 - val_loss: 0.7478\n",
      "current time:  2024-06-28_19-16\n",
      "\n",
      "\n",
      "20:mean_squared_error-label_sub 44.4%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.7313 - val_loss: 0.6745\n",
      "Epoch 2/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6532 - val_loss: 0.7124\n",
      "Epoch 3/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6032 - val_loss: 0.6854\n",
      "Epoch 4/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6019 - val_loss: 0.6825\n",
      "Epoch 5/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5688 - val_loss: 0.6897\n",
      "Epoch 6/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5563 - val_loss: 0.6954\n",
      "Epoch 7/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5369 - val_loss: 0.7284\n",
      "Epoch 8/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5456 - val_loss: 0.6900\n",
      "Epoch 9/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5347 - val_loss: 0.7018\n",
      "Epoch 10/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5161 - val_loss: 0.7004\n",
      "Epoch 11/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5064 - val_loss: 0.7305\n",
      "Epoch 12/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4985 - val_loss: 0.7438\n",
      "Epoch 13/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5030 - val_loss: 0.6968\n",
      "Epoch 14/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5047 - val_loss: 0.7156\n",
      "Epoch 15/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4781 - val_loss: 0.7286\n",
      "Epoch 16/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4752 - val_loss: 0.6946\n",
      "Epoch 17/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4741 - val_loss: 0.7356\n",
      "Epoch 18/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4803 - val_loss: 0.7053\n",
      "Epoch 19/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4762 - val_loss: 0.7220\n",
      "Epoch 20/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4693 - val_loss: 0.7262\n",
      "Epoch 21/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4815 - val_loss: 0.7054\n",
      "Epoch 22/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4661 - val_loss: 0.7027\n",
      "Epoch 23/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4656 - val_loss: 0.7071\n",
      "Epoch 24/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4733 - val_loss: 0.7238\n",
      "Epoch 25/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4520 - val_loss: 0.7217\n",
      "Epoch 26/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4632 - val_loss: 0.7263\n",
      "Epoch 27/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4621 - val_loss: 0.7147\n",
      "Epoch 28/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4501 - val_loss: 0.7130\n",
      "Epoch 29/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4631 - val_loss: 0.7361\n",
      "Epoch 30/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4491 - val_loss: 0.7145\n",
      "Epoch 31/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4548 - val_loss: 0.7083\n",
      "Epoch 32/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4536 - val_loss: 0.6968\n",
      "Epoch 33/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4554 - val_loss: 0.7171\n",
      "Epoch 34/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4643 - val_loss: 0.7319\n",
      "Epoch 35/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4334 - val_loss: 0.7264\n",
      "Epoch 36/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4395 - val_loss: 0.6954\n",
      "Epoch 37/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4340 - val_loss: 0.7068\n",
      "Epoch 38/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4430 - val_loss: 0.7175\n",
      "Epoch 39/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4396 - val_loss: 0.7241\n",
      "Epoch 40/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4391 - val_loss: 0.7030\n",
      "Epoch 41/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4473 - val_loss: 0.7487\n",
      "Epoch 42/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4516 - val_loss: 0.7298\n",
      "Epoch 43/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4447 - val_loss: 0.7384\n",
      "Epoch 44/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4454 - val_loss: 0.7222\n",
      "Epoch 45/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4495 - val_loss: 0.7232\n",
      "Epoch 46/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4590 - val_loss: 0.7233\n",
      "Epoch 47/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4554 - val_loss: 0.7263\n",
      "Epoch 48/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4447 - val_loss: 0.7338\n",
      "Epoch 49/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4419 - val_loss: 0.7151\n",
      "Epoch 50/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4427 - val_loss: 0.7302\n",
      "Epoch 51/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4376 - val_loss: 0.7336\n",
      "Epoch 52/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4426 - val_loss: 0.7212\n",
      "Epoch 53/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4320 - val_loss: 0.7387\n",
      "Epoch 54/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4363 - val_loss: 0.7246\n",
      "Epoch 55/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4514 - val_loss: 0.7147\n",
      "Epoch 56/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4371 - val_loss: 0.7382\n",
      "Epoch 57/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4335 - val_loss: 0.7210\n",
      "Epoch 58/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4275 - val_loss: 0.7378\n",
      "Epoch 59/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4318 - val_loss: 0.7239\n",
      "Epoch 60/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4363 - val_loss: 0.7382\n",
      "Epoch 61/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4184 - val_loss: 0.7323\n",
      "Epoch 62/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4370 - val_loss: 0.7278\n",
      "Epoch 63/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4388 - val_loss: 0.7301\n",
      "Epoch 64/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4203 - val_loss: 0.7413\n",
      "Epoch 65/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4549 - val_loss: 0.7256\n",
      "Epoch 66/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4298 - val_loss: 0.7212\n",
      "Epoch 67/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4377 - val_loss: 0.7324\n",
      "Epoch 68/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4351 - val_loss: 0.7321\n",
      "Epoch 69/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4363 - val_loss: 0.7487\n",
      "Epoch 70/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4417 - val_loss: 0.7439\n",
      "Epoch 71/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4306 - val_loss: 0.7337\n",
      "Epoch 72/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4177 - val_loss: 0.7381\n",
      "Epoch 73/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4335 - val_loss: 0.7390\n",
      "Epoch 74/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4303 - val_loss: 0.7179\n",
      "Epoch 75/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4304 - val_loss: 0.7294\n",
      "Epoch 76/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4293 - val_loss: 0.7401\n",
      "Epoch 77/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4328 - val_loss: 0.7285\n",
      "Epoch 78/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4240 - val_loss: 0.7431\n",
      "Epoch 79/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4382 - val_loss: 0.7180\n",
      "Epoch 80/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4190 - val_loss: 0.7361\n",
      "Epoch 81/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4153 - val_loss: 0.7259\n",
      "Epoch 82/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4170 - val_loss: 0.7506\n",
      "Epoch 83/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4127 - val_loss: 0.7602\n",
      "Epoch 84/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4292 - val_loss: 0.7337\n",
      "Epoch 85/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4235 - val_loss: 0.7229\n",
      "Epoch 86/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4097 - val_loss: 0.7241\n",
      "Epoch 87/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4316 - val_loss: 0.7427\n",
      "Epoch 88/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4313 - val_loss: 0.7258\n",
      "Epoch 89/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4305 - val_loss: 0.7507\n",
      "Epoch 90/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4306 - val_loss: 0.7334\n",
      "Epoch 91/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4202 - val_loss: 0.7459\n",
      "Epoch 92/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4199 - val_loss: 0.7301\n",
      "Epoch 93/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4130 - val_loss: 0.7222\n",
      "Epoch 94/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4284 - val_loss: 0.7194\n",
      "Epoch 95/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4292 - val_loss: 0.7424\n",
      "Epoch 96/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4203 - val_loss: 0.7256\n",
      "Epoch 97/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4109 - val_loss: 0.7220\n",
      "Epoch 98/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4290 - val_loss: 0.7437\n",
      "Epoch 99/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4221 - val_loss: 0.7421\n",
      "Epoch 100/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4285 - val_loss: 0.7360\n",
      "current time:  2024-06-28_19-18\n",
      "\n",
      "\n",
      "21:mean_squared_error-label_sub 46.7%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7218 - val_loss: 0.6847\n",
      "Epoch 2/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6495 - val_loss: 0.6880\n",
      "Epoch 3/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6050 - val_loss: 0.6709\n",
      "Epoch 4/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5864 - val_loss: 0.6899\n",
      "Epoch 5/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5870 - val_loss: 0.6821\n",
      "Epoch 6/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5610 - val_loss: 0.6991\n",
      "Epoch 7/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5437 - val_loss: 0.6939\n",
      "Epoch 8/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5431 - val_loss: 0.6841\n",
      "Epoch 9/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5327 - val_loss: 0.6904\n",
      "Epoch 10/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5220 - val_loss: 0.7057\n",
      "Epoch 11/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4897 - val_loss: 0.6917\n",
      "Epoch 12/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5225 - val_loss: 0.7075\n",
      "Epoch 13/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5254 - val_loss: 0.7067\n",
      "Epoch 14/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5167 - val_loss: 0.7020\n",
      "Epoch 15/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4838 - val_loss: 0.7155\n",
      "Epoch 16/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5047 - val_loss: 0.7036\n",
      "Epoch 17/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5095 - val_loss: 0.7172\n",
      "Epoch 18/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4878 - val_loss: 0.7182\n",
      "Epoch 19/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4888 - val_loss: 0.7181\n",
      "Epoch 20/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4845 - val_loss: 0.7115\n",
      "Epoch 21/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4828 - val_loss: 0.7095\n",
      "Epoch 22/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4776 - val_loss: 0.7239\n",
      "Epoch 23/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4791 - val_loss: 0.7255\n",
      "Epoch 24/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4759 - val_loss: 0.7247\n",
      "Epoch 25/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4720 - val_loss: 0.7249\n",
      "Epoch 26/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4712 - val_loss: 0.7199\n",
      "Epoch 27/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4620 - val_loss: 0.7331\n",
      "Epoch 28/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4746 - val_loss: 0.7301\n",
      "Epoch 29/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4756 - val_loss: 0.7418\n",
      "Epoch 30/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4582 - val_loss: 0.7219\n",
      "Epoch 31/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4590 - val_loss: 0.7219\n",
      "Epoch 32/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4612 - val_loss: 0.7357\n",
      "Epoch 33/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4576 - val_loss: 0.7284\n",
      "Epoch 34/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4644 - val_loss: 0.7262\n",
      "Epoch 35/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4478 - val_loss: 0.7479\n",
      "Epoch 36/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4544 - val_loss: 0.7384\n",
      "Epoch 37/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4502 - val_loss: 0.7276\n",
      "Epoch 38/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4541 - val_loss: 0.7364\n",
      "Epoch 39/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4655 - val_loss: 0.7289\n",
      "Epoch 40/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4567 - val_loss: 0.7379\n",
      "Epoch 41/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4456 - val_loss: 0.7431\n",
      "Epoch 42/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4425 - val_loss: 0.7371\n",
      "Epoch 43/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4590 - val_loss: 0.7307\n",
      "Epoch 44/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4501 - val_loss: 0.7301\n",
      "Epoch 45/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4564 - val_loss: 0.7392\n",
      "Epoch 46/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4601 - val_loss: 0.7280\n",
      "Epoch 47/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4379 - val_loss: 0.7280\n",
      "Epoch 48/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4454 - val_loss: 0.7483\n",
      "Epoch 49/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4540 - val_loss: 0.7599\n",
      "Epoch 50/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4375 - val_loss: 0.7387\n",
      "Epoch 51/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4441 - val_loss: 0.7426\n",
      "Epoch 52/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4475 - val_loss: 0.7355\n",
      "Epoch 53/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4425 - val_loss: 0.7351\n",
      "Epoch 54/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4456 - val_loss: 0.7414\n",
      "Epoch 55/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4406 - val_loss: 0.7310\n",
      "Epoch 56/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4346 - val_loss: 0.7560\n",
      "Epoch 57/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4472 - val_loss: 0.7338\n",
      "Epoch 58/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4405 - val_loss: 0.7268\n",
      "Epoch 59/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4408 - val_loss: 0.7351\n",
      "Epoch 60/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4352 - val_loss: 0.7343\n",
      "Epoch 61/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4431 - val_loss: 0.7355\n",
      "Epoch 62/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4482 - val_loss: 0.7546\n",
      "Epoch 63/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4407 - val_loss: 0.7354\n",
      "Epoch 64/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4453 - val_loss: 0.7442\n",
      "Epoch 65/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4444 - val_loss: 0.7524\n",
      "Epoch 66/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4377 - val_loss: 0.7455\n",
      "Epoch 67/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4406 - val_loss: 0.7570\n",
      "Epoch 68/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4338 - val_loss: 0.7428\n",
      "Epoch 69/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4423 - val_loss: 0.7457\n",
      "Epoch 70/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4416 - val_loss: 0.7450\n",
      "Epoch 71/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4418 - val_loss: 0.7486\n",
      "Epoch 72/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4446 - val_loss: 0.7544\n",
      "Epoch 73/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4407 - val_loss: 0.7456\n",
      "Epoch 74/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4469 - val_loss: 0.7461\n",
      "Epoch 75/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4514 - val_loss: 0.7493\n",
      "Epoch 76/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4397 - val_loss: 0.7522\n",
      "Epoch 77/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4301 - val_loss: 0.7482\n",
      "Epoch 78/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4307 - val_loss: 0.7394\n",
      "Epoch 79/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4259 - val_loss: 0.7427\n",
      "Epoch 80/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4418 - val_loss: 0.7426\n",
      "Epoch 81/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4365 - val_loss: 0.7443\n",
      "Epoch 82/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4483 - val_loss: 0.7419\n",
      "Epoch 83/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4449 - val_loss: 0.7556\n",
      "Epoch 84/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4368 - val_loss: 0.7455\n",
      "Epoch 85/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4345 - val_loss: 0.7558\n",
      "Epoch 86/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4305 - val_loss: 0.7360\n",
      "Epoch 87/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4436 - val_loss: 0.7540\n",
      "Epoch 88/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4399 - val_loss: 0.7433\n",
      "Epoch 89/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4316 - val_loss: 0.7446\n",
      "Epoch 90/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4311 - val_loss: 0.7432\n",
      "Epoch 91/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4387 - val_loss: 0.7472\n",
      "Epoch 92/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4350 - val_loss: 0.7530\n",
      "Epoch 93/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4331 - val_loss: 0.7455\n",
      "Epoch 94/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4302 - val_loss: 0.7461\n",
      "Epoch 95/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4311 - val_loss: 0.7427\n",
      "Epoch 96/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4217 - val_loss: 0.7460\n",
      "Epoch 97/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4255 - val_loss: 0.7440\n",
      "Epoch 98/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4343 - val_loss: 0.7351\n",
      "Epoch 99/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4433 - val_loss: 0.7354\n",
      "Epoch 100/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4302 - val_loss: 0.7425\n",
      "current time:  2024-06-28_19-18\n",
      "\n",
      "\n",
      "22:mean_squared_error-label_sub 48.9%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.7401 - val_loss: 0.6978\n",
      "Epoch 2/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6524 - val_loss: 0.6706\n",
      "Epoch 3/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6139 - val_loss: 0.6768\n",
      "Epoch 4/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5928 - val_loss: 0.6606\n",
      "Epoch 5/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5770 - val_loss: 0.6764\n",
      "Epoch 6/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5449 - val_loss: 0.6820\n",
      "Epoch 7/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5566 - val_loss: 0.6973\n",
      "Epoch 8/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5434 - val_loss: 0.6793\n",
      "Epoch 9/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5281 - val_loss: 0.7029\n",
      "Epoch 10/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5167 - val_loss: 0.7007\n",
      "Epoch 11/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5157 - val_loss: 0.6952\n",
      "Epoch 12/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4988 - val_loss: 0.7031\n",
      "Epoch 13/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5020 - val_loss: 0.7125\n",
      "Epoch 14/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5086 - val_loss: 0.6922\n",
      "Epoch 15/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4949 - val_loss: 0.7023\n",
      "Epoch 16/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4953 - val_loss: 0.6970\n",
      "Epoch 17/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4722 - val_loss: 0.7073\n",
      "Epoch 18/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4831 - val_loss: 0.7261\n",
      "Epoch 19/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4695 - val_loss: 0.7172\n",
      "Epoch 20/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4711 - val_loss: 0.7068\n",
      "Epoch 21/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4711 - val_loss: 0.7069\n",
      "Epoch 22/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4719 - val_loss: 0.7174\n",
      "Epoch 23/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4667 - val_loss: 0.7192\n",
      "Epoch 24/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4709 - val_loss: 0.7258\n",
      "Epoch 25/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4752 - val_loss: 0.7144\n",
      "Epoch 26/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4740 - val_loss: 0.7208\n",
      "Epoch 27/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4678 - val_loss: 0.7328\n",
      "Epoch 28/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4585 - val_loss: 0.7387\n",
      "Epoch 29/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4511 - val_loss: 0.7016\n",
      "Epoch 30/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4615 - val_loss: 0.7123\n",
      "Epoch 31/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4571 - val_loss: 0.7327\n",
      "Epoch 32/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4587 - val_loss: 0.7172\n",
      "Epoch 33/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4429 - val_loss: 0.7307\n",
      "Epoch 34/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4443 - val_loss: 0.7214\n",
      "Epoch 35/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4465 - val_loss: 0.7082\n",
      "Epoch 36/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4465 - val_loss: 0.7384\n",
      "Epoch 37/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4501 - val_loss: 0.7159\n",
      "Epoch 38/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4463 - val_loss: 0.7338\n",
      "Epoch 39/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4422 - val_loss: 0.7322\n",
      "Epoch 40/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4307 - val_loss: 0.7111\n",
      "Epoch 41/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4451 - val_loss: 0.7183\n",
      "Epoch 42/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4460 - val_loss: 0.7189\n",
      "Epoch 43/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4487 - val_loss: 0.7299\n",
      "Epoch 44/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4348 - val_loss: 0.7147\n",
      "Epoch 45/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4513 - val_loss: 0.7302\n",
      "Epoch 46/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4484 - val_loss: 0.7197\n",
      "Epoch 47/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4493 - val_loss: 0.7206\n",
      "Epoch 48/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4342 - val_loss: 0.7180\n",
      "Epoch 49/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4497 - val_loss: 0.7376\n",
      "Epoch 50/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4401 - val_loss: 0.7350\n",
      "Epoch 51/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4484 - val_loss: 0.7241\n",
      "Epoch 52/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4412 - val_loss: 0.7361\n",
      "Epoch 53/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4300 - val_loss: 0.7290\n",
      "Epoch 54/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4339 - val_loss: 0.7221\n",
      "Epoch 55/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4452 - val_loss: 0.7366\n",
      "Epoch 56/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4387 - val_loss: 0.7339\n",
      "Epoch 57/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4350 - val_loss: 0.7347\n",
      "Epoch 58/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4250 - val_loss: 0.7409\n",
      "Epoch 59/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4398 - val_loss: 0.7542\n",
      "Epoch 60/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4245 - val_loss: 0.7288\n",
      "Epoch 61/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4215 - val_loss: 0.7398\n",
      "Epoch 62/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4353 - val_loss: 0.7302\n",
      "Epoch 63/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4289 - val_loss: 0.7405\n",
      "Epoch 64/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4444 - val_loss: 0.7396\n",
      "Epoch 65/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4360 - val_loss: 0.7217\n",
      "Epoch 66/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4301 - val_loss: 0.7484\n",
      "Epoch 67/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4322 - val_loss: 0.7333\n",
      "Epoch 68/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4323 - val_loss: 0.7395\n",
      "Epoch 69/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4387 - val_loss: 0.7406\n",
      "Epoch 70/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4400 - val_loss: 0.7212\n",
      "Epoch 71/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4287 - val_loss: 0.7384\n",
      "Epoch 72/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4294 - val_loss: 0.7328\n",
      "Epoch 73/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4175 - val_loss: 0.7479\n",
      "Epoch 74/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4277 - val_loss: 0.7378\n",
      "Epoch 75/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4222 - val_loss: 0.7290\n",
      "Epoch 76/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4319 - val_loss: 0.7348\n",
      "Epoch 77/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4287 - val_loss: 0.7368\n",
      "Epoch 78/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4251 - val_loss: 0.7400\n",
      "Epoch 79/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4356 - val_loss: 0.7221\n",
      "Epoch 80/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4379 - val_loss: 0.7370\n",
      "Epoch 81/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4332 - val_loss: 0.7345\n",
      "Epoch 82/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4245 - val_loss: 0.7377\n",
      "Epoch 83/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4301 - val_loss: 0.7340\n",
      "Epoch 84/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4402 - val_loss: 0.7381\n",
      "Epoch 85/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4327 - val_loss: 0.7347\n",
      "Epoch 86/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4216 - val_loss: 0.7442\n",
      "Epoch 87/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4223 - val_loss: 0.7283\n",
      "Epoch 88/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4252 - val_loss: 0.7353\n",
      "Epoch 89/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4274 - val_loss: 0.7303\n",
      "Epoch 90/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4289 - val_loss: 0.7290\n",
      "Epoch 91/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4166 - val_loss: 0.7226\n",
      "Epoch 92/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4257 - val_loss: 0.7392\n",
      "Epoch 93/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4291 - val_loss: 0.7428\n",
      "Epoch 94/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4293 - val_loss: 0.7353\n",
      "Epoch 95/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4231 - val_loss: 0.7348\n",
      "Epoch 96/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4233 - val_loss: 0.7543\n",
      "Epoch 97/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4242 - val_loss: 0.7445\n",
      "Epoch 98/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4243 - val_loss: 0.7433\n",
      "Epoch 99/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4259 - val_loss: 0.7460\n",
      "Epoch 100/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4337 - val_loss: 0.7295\n",
      "current time:  2024-06-28_19-19\n",
      "\n",
      "\n",
      "23:mean_squared_error-label_sub 51.1%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7220 - val_loss: 0.6826\n",
      "Epoch 2/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6322 - val_loss: 0.6831\n",
      "Epoch 3/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5937 - val_loss: 0.6958\n",
      "Epoch 4/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5817 - val_loss: 0.6871\n",
      "Epoch 5/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5557 - val_loss: 0.6783\n",
      "Epoch 6/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5611 - val_loss: 0.7238\n",
      "Epoch 7/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5595 - val_loss: 0.7034\n",
      "Epoch 8/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5323 - val_loss: 0.6795\n",
      "Epoch 9/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5290 - val_loss: 0.6956\n",
      "Epoch 10/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5443 - val_loss: 0.6989\n",
      "Epoch 11/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4925 - val_loss: 0.7204\n",
      "Epoch 12/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5065 - val_loss: 0.7037\n",
      "Epoch 13/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4968 - val_loss: 0.7087\n",
      "Epoch 14/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4875 - val_loss: 0.7213\n",
      "Epoch 15/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4922 - val_loss: 0.7186\n",
      "Epoch 16/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4957 - val_loss: 0.7155\n",
      "Epoch 17/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4790 - val_loss: 0.7312\n",
      "Epoch 18/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4745 - val_loss: 0.7000\n",
      "Epoch 19/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4689 - val_loss: 0.6966\n",
      "Epoch 20/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4915 - val_loss: 0.7139\n",
      "Epoch 21/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4650 - val_loss: 0.6970\n",
      "Epoch 22/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4781 - val_loss: 0.7099\n",
      "Epoch 23/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4759 - val_loss: 0.7118\n",
      "Epoch 24/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4765 - val_loss: 0.7200\n",
      "Epoch 25/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4584 - val_loss: 0.7140\n",
      "Epoch 26/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4631 - val_loss: 0.7200\n",
      "Epoch 27/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4485 - val_loss: 0.7080\n",
      "Epoch 28/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4628 - val_loss: 0.7198\n",
      "Epoch 29/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4550 - val_loss: 0.7089\n",
      "Epoch 30/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4594 - val_loss: 0.7192\n",
      "Epoch 31/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4528 - val_loss: 0.7176\n",
      "Epoch 32/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4559 - val_loss: 0.6918\n",
      "Epoch 33/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4486 - val_loss: 0.7338\n",
      "Epoch 34/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4559 - val_loss: 0.7223\n",
      "Epoch 35/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4463 - val_loss: 0.7371\n",
      "Epoch 36/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4600 - val_loss: 0.7138\n",
      "Epoch 37/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4506 - val_loss: 0.7178\n",
      "Epoch 38/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4386 - val_loss: 0.7201\n",
      "Epoch 39/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4326 - val_loss: 0.7475\n",
      "Epoch 40/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4340 - val_loss: 0.7258\n",
      "Epoch 41/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4399 - val_loss: 0.7186\n",
      "Epoch 42/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4358 - val_loss: 0.7483\n",
      "Epoch 43/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4353 - val_loss: 0.7185\n",
      "Epoch 44/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4423 - val_loss: 0.7096\n",
      "Epoch 45/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4503 - val_loss: 0.7232\n",
      "Epoch 46/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4419 - val_loss: 0.7246\n",
      "Epoch 47/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4373 - val_loss: 0.7000\n",
      "Epoch 48/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4525 - val_loss: 0.7350\n",
      "Epoch 49/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4419 - val_loss: 0.7224\n",
      "Epoch 50/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4503 - val_loss: 0.7122\n",
      "Epoch 51/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4442 - val_loss: 0.7176\n",
      "Epoch 52/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4317 - val_loss: 0.7244\n",
      "Epoch 53/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4478 - val_loss: 0.7298\n",
      "Epoch 54/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4347 - val_loss: 0.7230\n",
      "Epoch 55/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4259 - val_loss: 0.7376\n",
      "Epoch 56/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4392 - val_loss: 0.7197\n",
      "Epoch 57/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4315 - val_loss: 0.7247\n",
      "Epoch 58/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4343 - val_loss: 0.7371\n",
      "Epoch 59/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4359 - val_loss: 0.7159\n",
      "Epoch 60/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4426 - val_loss: 0.7325\n",
      "Epoch 61/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4429 - val_loss: 0.7274\n",
      "Epoch 62/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4343 - val_loss: 0.7282\n",
      "Epoch 63/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4280 - val_loss: 0.7340\n",
      "Epoch 64/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4226 - val_loss: 0.7232\n",
      "Epoch 65/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4176 - val_loss: 0.7391\n",
      "Epoch 66/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4326 - val_loss: 0.7487\n",
      "Epoch 67/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4173 - val_loss: 0.7444\n",
      "Epoch 68/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4415 - val_loss: 0.7453\n",
      "Epoch 69/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4222 - val_loss: 0.7315\n",
      "Epoch 70/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4330 - val_loss: 0.7254\n",
      "Epoch 71/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4270 - val_loss: 0.7366\n",
      "Epoch 72/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4476 - val_loss: 0.7393\n",
      "Epoch 73/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4336 - val_loss: 0.7340\n",
      "Epoch 74/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4198 - val_loss: 0.7445\n",
      "Epoch 75/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4231 - val_loss: 0.7334\n",
      "Epoch 76/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4254 - val_loss: 0.7465\n",
      "Epoch 77/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4141 - val_loss: 0.7276\n",
      "Epoch 78/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4266 - val_loss: 0.7206\n",
      "Epoch 79/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4264 - val_loss: 0.7483\n",
      "Epoch 80/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4385 - val_loss: 0.7412\n",
      "Epoch 81/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4232 - val_loss: 0.7354\n",
      "Epoch 82/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4203 - val_loss: 0.7356\n",
      "Epoch 83/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4163 - val_loss: 0.7272\n",
      "Epoch 84/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4103 - val_loss: 0.7468\n",
      "Epoch 85/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4149 - val_loss: 0.7381\n",
      "Epoch 86/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4278 - val_loss: 0.7507\n",
      "Epoch 87/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4306 - val_loss: 0.7423\n",
      "Epoch 88/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4245 - val_loss: 0.7384\n",
      "Epoch 89/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4329 - val_loss: 0.7377\n",
      "Epoch 90/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4233 - val_loss: 0.7388\n",
      "Epoch 91/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4206 - val_loss: 0.7277\n",
      "Epoch 92/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4163 - val_loss: 0.7401\n",
      "Epoch 93/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4220 - val_loss: 0.7572\n",
      "Epoch 94/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4209 - val_loss: 0.7351\n",
      "Epoch 95/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4247 - val_loss: 0.7437\n",
      "Epoch 96/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4314 - val_loss: 0.7295\n",
      "Epoch 97/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4146 - val_loss: 0.7561\n",
      "Epoch 98/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4194 - val_loss: 0.7428\n",
      "Epoch 99/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4151 - val_loss: 0.7537\n",
      "Epoch 100/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4159 - val_loss: 0.7260\n",
      "current time:  2024-06-28_19-19\n",
      "\n",
      "\n",
      "24:mean_squared_error-label_sub 53.3%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7498 - val_loss: 0.6964\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7067 - val_loss: 0.7000\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6820 - val_loss: 0.6878\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6524 - val_loss: 0.6796\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6263 - val_loss: 0.7042\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6298 - val_loss: 0.6633\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5814 - val_loss: 0.6624\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5743 - val_loss: 0.6655\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5858 - val_loss: 0.6653\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5603 - val_loss: 0.6636\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5563 - val_loss: 0.6649\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5363 - val_loss: 0.6631\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5396 - val_loss: 0.6692\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5300 - val_loss: 0.6686\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5333 - val_loss: 0.6750\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5193 - val_loss: 0.6858\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5096 - val_loss: 0.6873\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5186 - val_loss: 0.6832\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5064 - val_loss: 0.6767\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5146 - val_loss: 0.6838\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4829 - val_loss: 0.6858\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4928 - val_loss: 0.6862\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4991 - val_loss: 0.6806\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4995 - val_loss: 0.6848\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4929 - val_loss: 0.6992\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4896 - val_loss: 0.7028\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4867 - val_loss: 0.6813\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4898 - val_loss: 0.7052\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4778 - val_loss: 0.6932\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4710 - val_loss: 0.6969\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4691 - val_loss: 0.6974\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4638 - val_loss: 0.7027\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4658 - val_loss: 0.7025\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4706 - val_loss: 0.7063\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4705 - val_loss: 0.6946\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4667 - val_loss: 0.7082\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4654 - val_loss: 0.7094\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4632 - val_loss: 0.7025\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4771 - val_loss: 0.7171\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4919 - val_loss: 0.7099\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4891 - val_loss: 0.7124\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4559 - val_loss: 0.7135\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4598 - val_loss: 0.7111\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4643 - val_loss: 0.7059\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4648 - val_loss: 0.7170\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4597 - val_loss: 0.7119\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4581 - val_loss: 0.7106\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4578 - val_loss: 0.7111\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4607 - val_loss: 0.7137\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4589 - val_loss: 0.7138\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4594 - val_loss: 0.7102\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4645 - val_loss: 0.7203\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4515 - val_loss: 0.7153\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4686 - val_loss: 0.7123\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4426 - val_loss: 0.7168\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4568 - val_loss: 0.7233\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4491 - val_loss: 0.7284\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4391 - val_loss: 0.7262\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4460 - val_loss: 0.7209\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4516 - val_loss: 0.7166\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4482 - val_loss: 0.7170\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4527 - val_loss: 0.7133\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4369 - val_loss: 0.7182\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4386 - val_loss: 0.7196\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4489 - val_loss: 0.7176\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4445 - val_loss: 0.7176\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4467 - val_loss: 0.7161\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4471 - val_loss: 0.7198\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4525 - val_loss: 0.7291\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4614 - val_loss: 0.7197\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4503 - val_loss: 0.7218\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4350 - val_loss: 0.7193\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4456 - val_loss: 0.7252\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4490 - val_loss: 0.7207\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4359 - val_loss: 0.7258\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4389 - val_loss: 0.7157\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4455 - val_loss: 0.7201\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4297 - val_loss: 0.7240\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4476 - val_loss: 0.7263\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4515 - val_loss: 0.7223\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4504 - val_loss: 0.7182\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4349 - val_loss: 0.7210\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4358 - val_loss: 0.7208\n",
      "Epoch 84/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4350 - val_loss: 0.7268\n",
      "Epoch 85/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4356 - val_loss: 0.7269\n",
      "Epoch 86/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4547 - val_loss: 0.7302\n",
      "Epoch 87/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4535 - val_loss: 0.7293\n",
      "Epoch 88/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4439 - val_loss: 0.7361\n",
      "Epoch 89/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4528 - val_loss: 0.7301\n",
      "Epoch 90/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4387 - val_loss: 0.7262\n",
      "Epoch 91/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4426 - val_loss: 0.7227\n",
      "Epoch 92/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4273 - val_loss: 0.7272\n",
      "Epoch 93/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4453 - val_loss: 0.7315\n",
      "Epoch 94/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4367 - val_loss: 0.7301\n",
      "Epoch 95/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4211 - val_loss: 0.7276\n",
      "Epoch 96/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4309 - val_loss: 0.7279\n",
      "Epoch 97/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4379 - val_loss: 0.7247\n",
      "Epoch 98/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4316 - val_loss: 0.7297\n",
      "Epoch 99/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4252 - val_loss: 0.7242\n",
      "Epoch 100/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4337 - val_loss: 0.7248\n",
      "current time:  2024-06-28_19-19\n",
      "\n",
      "\n",
      "25:mean_squared_error-label_sub 55.6%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7286 - val_loss: 0.6970\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6863 - val_loss: 0.6869\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6565 - val_loss: 0.6660\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6173 - val_loss: 0.6798\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5984 - val_loss: 0.6867\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5703 - val_loss: 0.6668\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5662 - val_loss: 0.6842\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5585 - val_loss: 0.6820\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5344 - val_loss: 0.6939\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5454 - val_loss: 0.6792\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5407 - val_loss: 0.6694\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5278 - val_loss: 0.6971\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5190 - val_loss: 0.6758\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5212 - val_loss: 0.6790\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5160 - val_loss: 0.6947\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5105 - val_loss: 0.6904\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4961 - val_loss: 0.6808\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5224 - val_loss: 0.6744\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4889 - val_loss: 0.6745\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4886 - val_loss: 0.6912\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4977 - val_loss: 0.6888\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4830 - val_loss: 0.6765\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4896 - val_loss: 0.6751\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4779 - val_loss: 0.7074\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4970 - val_loss: 0.6835\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4976 - val_loss: 0.6922\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4743 - val_loss: 0.6823\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4776 - val_loss: 0.6911\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4615 - val_loss: 0.6912\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4705 - val_loss: 0.6899\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4546 - val_loss: 0.6907\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4847 - val_loss: 0.6870\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4640 - val_loss: 0.7047\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4636 - val_loss: 0.6964\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4686 - val_loss: 0.7076\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4621 - val_loss: 0.6878\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4653 - val_loss: 0.6976\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4610 - val_loss: 0.6995\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4523 - val_loss: 0.7100\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4633 - val_loss: 0.7182\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4799 - val_loss: 0.7129\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4582 - val_loss: 0.7096\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4494 - val_loss: 0.7014\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4513 - val_loss: 0.7234\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4609 - val_loss: 0.6985\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4445 - val_loss: 0.7044\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4484 - val_loss: 0.7166\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4513 - val_loss: 0.6970\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4562 - val_loss: 0.7080\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4527 - val_loss: 0.7112\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4478 - val_loss: 0.7020\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4432 - val_loss: 0.7147\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4393 - val_loss: 0.7040\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4488 - val_loss: 0.7160\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4437 - val_loss: 0.7107\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4452 - val_loss: 0.7123\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4580 - val_loss: 0.6930\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4589 - val_loss: 0.7022\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4488 - val_loss: 0.7119\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4428 - val_loss: 0.7029\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4342 - val_loss: 0.7087\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4470 - val_loss: 0.7158\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4401 - val_loss: 0.7165\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4361 - val_loss: 0.7026\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4455 - val_loss: 0.7198\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4476 - val_loss: 0.7208\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4454 - val_loss: 0.7078\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4413 - val_loss: 0.7181\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4392 - val_loss: 0.7224\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4449 - val_loss: 0.7227\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4426 - val_loss: 0.7123\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4339 - val_loss: 0.6978\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4305 - val_loss: 0.7114\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4343 - val_loss: 0.7076\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4322 - val_loss: 0.7125\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4377 - val_loss: 0.7057\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4292 - val_loss: 0.7120\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4392 - val_loss: 0.7143\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4176 - val_loss: 0.7176\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4492 - val_loss: 0.7316\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4500 - val_loss: 0.7098\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4362 - val_loss: 0.7029\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4371 - val_loss: 0.7129\n",
      "Epoch 84/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4527 - val_loss: 0.7103\n",
      "Epoch 85/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4473 - val_loss: 0.7219\n",
      "Epoch 86/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4261 - val_loss: 0.7175\n",
      "Epoch 87/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4513 - val_loss: 0.7202\n",
      "Epoch 88/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4349 - val_loss: 0.7291\n",
      "Epoch 89/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4252 - val_loss: 0.7221\n",
      "Epoch 90/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4309 - val_loss: 0.7182\n",
      "Epoch 91/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4256 - val_loss: 0.7107\n",
      "Epoch 92/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4254 - val_loss: 0.7290\n",
      "Epoch 93/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4385 - val_loss: 0.7068\n",
      "Epoch 94/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4410 - val_loss: 0.7126\n",
      "Epoch 95/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4339 - val_loss: 0.7180\n",
      "Epoch 96/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4428 - val_loss: 0.7228\n",
      "Epoch 97/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4341 - val_loss: 0.7110\n",
      "Epoch 98/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4233 - val_loss: 0.7174\n",
      "Epoch 99/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4162 - val_loss: 0.7138\n",
      "Epoch 100/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4279 - val_loss: 0.7005\n",
      "current time:  2024-06-28_19-19\n",
      "\n",
      "\n",
      "26:mean_squared_error-label_sub 57.8%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7447 - val_loss: 0.7033\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7008 - val_loss: 0.6771\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6502 - val_loss: 0.6829\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6171 - val_loss: 0.6851\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5711 - val_loss: 0.6776\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5539 - val_loss: 0.7197\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5440 - val_loss: 0.6976\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5288 - val_loss: 0.7157\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5320 - val_loss: 0.6958\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5205 - val_loss: 0.7099\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5186 - val_loss: 0.7042\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5113 - val_loss: 0.6935\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5043 - val_loss: 0.7036\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4952 - val_loss: 0.6941\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5039 - val_loss: 0.7171\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4942 - val_loss: 0.7126\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4925 - val_loss: 0.7040\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4821 - val_loss: 0.7233\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4765 - val_loss: 0.7102\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4874 - val_loss: 0.6984\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4684 - val_loss: 0.7181\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4860 - val_loss: 0.7067\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4624 - val_loss: 0.7093\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4917 - val_loss: 0.7148\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4682 - val_loss: 0.7298\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4717 - val_loss: 0.7219\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4648 - val_loss: 0.7153\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4642 - val_loss: 0.7122\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4645 - val_loss: 0.7231\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4650 - val_loss: 0.7289\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4576 - val_loss: 0.7270\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4638 - val_loss: 0.7132\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4668 - val_loss: 0.7320\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4543 - val_loss: 0.7207\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4542 - val_loss: 0.7389\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4606 - val_loss: 0.7408\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4633 - val_loss: 0.7201\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4407 - val_loss: 0.7213\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4538 - val_loss: 0.7391\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4477 - val_loss: 0.7160\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4456 - val_loss: 0.7405\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4373 - val_loss: 0.7380\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4431 - val_loss: 0.7276\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4571 - val_loss: 0.7423\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4402 - val_loss: 0.7310\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4592 - val_loss: 0.7400\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4370 - val_loss: 0.7321\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4427 - val_loss: 0.7240\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4449 - val_loss: 0.7350\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4408 - val_loss: 0.7235\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4423 - val_loss: 0.7280\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4413 - val_loss: 0.7359\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4467 - val_loss: 0.7320\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4307 - val_loss: 0.7297\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4431 - val_loss: 0.7470\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4425 - val_loss: 0.7247\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4434 - val_loss: 0.7328\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4439 - val_loss: 0.7448\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4341 - val_loss: 0.7286\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4337 - val_loss: 0.7425\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4382 - val_loss: 0.7416\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4300 - val_loss: 0.7280\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4205 - val_loss: 0.7533\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4386 - val_loss: 0.7634\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4353 - val_loss: 0.7505\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4519 - val_loss: 0.7646\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4421 - val_loss: 0.7454\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4374 - val_loss: 0.7322\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4457 - val_loss: 0.7410\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4496 - val_loss: 0.7405\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4255 - val_loss: 0.7387\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4308 - val_loss: 0.7584\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4314 - val_loss: 0.7483\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4423 - val_loss: 0.7466\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4369 - val_loss: 0.7498\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4396 - val_loss: 0.7376\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4262 - val_loss: 0.7477\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4342 - val_loss: 0.7430\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4223 - val_loss: 0.7441\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4278 - val_loss: 0.7422\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4308 - val_loss: 0.7406\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4290 - val_loss: 0.7348\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4229 - val_loss: 0.7497\n",
      "Epoch 84/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4225 - val_loss: 0.7538\n",
      "Epoch 85/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4265 - val_loss: 0.7380\n",
      "Epoch 86/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4307 - val_loss: 0.7285\n",
      "Epoch 87/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4242 - val_loss: 0.7371\n",
      "Epoch 88/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4338 - val_loss: 0.7427\n",
      "Epoch 89/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4241 - val_loss: 0.7294\n",
      "Epoch 90/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4210 - val_loss: 0.7402\n",
      "Epoch 91/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4157 - val_loss: 0.7421\n",
      "Epoch 92/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4242 - val_loss: 0.7365\n",
      "Epoch 93/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4270 - val_loss: 0.7553\n",
      "Epoch 94/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4206 - val_loss: 0.7570\n",
      "Epoch 95/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4168 - val_loss: 0.7408\n",
      "Epoch 96/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4211 - val_loss: 0.7408\n",
      "Epoch 97/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4357 - val_loss: 0.7523\n",
      "Epoch 98/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4250 - val_loss: 0.7470\n",
      "Epoch 99/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4356 - val_loss: 0.7340\n",
      "Epoch 100/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4311 - val_loss: 0.7394\n",
      "current time:  2024-06-28_19-20\n",
      "\n",
      "\n",
      "27:mean_squared_error-label_sub 60.0%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.7117 - val_loss: 0.7204\n",
      "Epoch 2/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.6511 - val_loss: 0.6796\n",
      "Epoch 3/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 0.6064 - val_loss: 0.6732\n",
      "Epoch 4/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5958 - val_loss: 0.6694\n",
      "Epoch 5/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.5805 - val_loss: 0.6686\n",
      "Epoch 6/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.5740 - val_loss: 0.6562\n",
      "Epoch 7/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 0.5296 - val_loss: 0.6840\n",
      "Epoch 8/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 0.5453 - val_loss: 0.6800\n",
      "Epoch 9/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.5400 - val_loss: 0.6749\n",
      "Epoch 10/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5288 - val_loss: 0.6779\n",
      "Epoch 11/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.5120 - val_loss: 0.7078\n",
      "Epoch 12/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5237 - val_loss: 0.6707\n",
      "Epoch 13/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5000 - val_loss: 0.6683\n",
      "Epoch 14/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4930 - val_loss: 0.6982\n",
      "Epoch 15/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4914 - val_loss: 0.6750\n",
      "Epoch 16/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4839 - val_loss: 0.6835\n",
      "Epoch 17/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4787 - val_loss: 0.6922\n",
      "Epoch 18/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4680 - val_loss: 0.6741\n",
      "Epoch 19/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4720 - val_loss: 0.6827\n",
      "Epoch 20/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4818 - val_loss: 0.6834\n",
      "Epoch 21/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4697 - val_loss: 0.6891\n",
      "Epoch 22/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4744 - val_loss: 0.6959\n",
      "Epoch 23/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.4697 - val_loss: 0.6865\n",
      "Epoch 24/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.4690 - val_loss: 0.7096\n",
      "Epoch 25/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.4615 - val_loss: 0.7075\n",
      "Epoch 26/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4714 - val_loss: 0.7008\n",
      "Epoch 27/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.4724 - val_loss: 0.6944\n",
      "Epoch 28/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.4631 - val_loss: 0.7173\n",
      "Epoch 29/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.4608 - val_loss: 0.6981\n",
      "Epoch 30/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.4547 - val_loss: 0.6994\n",
      "Epoch 31/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4682 - val_loss: 0.7022\n",
      "Epoch 32/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4583 - val_loss: 0.6948\n",
      "Epoch 33/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.4648 - val_loss: 0.6980\n",
      "Epoch 34/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4522 - val_loss: 0.7076\n",
      "Epoch 35/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4565 - val_loss: 0.6920\n",
      "Epoch 36/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4574 - val_loss: 0.7009\n",
      "Epoch 37/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.4625 - val_loss: 0.7077\n",
      "Epoch 38/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4540 - val_loss: 0.6900\n",
      "Epoch 39/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4573 - val_loss: 0.7160\n",
      "Epoch 40/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4450 - val_loss: 0.7041\n",
      "Epoch 41/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4492 - val_loss: 0.7033\n",
      "Epoch 42/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4471 - val_loss: 0.7055\n",
      "Epoch 43/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4505 - val_loss: 0.6824\n",
      "Epoch 44/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4471 - val_loss: 0.7147\n",
      "Epoch 45/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4430 - val_loss: 0.7180\n",
      "Epoch 46/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4458 - val_loss: 0.7215\n",
      "Epoch 47/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4505 - val_loss: 0.7186\n",
      "Epoch 48/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4456 - val_loss: 0.7255\n",
      "Epoch 49/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4448 - val_loss: 0.7201\n",
      "Epoch 50/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4386 - val_loss: 0.7105\n",
      "Epoch 51/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4522 - val_loss: 0.7116\n",
      "Epoch 52/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4447 - val_loss: 0.7158\n",
      "Epoch 53/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4456 - val_loss: 0.6973\n",
      "Epoch 54/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4431 - val_loss: 0.7056\n",
      "Epoch 55/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4436 - val_loss: 0.7154\n",
      "Epoch 56/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4442 - val_loss: 0.7228\n",
      "Epoch 57/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4384 - val_loss: 0.7277\n",
      "Epoch 58/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4516 - val_loss: 0.7055\n",
      "Epoch 59/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4260 - val_loss: 0.7144\n",
      "Epoch 60/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4378 - val_loss: 0.7129\n",
      "Epoch 61/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4384 - val_loss: 0.7292\n",
      "Epoch 62/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4410 - val_loss: 0.6993\n",
      "Epoch 63/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4433 - val_loss: 0.7180\n",
      "Epoch 64/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4475 - val_loss: 0.6952\n",
      "Epoch 65/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4514 - val_loss: 0.7090\n",
      "Epoch 66/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4230 - val_loss: 0.7160\n",
      "Epoch 67/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4385 - val_loss: 0.7056\n",
      "Epoch 68/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4447 - val_loss: 0.7150\n",
      "Epoch 69/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4403 - val_loss: 0.7100\n",
      "Epoch 70/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4344 - val_loss: 0.7102\n",
      "Epoch 71/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4352 - val_loss: 0.7054\n",
      "Epoch 72/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4419 - val_loss: 0.7099\n",
      "Epoch 73/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4311 - val_loss: 0.7339\n",
      "Epoch 74/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4436 - val_loss: 0.7158\n",
      "Epoch 75/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4222 - val_loss: 0.7400\n",
      "Epoch 76/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4342 - val_loss: 0.7114\n",
      "Epoch 77/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4387 - val_loss: 0.7035\n",
      "Epoch 78/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4407 - val_loss: 0.7113\n",
      "Epoch 79/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4404 - val_loss: 0.6971\n",
      "Epoch 80/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.4348 - val_loss: 0.7222\n",
      "Epoch 81/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4364 - val_loss: 0.7244\n",
      "Epoch 82/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4445 - val_loss: 0.7220\n",
      "Epoch 83/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4387 - val_loss: 0.7249\n",
      "Epoch 84/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4325 - val_loss: 0.7269\n",
      "Epoch 85/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4376 - val_loss: 0.7170\n",
      "Epoch 86/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.4301 - val_loss: 0.7085\n",
      "Epoch 87/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4358 - val_loss: 0.7072\n",
      "Epoch 88/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.4280 - val_loss: 0.7143\n",
      "Epoch 89/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.4387 - val_loss: 0.7040\n",
      "Epoch 90/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4401 - val_loss: 0.7127\n",
      "Epoch 91/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4354 - val_loss: 0.7189\n",
      "Epoch 92/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4293 - val_loss: 0.7200\n",
      "Epoch 93/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.4507 - val_loss: 0.7371\n",
      "Epoch 94/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4247 - val_loss: 0.7263\n",
      "Epoch 95/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.4244 - val_loss: 0.7042\n",
      "Epoch 96/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.4291 - val_loss: 0.7134\n",
      "Epoch 97/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4346 - val_loss: 0.7243\n",
      "Epoch 98/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4251 - val_loss: 0.7110\n",
      "Epoch 99/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4451 - val_loss: 0.7112\n",
      "Epoch 100/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.4275 - val_loss: 0.7123\n",
      "current time:  2024-06-28_19-20\n",
      "\n",
      "\n",
      "28:mean_squared_error-label_sub 62.2%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.6939 - val_loss: 0.6773\n",
      "Epoch 2/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6425 - val_loss: 0.6736\n",
      "Epoch 3/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6299 - val_loss: 0.6629\n",
      "Epoch 4/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5839 - val_loss: 0.6690\n",
      "Epoch 5/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5740 - val_loss: 0.6614\n",
      "Epoch 6/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5600 - val_loss: 0.6760\n",
      "Epoch 7/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5491 - val_loss: 0.6725\n",
      "Epoch 8/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5195 - val_loss: 0.6637\n",
      "Epoch 9/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5171 - val_loss: 0.6784\n",
      "Epoch 10/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5156 - val_loss: 0.6901\n",
      "Epoch 11/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5085 - val_loss: 0.6687\n",
      "Epoch 12/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5102 - val_loss: 0.6849\n",
      "Epoch 13/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4998 - val_loss: 0.6875\n",
      "Epoch 14/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4815 - val_loss: 0.7032\n",
      "Epoch 15/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4869 - val_loss: 0.6824\n",
      "Epoch 16/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4862 - val_loss: 0.6863\n",
      "Epoch 17/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4748 - val_loss: 0.6959\n",
      "Epoch 18/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4676 - val_loss: 0.7116\n",
      "Epoch 19/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4801 - val_loss: 0.7070\n",
      "Epoch 20/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4648 - val_loss: 0.7019\n",
      "Epoch 21/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4743 - val_loss: 0.6959\n",
      "Epoch 22/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4675 - val_loss: 0.7019\n",
      "Epoch 23/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4565 - val_loss: 0.6918\n",
      "Epoch 24/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4685 - val_loss: 0.7033\n",
      "Epoch 25/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4522 - val_loss: 0.7092\n",
      "Epoch 26/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4435 - val_loss: 0.7105\n",
      "Epoch 27/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4572 - val_loss: 0.7070\n",
      "Epoch 28/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4502 - val_loss: 0.7126\n",
      "Epoch 29/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4408 - val_loss: 0.6980\n",
      "Epoch 30/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4555 - val_loss: 0.6979\n",
      "Epoch 31/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4470 - val_loss: 0.7112\n",
      "Epoch 32/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4446 - val_loss: 0.7059\n",
      "Epoch 33/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4473 - val_loss: 0.6907\n",
      "Epoch 34/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4485 - val_loss: 0.7115\n",
      "Epoch 35/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4494 - val_loss: 0.7274\n",
      "Epoch 36/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4505 - val_loss: 0.7236\n",
      "Epoch 37/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4550 - val_loss: 0.7137\n",
      "Epoch 38/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4468 - val_loss: 0.6966\n",
      "Epoch 39/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4393 - val_loss: 0.7277\n",
      "Epoch 40/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4518 - val_loss: 0.7046\n",
      "Epoch 41/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4453 - val_loss: 0.7010\n",
      "Epoch 42/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4426 - val_loss: 0.7214\n",
      "Epoch 43/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4463 - val_loss: 0.7015\n",
      "Epoch 44/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4575 - val_loss: 0.6974\n",
      "Epoch 45/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4379 - val_loss: 0.7106\n",
      "Epoch 46/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4427 - val_loss: 0.7172\n",
      "Epoch 47/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4402 - val_loss: 0.7028\n",
      "Epoch 48/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4302 - val_loss: 0.7264\n",
      "Epoch 49/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4354 - val_loss: 0.7114\n",
      "Epoch 50/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4386 - val_loss: 0.7095\n",
      "Epoch 51/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4465 - val_loss: 0.7150\n",
      "Epoch 52/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4339 - val_loss: 0.7019\n",
      "Epoch 53/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4190 - val_loss: 0.6937\n",
      "Epoch 54/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4248 - val_loss: 0.7093\n",
      "Epoch 55/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4505 - val_loss: 0.6986\n",
      "Epoch 56/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4236 - val_loss: 0.7086\n",
      "Epoch 57/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4324 - val_loss: 0.7140\n",
      "Epoch 58/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4222 - val_loss: 0.7052\n",
      "Epoch 59/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4272 - val_loss: 0.7310\n",
      "Epoch 60/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4397 - val_loss: 0.7161\n",
      "Epoch 61/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4387 - val_loss: 0.7068\n",
      "Epoch 62/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4273 - val_loss: 0.7132\n",
      "Epoch 63/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4325 - val_loss: 0.7231\n",
      "Epoch 64/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4247 - val_loss: 0.7018\n",
      "Epoch 65/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4419 - val_loss: 0.7146\n",
      "Epoch 66/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4435 - val_loss: 0.6964\n",
      "Epoch 67/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4332 - val_loss: 0.7032\n",
      "Epoch 68/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4256 - val_loss: 0.6966\n",
      "Epoch 69/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4301 - val_loss: 0.6957\n",
      "Epoch 70/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4428 - val_loss: 0.7040\n",
      "Epoch 71/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4310 - val_loss: 0.7070\n",
      "Epoch 72/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4217 - val_loss: 0.7128\n",
      "Epoch 73/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4374 - val_loss: 0.7218\n",
      "Epoch 74/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4244 - val_loss: 0.7079\n",
      "Epoch 75/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4328 - val_loss: 0.7097\n",
      "Epoch 76/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4307 - val_loss: 0.7102\n",
      "Epoch 77/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4240 - val_loss: 0.6969\n",
      "Epoch 78/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4316 - val_loss: 0.7015\n",
      "Epoch 79/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4358 - val_loss: 0.6974\n",
      "Epoch 80/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4388 - val_loss: 0.7080\n",
      "Epoch 81/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4198 - val_loss: 0.7219\n",
      "Epoch 82/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4199 - val_loss: 0.7112\n",
      "Epoch 83/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4296 - val_loss: 0.7192\n",
      "Epoch 84/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4225 - val_loss: 0.7068\n",
      "Epoch 85/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4276 - val_loss: 0.7163\n",
      "Epoch 86/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4268 - val_loss: 0.7101\n",
      "Epoch 87/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4276 - val_loss: 0.7121\n",
      "Epoch 88/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4356 - val_loss: 0.7116\n",
      "Epoch 89/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4383 - val_loss: 0.7030\n",
      "Epoch 90/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4307 - val_loss: 0.6993\n",
      "Epoch 91/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4286 - val_loss: 0.7010\n",
      "Epoch 92/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4219 - val_loss: 0.7071\n",
      "Epoch 93/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4307 - val_loss: 0.7173\n",
      "Epoch 94/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4265 - val_loss: 0.7216\n",
      "Epoch 95/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4378 - val_loss: 0.7169\n",
      "Epoch 96/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4287 - val_loss: 0.7309\n",
      "Epoch 97/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4195 - val_loss: 0.7316\n",
      "Epoch 98/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4133 - val_loss: 0.7240\n",
      "Epoch 99/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4255 - val_loss: 0.7185\n",
      "Epoch 100/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4267 - val_loss: 0.7093\n",
      "current time:  2024-06-28_19-21\n",
      "\n",
      "\n",
      "29:mean_squared_error-label_sub 64.4%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.7377 - val_loss: 0.6880\n",
      "Epoch 2/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6481 - val_loss: 0.6801\n",
      "Epoch 3/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6012 - val_loss: 0.6891\n",
      "Epoch 4/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5904 - val_loss: 0.6651\n",
      "Epoch 5/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5740 - val_loss: 0.6779\n",
      "Epoch 6/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5524 - val_loss: 0.6698\n",
      "Epoch 7/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5421 - val_loss: 0.6948\n",
      "Epoch 8/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5337 - val_loss: 0.6694\n",
      "Epoch 9/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5089 - val_loss: 0.6773\n",
      "Epoch 10/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5102 - val_loss: 0.7076\n",
      "Epoch 11/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5018 - val_loss: 0.6851\n",
      "Epoch 12/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5144 - val_loss: 0.6869\n",
      "Epoch 13/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4895 - val_loss: 0.6852\n",
      "Epoch 14/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4877 - val_loss: 0.7075\n",
      "Epoch 15/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5069 - val_loss: 0.6990\n",
      "Epoch 16/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4670 - val_loss: 0.6734\n",
      "Epoch 17/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4746 - val_loss: 0.6844\n",
      "Epoch 18/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4828 - val_loss: 0.6791\n",
      "Epoch 19/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4735 - val_loss: 0.6973\n",
      "Epoch 20/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4744 - val_loss: 0.6887\n",
      "Epoch 21/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4725 - val_loss: 0.6870\n",
      "Epoch 22/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4604 - val_loss: 0.7108\n",
      "Epoch 23/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4598 - val_loss: 0.7194\n",
      "Epoch 24/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4659 - val_loss: 0.7074\n",
      "Epoch 25/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4521 - val_loss: 0.6938\n",
      "Epoch 26/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4538 - val_loss: 0.7007\n",
      "Epoch 27/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4470 - val_loss: 0.7083\n",
      "Epoch 28/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4531 - val_loss: 0.6991\n",
      "Epoch 29/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4450 - val_loss: 0.6940\n",
      "Epoch 30/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4461 - val_loss: 0.7193\n",
      "Epoch 31/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4630 - val_loss: 0.7190\n",
      "Epoch 32/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4574 - val_loss: 0.7140\n",
      "Epoch 33/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4436 - val_loss: 0.7096\n",
      "Epoch 34/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4472 - val_loss: 0.7098\n",
      "Epoch 35/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4287 - val_loss: 0.7426\n",
      "Epoch 36/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4363 - val_loss: 0.7010\n",
      "Epoch 37/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4493 - val_loss: 0.7209\n",
      "Epoch 38/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4286 - val_loss: 0.7491\n",
      "Epoch 39/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4519 - val_loss: 0.7182\n",
      "Epoch 40/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4335 - val_loss: 0.7185\n",
      "Epoch 41/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4353 - val_loss: 0.7111\n",
      "Epoch 42/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4548 - val_loss: 0.7091\n",
      "Epoch 43/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4451 - val_loss: 0.7264\n",
      "Epoch 44/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4385 - val_loss: 0.7436\n",
      "Epoch 45/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4521 - val_loss: 0.7324\n",
      "Epoch 46/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4341 - val_loss: 0.7275\n",
      "Epoch 47/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4373 - val_loss: 0.7137\n",
      "Epoch 48/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4331 - val_loss: 0.7389\n",
      "Epoch 49/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4399 - val_loss: 0.7093\n",
      "Epoch 50/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4364 - val_loss: 0.7454\n",
      "Epoch 51/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4331 - val_loss: 0.7223\n",
      "Epoch 52/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4213 - val_loss: 0.7359\n",
      "Epoch 53/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4318 - val_loss: 0.7413\n",
      "Epoch 54/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4307 - val_loss: 0.7246\n",
      "Epoch 55/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4315 - val_loss: 0.7359\n",
      "Epoch 56/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4369 - val_loss: 0.7259\n",
      "Epoch 57/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4409 - val_loss: 0.7496\n",
      "Epoch 58/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4414 - val_loss: 0.7492\n",
      "Epoch 59/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4325 - val_loss: 0.7147\n",
      "Epoch 60/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4143 - val_loss: 0.7414\n",
      "Epoch 61/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4274 - val_loss: 0.7308\n",
      "Epoch 62/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4170 - val_loss: 0.7169\n",
      "Epoch 63/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4227 - val_loss: 0.7420\n",
      "Epoch 64/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4320 - val_loss: 0.7256\n",
      "Epoch 65/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4314 - val_loss: 0.7214\n",
      "Epoch 66/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4282 - val_loss: 0.7436\n",
      "Epoch 67/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4171 - val_loss: 0.7537\n",
      "Epoch 68/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4217 - val_loss: 0.7532\n",
      "Epoch 69/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4294 - val_loss: 0.7513\n",
      "Epoch 70/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4296 - val_loss: 0.7346\n",
      "Epoch 71/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4205 - val_loss: 0.7467\n",
      "Epoch 72/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4286 - val_loss: 0.7564\n",
      "Epoch 73/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4245 - val_loss: 0.7344\n",
      "Epoch 74/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4308 - val_loss: 0.7263\n",
      "Epoch 75/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4371 - val_loss: 0.7297\n",
      "Epoch 76/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4319 - val_loss: 0.7350\n",
      "Epoch 77/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4247 - val_loss: 0.7242\n",
      "Epoch 78/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4221 - val_loss: 0.7357\n",
      "Epoch 79/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4354 - val_loss: 0.7396\n",
      "Epoch 80/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4176 - val_loss: 0.7121\n",
      "Epoch 81/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4257 - val_loss: 0.7387\n",
      "Epoch 82/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4240 - val_loss: 0.7457\n",
      "Epoch 83/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4277 - val_loss: 0.7285\n",
      "Epoch 84/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4345 - val_loss: 0.7265\n",
      "Epoch 85/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4277 - val_loss: 0.7343\n",
      "Epoch 86/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4133 - val_loss: 0.7243\n",
      "Epoch 87/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4317 - val_loss: 0.7458\n",
      "Epoch 88/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4250 - val_loss: 0.7670\n",
      "Epoch 89/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4179 - val_loss: 0.7367\n",
      "Epoch 90/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4157 - val_loss: 0.7307\n",
      "Epoch 91/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4228 - val_loss: 0.7308\n",
      "Epoch 92/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4188 - val_loss: 0.7477\n",
      "Epoch 93/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4230 - val_loss: 0.7448\n",
      "Epoch 94/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4297 - val_loss: 0.7430\n",
      "Epoch 95/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4244 - val_loss: 0.7358\n",
      "Epoch 96/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4175 - val_loss: 0.7459\n",
      "Epoch 97/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4170 - val_loss: 0.7474\n",
      "Epoch 98/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4183 - val_loss: 0.7364\n",
      "Epoch 99/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4274 - val_loss: 0.7403\n",
      "Epoch 100/100\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4336 - val_loss: 0.7500\n",
      "current time:  2024-06-28_19-23\n",
      "\n",
      "\n",
      "30:mean_squared_error-label_sub 66.7%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7219 - val_loss: 0.7124\n",
      "Epoch 2/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6714 - val_loss: 0.6742\n",
      "Epoch 3/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6356 - val_loss: 0.6604\n",
      "Epoch 4/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5802 - val_loss: 0.6519\n",
      "Epoch 5/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5881 - val_loss: 0.6499\n",
      "Epoch 6/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5766 - val_loss: 0.6652\n",
      "Epoch 7/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5568 - val_loss: 0.6615\n",
      "Epoch 8/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5303 - val_loss: 0.6502\n",
      "Epoch 9/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5378 - val_loss: 0.6546\n",
      "Epoch 10/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5139 - val_loss: 0.6637\n",
      "Epoch 11/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5245 - val_loss: 0.6571\n",
      "Epoch 12/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5211 - val_loss: 0.6761\n",
      "Epoch 13/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5156 - val_loss: 0.6610\n",
      "Epoch 14/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5112 - val_loss: 0.6585\n",
      "Epoch 15/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5011 - val_loss: 0.6656\n",
      "Epoch 16/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4843 - val_loss: 0.6559\n",
      "Epoch 17/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5000 - val_loss: 0.6615\n",
      "Epoch 18/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4783 - val_loss: 0.6721\n",
      "Epoch 19/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4955 - val_loss: 0.6776\n",
      "Epoch 20/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4838 - val_loss: 0.6735\n",
      "Epoch 21/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4886 - val_loss: 0.6838\n",
      "Epoch 22/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4924 - val_loss: 0.6778\n",
      "Epoch 23/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4748 - val_loss: 0.6881\n",
      "Epoch 24/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4639 - val_loss: 0.6925\n",
      "Epoch 25/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4686 - val_loss: 0.6897\n",
      "Epoch 26/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4562 - val_loss: 0.6915\n",
      "Epoch 27/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4597 - val_loss: 0.6902\n",
      "Epoch 28/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4650 - val_loss: 0.6910\n",
      "Epoch 29/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4643 - val_loss: 0.6973\n",
      "Epoch 30/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4570 - val_loss: 0.6949\n",
      "Epoch 31/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4694 - val_loss: 0.6958\n",
      "Epoch 32/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4558 - val_loss: 0.6970\n",
      "Epoch 33/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4559 - val_loss: 0.6927\n",
      "Epoch 34/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4648 - val_loss: 0.6988\n",
      "Epoch 35/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4627 - val_loss: 0.6932\n",
      "Epoch 36/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4495 - val_loss: 0.6919\n",
      "Epoch 37/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4469 - val_loss: 0.6919\n",
      "Epoch 38/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4641 - val_loss: 0.7033\n",
      "Epoch 39/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4614 - val_loss: 0.7041\n",
      "Epoch 40/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4538 - val_loss: 0.6917\n",
      "Epoch 41/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4536 - val_loss: 0.6880\n",
      "Epoch 42/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4556 - val_loss: 0.7032\n",
      "Epoch 43/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4601 - val_loss: 0.7010\n",
      "Epoch 44/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4463 - val_loss: 0.6935\n",
      "Epoch 45/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4652 - val_loss: 0.7053\n",
      "Epoch 46/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4565 - val_loss: 0.6955\n",
      "Epoch 47/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4460 - val_loss: 0.6960\n",
      "Epoch 48/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4512 - val_loss: 0.7049\n",
      "Epoch 49/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4501 - val_loss: 0.7041\n",
      "Epoch 50/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4479 - val_loss: 0.7048\n",
      "Epoch 51/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4514 - val_loss: 0.7118\n",
      "Epoch 52/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4430 - val_loss: 0.6963\n",
      "Epoch 53/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4578 - val_loss: 0.7036\n",
      "Epoch 54/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4493 - val_loss: 0.7064\n",
      "Epoch 55/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4349 - val_loss: 0.6966\n",
      "Epoch 56/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4427 - val_loss: 0.7105\n",
      "Epoch 57/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4461 - val_loss: 0.7105\n",
      "Epoch 58/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4424 - val_loss: 0.7103\n",
      "Epoch 59/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4420 - val_loss: 0.7081\n",
      "Epoch 60/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4417 - val_loss: 0.7036\n",
      "Epoch 61/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4393 - val_loss: 0.6962\n",
      "Epoch 62/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4453 - val_loss: 0.7079\n",
      "Epoch 63/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4486 - val_loss: 0.7084\n",
      "Epoch 64/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4396 - val_loss: 0.7128\n",
      "Epoch 65/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4456 - val_loss: 0.7141\n",
      "Epoch 66/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4443 - val_loss: 0.7064\n",
      "Epoch 67/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4405 - val_loss: 0.7150\n",
      "Epoch 68/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4485 - val_loss: 0.7134\n",
      "Epoch 69/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4328 - val_loss: 0.7049\n",
      "Epoch 70/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4295 - val_loss: 0.7023\n",
      "Epoch 71/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4452 - val_loss: 0.7162\n",
      "Epoch 72/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4427 - val_loss: 0.7058\n",
      "Epoch 73/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4370 - val_loss: 0.7115\n",
      "Epoch 74/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4433 - val_loss: 0.7177\n",
      "Epoch 75/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4355 - val_loss: 0.7257\n",
      "Epoch 76/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4305 - val_loss: 0.7146\n",
      "Epoch 77/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4497 - val_loss: 0.7143\n",
      "Epoch 78/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4539 - val_loss: 0.7118\n",
      "Epoch 79/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4192 - val_loss: 0.7043\n",
      "Epoch 80/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4406 - val_loss: 0.7095\n",
      "Epoch 81/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4351 - val_loss: 0.7008\n",
      "Epoch 82/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4527 - val_loss: 0.7138\n",
      "Epoch 83/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4375 - val_loss: 0.6986\n",
      "Epoch 84/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4334 - val_loss: 0.7040\n",
      "Epoch 85/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4406 - val_loss: 0.7005\n",
      "Epoch 86/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4299 - val_loss: 0.6988\n",
      "Epoch 87/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4245 - val_loss: 0.7071\n",
      "Epoch 88/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4220 - val_loss: 0.6979\n",
      "Epoch 89/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4268 - val_loss: 0.7045\n",
      "Epoch 90/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4350 - val_loss: 0.7088\n",
      "Epoch 91/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4391 - val_loss: 0.7134\n",
      "Epoch 92/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4254 - val_loss: 0.7129\n",
      "Epoch 93/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4460 - val_loss: 0.7148\n",
      "Epoch 94/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4292 - val_loss: 0.7138\n",
      "Epoch 95/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4340 - val_loss: 0.7138\n",
      "Epoch 96/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4193 - val_loss: 0.7208\n",
      "Epoch 97/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4394 - val_loss: 0.7090\n",
      "Epoch 98/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4313 - val_loss: 0.7092\n",
      "Epoch 99/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4306 - val_loss: 0.7085\n",
      "Epoch 100/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4268 - val_loss: 0.7126\n",
      "current time:  2024-06-28_19-23\n",
      "\n",
      "\n",
      "31:mean_squared_error-label_sub 68.9%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.7123 - val_loss: 0.6934\n",
      "Epoch 2/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6580 - val_loss: 0.6768\n",
      "Epoch 3/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6272 - val_loss: 0.6606\n",
      "Epoch 4/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5822 - val_loss: 0.6581\n",
      "Epoch 5/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5788 - val_loss: 0.6746\n",
      "Epoch 6/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5709 - val_loss: 0.6559\n",
      "Epoch 7/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5447 - val_loss: 0.6731\n",
      "Epoch 8/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5311 - val_loss: 0.6627\n",
      "Epoch 9/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5260 - val_loss: 0.6655\n",
      "Epoch 10/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5265 - val_loss: 0.6877\n",
      "Epoch 11/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5154 - val_loss: 0.6703\n",
      "Epoch 12/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5052 - val_loss: 0.6856\n",
      "Epoch 13/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5032 - val_loss: 0.6905\n",
      "Epoch 14/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4797 - val_loss: 0.6818\n",
      "Epoch 15/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4813 - val_loss: 0.6906\n",
      "Epoch 16/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4928 - val_loss: 0.6995\n",
      "Epoch 17/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4832 - val_loss: 0.6908\n",
      "Epoch 18/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4933 - val_loss: 0.6886\n",
      "Epoch 19/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4692 - val_loss: 0.6929\n",
      "Epoch 20/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4658 - val_loss: 0.6813\n",
      "Epoch 21/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4636 - val_loss: 0.6941\n",
      "Epoch 22/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4719 - val_loss: 0.7090\n",
      "Epoch 23/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4668 - val_loss: 0.7113\n",
      "Epoch 24/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4582 - val_loss: 0.7107\n",
      "Epoch 25/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4650 - val_loss: 0.7286\n",
      "Epoch 26/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4701 - val_loss: 0.6930\n",
      "Epoch 27/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4464 - val_loss: 0.7087\n",
      "Epoch 28/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4660 - val_loss: 0.7019\n",
      "Epoch 29/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4460 - val_loss: 0.7141\n",
      "Epoch 30/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4471 - val_loss: 0.7219\n",
      "Epoch 31/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4515 - val_loss: 0.7260\n",
      "Epoch 32/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4506 - val_loss: 0.6873\n",
      "Epoch 33/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4479 - val_loss: 0.7043\n",
      "Epoch 34/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4655 - val_loss: 0.7095\n",
      "Epoch 35/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4538 - val_loss: 0.7007\n",
      "Epoch 36/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4372 - val_loss: 0.7152\n",
      "Epoch 37/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4389 - val_loss: 0.7018\n",
      "Epoch 38/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4443 - val_loss: 0.7087\n",
      "Epoch 39/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4345 - val_loss: 0.6996\n",
      "Epoch 40/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4447 - val_loss: 0.6965\n",
      "Epoch 41/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4391 - val_loss: 0.6997\n",
      "Epoch 42/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4345 - val_loss: 0.7180\n",
      "Epoch 43/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4363 - val_loss: 0.7011\n",
      "Epoch 44/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4516 - val_loss: 0.6937\n",
      "Epoch 45/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4350 - val_loss: 0.7004\n",
      "Epoch 46/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4512 - val_loss: 0.6989\n",
      "Epoch 47/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4486 - val_loss: 0.7091\n",
      "Epoch 48/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4380 - val_loss: 0.7008\n",
      "Epoch 49/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4328 - val_loss: 0.7063\n",
      "Epoch 50/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4429 - val_loss: 0.6985\n",
      "Epoch 51/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4345 - val_loss: 0.6994\n",
      "Epoch 52/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4277 - val_loss: 0.7022\n",
      "Epoch 53/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4406 - val_loss: 0.7023\n",
      "Epoch 54/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4364 - val_loss: 0.7150\n",
      "Epoch 55/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4286 - val_loss: 0.7136\n",
      "Epoch 56/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4299 - val_loss: 0.7089\n",
      "Epoch 57/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4360 - val_loss: 0.7001\n",
      "Epoch 58/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4479 - val_loss: 0.7054\n",
      "Epoch 59/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4518 - val_loss: 0.7134\n",
      "Epoch 60/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4388 - val_loss: 0.7035\n",
      "Epoch 61/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4445 - val_loss: 0.7195\n",
      "Epoch 62/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4376 - val_loss: 0.7152\n",
      "Epoch 63/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4293 - val_loss: 0.7184\n",
      "Epoch 64/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4316 - val_loss: 0.7074\n",
      "Epoch 65/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4285 - val_loss: 0.7164\n",
      "Epoch 66/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4343 - val_loss: 0.7338\n",
      "Epoch 67/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4412 - val_loss: 0.7173\n",
      "Epoch 68/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4407 - val_loss: 0.7060\n",
      "Epoch 69/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4347 - val_loss: 0.7109\n",
      "Epoch 70/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4250 - val_loss: 0.7195\n",
      "Epoch 71/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4229 - val_loss: 0.6881\n",
      "Epoch 72/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4332 - val_loss: 0.7089\n",
      "Epoch 73/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4332 - val_loss: 0.7061\n",
      "Epoch 74/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4327 - val_loss: 0.7074\n",
      "Epoch 75/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4421 - val_loss: 0.7120\n",
      "Epoch 76/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4261 - val_loss: 0.7060\n",
      "Epoch 77/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4291 - val_loss: 0.7157\n",
      "Epoch 78/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4271 - val_loss: 0.7052\n",
      "Epoch 79/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4264 - val_loss: 0.7069\n",
      "Epoch 80/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4429 - val_loss: 0.7019\n",
      "Epoch 81/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4311 - val_loss: 0.7234\n",
      "Epoch 82/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4349 - val_loss: 0.6996\n",
      "Epoch 83/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4302 - val_loss: 0.7160\n",
      "Epoch 84/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4249 - val_loss: 0.7106\n",
      "Epoch 85/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4115 - val_loss: 0.7216\n",
      "Epoch 86/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4209 - val_loss: 0.7145\n",
      "Epoch 87/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4399 - val_loss: 0.6977\n",
      "Epoch 88/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4346 - val_loss: 0.7157\n",
      "Epoch 89/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4132 - val_loss: 0.7230\n",
      "Epoch 90/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4258 - val_loss: 0.7156\n",
      "Epoch 91/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4283 - val_loss: 0.7142\n",
      "Epoch 92/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4252 - val_loss: 0.7157\n",
      "Epoch 93/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4328 - val_loss: 0.6959\n",
      "Epoch 94/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4253 - val_loss: 0.7030\n",
      "Epoch 95/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4159 - val_loss: 0.7144\n",
      "Epoch 96/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4308 - val_loss: 0.7048\n",
      "Epoch 97/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4257 - val_loss: 0.7081\n",
      "Epoch 98/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4106 - val_loss: 0.7087\n",
      "Epoch 99/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4290 - val_loss: 0.7131\n",
      "Epoch 100/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4292 - val_loss: 0.7185\n",
      "current time:  2024-06-28_19-23\n",
      "\n",
      "\n",
      "32:mean_squared_error-label_sub 71.1%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7055 - val_loss: 0.6949\n",
      "Epoch 2/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6614 - val_loss: 0.6845\n",
      "Epoch 3/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6229 - val_loss: 0.6700\n",
      "Epoch 4/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5859 - val_loss: 0.6644\n",
      "Epoch 5/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5817 - val_loss: 0.6810\n",
      "Epoch 6/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5458 - val_loss: 0.6604\n",
      "Epoch 7/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5410 - val_loss: 0.6558\n",
      "Epoch 8/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5190 - val_loss: 0.6651\n",
      "Epoch 9/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5316 - val_loss: 0.6755\n",
      "Epoch 10/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5146 - val_loss: 0.6842\n",
      "Epoch 11/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4818 - val_loss: 0.6709\n",
      "Epoch 12/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5084 - val_loss: 0.6850\n",
      "Epoch 13/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4877 - val_loss: 0.6783\n",
      "Epoch 14/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4813 - val_loss: 0.6911\n",
      "Epoch 15/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4738 - val_loss: 0.6844\n",
      "Epoch 16/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4928 - val_loss: 0.7094\n",
      "Epoch 17/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4887 - val_loss: 0.7241\n",
      "Epoch 18/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4730 - val_loss: 0.6918\n",
      "Epoch 19/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4644 - val_loss: 0.6870\n",
      "Epoch 20/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4779 - val_loss: 0.6984\n",
      "Epoch 21/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4537 - val_loss: 0.7081\n",
      "Epoch 22/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4601 - val_loss: 0.7194\n",
      "Epoch 23/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4723 - val_loss: 0.7066\n",
      "Epoch 24/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4494 - val_loss: 0.7171\n",
      "Epoch 25/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4371 - val_loss: 0.6963\n",
      "Epoch 26/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4440 - val_loss: 0.7152\n",
      "Epoch 27/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4527 - val_loss: 0.7273\n",
      "Epoch 28/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4526 - val_loss: 0.7064\n",
      "Epoch 29/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4563 - val_loss: 0.7096\n",
      "Epoch 30/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4481 - val_loss: 0.7109\n",
      "Epoch 31/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4543 - val_loss: 0.7265\n",
      "Epoch 32/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4469 - val_loss: 0.6975\n",
      "Epoch 33/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4446 - val_loss: 0.7073\n",
      "Epoch 34/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4491 - val_loss: 0.7106\n",
      "Epoch 35/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4498 - val_loss: 0.7053\n",
      "Epoch 36/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4457 - val_loss: 0.7228\n",
      "Epoch 37/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4399 - val_loss: 0.7223\n",
      "Epoch 38/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4281 - val_loss: 0.7261\n",
      "Epoch 39/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4508 - val_loss: 0.7076\n",
      "Epoch 40/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4331 - val_loss: 0.7192\n",
      "Epoch 41/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4302 - val_loss: 0.7229\n",
      "Epoch 42/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4441 - val_loss: 0.7083\n",
      "Epoch 43/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4435 - val_loss: 0.7271\n",
      "Epoch 44/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4307 - val_loss: 0.7169\n",
      "Epoch 45/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4433 - val_loss: 0.7096\n",
      "Epoch 46/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4349 - val_loss: 0.7212\n",
      "Epoch 47/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4262 - val_loss: 0.7072\n",
      "Epoch 48/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4256 - val_loss: 0.6969\n",
      "Epoch 49/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4324 - val_loss: 0.7171\n",
      "Epoch 50/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4348 - val_loss: 0.7190\n",
      "Epoch 51/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4284 - val_loss: 0.7172\n",
      "Epoch 52/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4319 - val_loss: 0.7094\n",
      "Epoch 53/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4311 - val_loss: 0.7074\n",
      "Epoch 54/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4342 - val_loss: 0.7228\n",
      "Epoch 55/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4371 - val_loss: 0.7004\n",
      "Epoch 56/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4131 - val_loss: 0.7061\n",
      "Epoch 57/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4240 - val_loss: 0.7122\n",
      "Epoch 58/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4221 - val_loss: 0.7114\n",
      "Epoch 59/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4216 - val_loss: 0.7181\n",
      "Epoch 60/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4390 - val_loss: 0.6993\n",
      "Epoch 61/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4273 - val_loss: 0.7188\n",
      "Epoch 62/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4180 - val_loss: 0.7203\n",
      "Epoch 63/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4358 - val_loss: 0.7196\n",
      "Epoch 64/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4216 - val_loss: 0.7098\n",
      "Epoch 65/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4318 - val_loss: 0.7199\n",
      "Epoch 66/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4140 - val_loss: 0.7018\n",
      "Epoch 67/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4286 - val_loss: 0.7214\n",
      "Epoch 68/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4294 - val_loss: 0.7103\n",
      "Epoch 69/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4315 - val_loss: 0.7104\n",
      "Epoch 70/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4278 - val_loss: 0.7020\n",
      "Epoch 71/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4165 - val_loss: 0.7036\n",
      "Epoch 72/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4161 - val_loss: 0.7167\n",
      "Epoch 73/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4221 - val_loss: 0.7053\n",
      "Epoch 74/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4173 - val_loss: 0.7011\n",
      "Epoch 75/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4142 - val_loss: 0.7192\n",
      "Epoch 76/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4268 - val_loss: 0.7145\n",
      "Epoch 77/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4200 - val_loss: 0.7006\n",
      "Epoch 78/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4267 - val_loss: 0.7196\n",
      "Epoch 79/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4255 - val_loss: 0.7046\n",
      "Epoch 80/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4200 - val_loss: 0.7196\n",
      "Epoch 81/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4130 - val_loss: 0.7128\n",
      "Epoch 82/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4198 - val_loss: 0.7116\n",
      "Epoch 83/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4140 - val_loss: 0.7032\n",
      "Epoch 84/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4115 - val_loss: 0.7140\n",
      "Epoch 85/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4098 - val_loss: 0.7127\n",
      "Epoch 86/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4157 - val_loss: 0.7157\n",
      "Epoch 87/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4217 - val_loss: 0.6982\n",
      "Epoch 88/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4088 - val_loss: 0.7172\n",
      "Epoch 89/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4034 - val_loss: 0.7087\n",
      "Epoch 90/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4065 - val_loss: 0.7157\n",
      "Epoch 91/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4177 - val_loss: 0.7098\n",
      "Epoch 92/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4190 - val_loss: 0.7048\n",
      "Epoch 93/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4184 - val_loss: 0.7094\n",
      "Epoch 94/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4170 - val_loss: 0.7033\n",
      "Epoch 95/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4181 - val_loss: 0.7098\n",
      "Epoch 96/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4112 - val_loss: 0.7188\n",
      "Epoch 97/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4223 - val_loss: 0.7227\n",
      "Epoch 98/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4183 - val_loss: 0.7060\n",
      "Epoch 99/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4373 - val_loss: 0.7192\n",
      "Epoch 100/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4142 - val_loss: 0.7091\n",
      "current time:  2024-06-28_19-24\n",
      "\n",
      "\n",
      "33:mean_squared_error-label_sub 73.3%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.7088 - val_loss: 0.7290\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6852 - val_loss: 0.7232\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6778 - val_loss: 0.7086\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6468 - val_loss: 0.6947\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6167 - val_loss: 0.6827\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6132 - val_loss: 0.6827\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6091 - val_loss: 0.6662\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5781 - val_loss: 0.6557\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5933 - val_loss: 0.6716\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5855 - val_loss: 0.6563\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5694 - val_loss: 0.6586\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5591 - val_loss: 0.6577\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5443 - val_loss: 0.6646\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5399 - val_loss: 0.6691\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5426 - val_loss: 0.6913\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5579 - val_loss: 0.6651\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5456 - val_loss: 0.6594\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5321 - val_loss: 0.6721\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5520 - val_loss: 0.6609\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5145 - val_loss: 0.6671\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5188 - val_loss: 0.6609\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5154 - val_loss: 0.6658\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5092 - val_loss: 0.6675\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5158 - val_loss: 0.6654\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4849 - val_loss: 0.6614\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5007 - val_loss: 0.6696\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4929 - val_loss: 0.6828\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5096 - val_loss: 0.6700\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4873 - val_loss: 0.6741\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4822 - val_loss: 0.6810\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4893 - val_loss: 0.6775\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4932 - val_loss: 0.6805\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4895 - val_loss: 0.6971\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5044 - val_loss: 0.6866\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4860 - val_loss: 0.6773\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4675 - val_loss: 0.6933\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4925 - val_loss: 0.6873\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4828 - val_loss: 0.6879\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4758 - val_loss: 0.6984\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4707 - val_loss: 0.6979\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4491 - val_loss: 0.6999\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4703 - val_loss: 0.7057\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4644 - val_loss: 0.6968\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4578 - val_loss: 0.7128\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4622 - val_loss: 0.7126\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4690 - val_loss: 0.7149\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4731 - val_loss: 0.7053\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4543 - val_loss: 0.7079\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4834 - val_loss: 0.7024\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4597 - val_loss: 0.6972\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4597 - val_loss: 0.7076\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4595 - val_loss: 0.7096\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4685 - val_loss: 0.7036\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4591 - val_loss: 0.7052\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4572 - val_loss: 0.7144\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4551 - val_loss: 0.7093\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4687 - val_loss: 0.7171\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4527 - val_loss: 0.7071\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4412 - val_loss: 0.7264\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4685 - val_loss: 0.7094\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4475 - val_loss: 0.7129\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4648 - val_loss: 0.7036\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4560 - val_loss: 0.7079\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4471 - val_loss: 0.7128\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4468 - val_loss: 0.7211\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4722 - val_loss: 0.7132\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4610 - val_loss: 0.7123\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4483 - val_loss: 0.7155\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4434 - val_loss: 0.7120\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4475 - val_loss: 0.7120\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4531 - val_loss: 0.7190\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4557 - val_loss: 0.7268\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4439 - val_loss: 0.7218\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4624 - val_loss: 0.7199\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4429 - val_loss: 0.7366\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4779 - val_loss: 0.7173\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4511 - val_loss: 0.7177\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4491 - val_loss: 0.7167\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4488 - val_loss: 0.7134\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4430 - val_loss: 0.7192\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4548 - val_loss: 0.7163\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4403 - val_loss: 0.7169\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4377 - val_loss: 0.7158\n",
      "Epoch 84/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4572 - val_loss: 0.7211\n",
      "Epoch 85/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4585 - val_loss: 0.7092\n",
      "Epoch 86/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4379 - val_loss: 0.7159\n",
      "Epoch 87/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4444 - val_loss: 0.7210\n",
      "Epoch 88/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4387 - val_loss: 0.7231\n",
      "Epoch 89/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4359 - val_loss: 0.7177\n",
      "Epoch 90/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4486 - val_loss: 0.7199\n",
      "Epoch 91/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4433 - val_loss: 0.7310\n",
      "Epoch 92/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4434 - val_loss: 0.7167\n",
      "Epoch 93/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4432 - val_loss: 0.7221\n",
      "Epoch 94/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4514 - val_loss: 0.7168\n",
      "Epoch 95/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4472 - val_loss: 0.7224\n",
      "Epoch 96/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4310 - val_loss: 0.7130\n",
      "Epoch 97/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4286 - val_loss: 0.7159\n",
      "Epoch 98/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4245 - val_loss: 0.7209\n",
      "Epoch 99/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4341 - val_loss: 0.7313\n",
      "Epoch 100/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4483 - val_loss: 0.7184\n",
      "current time:  2024-06-28_19-24\n",
      "\n",
      "\n",
      "34:mean_squared_error-label_sub 75.6%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7235 - val_loss: 0.7120\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6648 - val_loss: 0.6952\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6399 - val_loss: 0.6872\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6394 - val_loss: 0.6683\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6092 - val_loss: 0.6518\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5919 - val_loss: 0.6487\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5889 - val_loss: 0.6591\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5748 - val_loss: 0.6559\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5708 - val_loss: 0.6614\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5593 - val_loss: 0.6566\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5495 - val_loss: 0.6514\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5366 - val_loss: 0.6575\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5521 - val_loss: 0.6352\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5391 - val_loss: 0.6462\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5159 - val_loss: 0.6505\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5148 - val_loss: 0.6501\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5031 - val_loss: 0.6541\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5331 - val_loss: 0.6744\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5119 - val_loss: 0.6641\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5058 - val_loss: 0.6578\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5054 - val_loss: 0.6664\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4892 - val_loss: 0.6713\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4877 - val_loss: 0.6715\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4918 - val_loss: 0.6637\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4952 - val_loss: 0.6764\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4795 - val_loss: 0.6803\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4751 - val_loss: 0.6888\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4774 - val_loss: 0.6851\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4882 - val_loss: 0.6767\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4736 - val_loss: 0.6836\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4802 - val_loss: 0.6911\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4981 - val_loss: 0.6811\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4636 - val_loss: 0.6818\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4657 - val_loss: 0.6919\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4503 - val_loss: 0.6978\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4612 - val_loss: 0.6862\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4598 - val_loss: 0.6946\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4693 - val_loss: 0.7052\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4589 - val_loss: 0.6951\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4668 - val_loss: 0.6939\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4752 - val_loss: 0.7169\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4683 - val_loss: 0.6973\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4611 - val_loss: 0.7116\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4668 - val_loss: 0.6931\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4443 - val_loss: 0.6955\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4408 - val_loss: 0.7018\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4591 - val_loss: 0.6942\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4416 - val_loss: 0.7021\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4509 - val_loss: 0.7031\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4606 - val_loss: 0.7090\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4605 - val_loss: 0.7066\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4585 - val_loss: 0.7011\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4420 - val_loss: 0.7046\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4461 - val_loss: 0.7004\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4567 - val_loss: 0.7043\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4547 - val_loss: 0.7057\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4391 - val_loss: 0.7146\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4443 - val_loss: 0.7094\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4510 - val_loss: 0.7061\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4403 - val_loss: 0.7024\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4387 - val_loss: 0.7159\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4492 - val_loss: 0.7108\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4418 - val_loss: 0.7203\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4447 - val_loss: 0.7121\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4384 - val_loss: 0.7024\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4299 - val_loss: 0.7140\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4385 - val_loss: 0.6999\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4471 - val_loss: 0.7101\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4523 - val_loss: 0.7094\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4416 - val_loss: 0.7150\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4360 - val_loss: 0.7082\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4434 - val_loss: 0.6994\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4346 - val_loss: 0.7056\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4516 - val_loss: 0.7065\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4536 - val_loss: 0.7109\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4495 - val_loss: 0.7119\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4484 - val_loss: 0.6957\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4358 - val_loss: 0.7034\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4354 - val_loss: 0.7105\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4413 - val_loss: 0.7005\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4301 - val_loss: 0.7012\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4322 - val_loss: 0.7070\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4336 - val_loss: 0.7097\n",
      "Epoch 84/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4378 - val_loss: 0.7050\n",
      "Epoch 85/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4391 - val_loss: 0.7104\n",
      "Epoch 86/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4271 - val_loss: 0.7070\n",
      "Epoch 87/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4408 - val_loss: 0.7077\n",
      "Epoch 88/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4277 - val_loss: 0.7095\n",
      "Epoch 89/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4353 - val_loss: 0.7167\n",
      "Epoch 90/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4458 - val_loss: 0.7170\n",
      "Epoch 91/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4240 - val_loss: 0.7077\n",
      "Epoch 92/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4244 - val_loss: 0.7049\n",
      "Epoch 93/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4242 - val_loss: 0.7118\n",
      "Epoch 94/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4310 - val_loss: 0.7061\n",
      "Epoch 95/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4308 - val_loss: 0.7286\n",
      "Epoch 96/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4528 - val_loss: 0.7315\n",
      "Epoch 97/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4291 - val_loss: 0.7187\n",
      "Epoch 98/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4492 - val_loss: 0.7172\n",
      "Epoch 99/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4249 - val_loss: 0.7081\n",
      "Epoch 100/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4313 - val_loss: 0.7180\n",
      "current time:  2024-06-28_19-24\n",
      "\n",
      "\n",
      "35:mean_squared_error-label_sub 77.8%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.7409 - val_loss: 0.7346\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6885 - val_loss: 0.7198\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6681 - val_loss: 0.7008\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6382 - val_loss: 0.6683\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5985 - val_loss: 0.6685\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5915 - val_loss: 0.6541\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5677 - val_loss: 0.6519\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5436 - val_loss: 0.6472\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5555 - val_loss: 0.6479\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5402 - val_loss: 0.6473\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5481 - val_loss: 0.6671\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5361 - val_loss: 0.6539\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5320 - val_loss: 0.6550\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5362 - val_loss: 0.6554\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5167 - val_loss: 0.6549\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5080 - val_loss: 0.6708\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5181 - val_loss: 0.6673\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5173 - val_loss: 0.6695\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4952 - val_loss: 0.6671\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5000 - val_loss: 0.6678\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4892 - val_loss: 0.6729\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4956 - val_loss: 0.6662\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4854 - val_loss: 0.6682\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4720 - val_loss: 0.6855\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4671 - val_loss: 0.6769\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4653 - val_loss: 0.6745\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4705 - val_loss: 0.6679\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4656 - val_loss: 0.6870\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4855 - val_loss: 0.6868\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4667 - val_loss: 0.6763\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4504 - val_loss: 0.6846\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4564 - val_loss: 0.6926\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4638 - val_loss: 0.6927\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4599 - val_loss: 0.6907\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4566 - val_loss: 0.7030\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4695 - val_loss: 0.6877\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4523 - val_loss: 0.7016\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4681 - val_loss: 0.7052\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4563 - val_loss: 0.7054\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4459 - val_loss: 0.6875\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4524 - val_loss: 0.7026\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4626 - val_loss: 0.6931\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4396 - val_loss: 0.6985\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4366 - val_loss: 0.6943\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4412 - val_loss: 0.6913\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4510 - val_loss: 0.7009\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4319 - val_loss: 0.6907\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4526 - val_loss: 0.6859\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4295 - val_loss: 0.6917\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4375 - val_loss: 0.7033\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4505 - val_loss: 0.6983\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4292 - val_loss: 0.6990\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4345 - val_loss: 0.7062\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4369 - val_loss: 0.7088\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4423 - val_loss: 0.6946\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4380 - val_loss: 0.6979\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4435 - val_loss: 0.6951\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4321 - val_loss: 0.6997\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4287 - val_loss: 0.6984\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4330 - val_loss: 0.7050\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4321 - val_loss: 0.7056\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4445 - val_loss: 0.7076\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4361 - val_loss: 0.7176\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4394 - val_loss: 0.7070\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4330 - val_loss: 0.7103\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4248 - val_loss: 0.7001\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4347 - val_loss: 0.6990\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4354 - val_loss: 0.6976\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4284 - val_loss: 0.6995\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4359 - val_loss: 0.7173\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4424 - val_loss: 0.7170\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4321 - val_loss: 0.7057\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4316 - val_loss: 0.7064\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4378 - val_loss: 0.7057\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4205 - val_loss: 0.7154\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4224 - val_loss: 0.7084\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4236 - val_loss: 0.6881\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4359 - val_loss: 0.7071\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4216 - val_loss: 0.7136\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4352 - val_loss: 0.7091\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4303 - val_loss: 0.7301\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4291 - val_loss: 0.7097\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4245 - val_loss: 0.7125\n",
      "Epoch 84/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4354 - val_loss: 0.7121\n",
      "Epoch 85/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4277 - val_loss: 0.7140\n",
      "Epoch 86/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4297 - val_loss: 0.7130\n",
      "Epoch 87/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4263 - val_loss: 0.7173\n",
      "Epoch 88/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4300 - val_loss: 0.6993\n",
      "Epoch 89/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4234 - val_loss: 0.7369\n",
      "Epoch 90/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4391 - val_loss: 0.7178\n",
      "Epoch 91/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4229 - val_loss: 0.7226\n",
      "Epoch 92/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4220 - val_loss: 0.7152\n",
      "Epoch 93/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4237 - val_loss: 0.7157\n",
      "Epoch 94/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4219 - val_loss: 0.7066\n",
      "Epoch 95/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4197 - val_loss: 0.7119\n",
      "Epoch 96/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4334 - val_loss: 0.7163\n",
      "Epoch 97/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4237 - val_loss: 0.7180\n",
      "Epoch 98/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4241 - val_loss: 0.7116\n",
      "Epoch 99/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4342 - val_loss: 0.7090\n",
      "Epoch 100/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4263 - val_loss: 0.7179\n",
      "current time:  2024-06-28_19-25\n",
      "\n",
      "\n",
      "36:mean_squared_error-label_sub 80.0%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.7241 - val_loss: 0.6997\n",
      "Epoch 2/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6318 - val_loss: 0.6903\n",
      "Epoch 3/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.6061 - val_loss: 0.6737\n",
      "Epoch 4/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5880 - val_loss: 0.6857\n",
      "Epoch 5/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5785 - val_loss: 0.6774\n",
      "Epoch 6/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5496 - val_loss: 0.6666\n",
      "Epoch 7/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.5450 - val_loss: 0.6739\n",
      "Epoch 8/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.5370 - val_loss: 0.6829\n",
      "Epoch 9/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.5526 - val_loss: 0.6747\n",
      "Epoch 10/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.5331 - val_loss: 0.6703\n",
      "Epoch 11/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5125 - val_loss: 0.6923\n",
      "Epoch 12/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.5219 - val_loss: 0.6871\n",
      "Epoch 13/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.5050 - val_loss: 0.6815\n",
      "Epoch 14/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5054 - val_loss: 0.6792\n",
      "Epoch 15/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.4976 - val_loss: 0.6771\n",
      "Epoch 16/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5028 - val_loss: 0.6804\n",
      "Epoch 17/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.5048 - val_loss: 0.6785\n",
      "Epoch 18/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.4965 - val_loss: 0.6758\n",
      "Epoch 19/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.4935 - val_loss: 0.6789\n",
      "Epoch 20/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.4780 - val_loss: 0.6887\n",
      "Epoch 21/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.4755 - val_loss: 0.6876\n",
      "Epoch 22/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4820 - val_loss: 0.6793\n",
      "Epoch 23/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.4758 - val_loss: 0.6919\n",
      "Epoch 24/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.4780 - val_loss: 0.6783\n",
      "Epoch 25/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4742 - val_loss: 0.6950\n",
      "Epoch 26/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.4792 - val_loss: 0.6887\n",
      "Epoch 27/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4771 - val_loss: 0.6787\n",
      "Epoch 28/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.4767 - val_loss: 0.6843\n",
      "Epoch 29/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4764 - val_loss: 0.6945\n",
      "Epoch 30/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.4657 - val_loss: 0.6889\n",
      "Epoch 31/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4633 - val_loss: 0.6863\n",
      "Epoch 32/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4626 - val_loss: 0.6969\n",
      "Epoch 33/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.4553 - val_loss: 0.6873\n",
      "Epoch 34/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4713 - val_loss: 0.6688\n",
      "Epoch 35/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.4693 - val_loss: 0.6922\n",
      "Epoch 36/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.4551 - val_loss: 0.6779\n",
      "Epoch 37/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4707 - val_loss: 0.6853\n",
      "Epoch 38/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.4587 - val_loss: 0.6803\n",
      "Epoch 39/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.4541 - val_loss: 0.6888\n",
      "Epoch 40/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4475 - val_loss: 0.6892\n",
      "Epoch 41/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.4576 - val_loss: 0.6987\n",
      "Epoch 42/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4513 - val_loss: 0.6893\n",
      "Epoch 43/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.4508 - val_loss: 0.6893\n",
      "Epoch 44/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.4407 - val_loss: 0.7022\n",
      "Epoch 45/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4581 - val_loss: 0.6872\n",
      "Epoch 46/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.4575 - val_loss: 0.7138\n",
      "Epoch 47/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.4420 - val_loss: 0.6863\n",
      "Epoch 48/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4417 - val_loss: 0.6866\n",
      "Epoch 49/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.4474 - val_loss: 0.6970\n",
      "Epoch 50/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.4640 - val_loss: 0.6928\n",
      "Epoch 51/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4568 - val_loss: 0.6884\n",
      "Epoch 52/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4444 - val_loss: 0.6826\n",
      "Epoch 53/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4402 - val_loss: 0.6953\n",
      "Epoch 54/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4436 - val_loss: 0.6965\n",
      "Epoch 55/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4454 - val_loss: 0.6834\n",
      "Epoch 56/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.4491 - val_loss: 0.6923\n",
      "Epoch 57/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4457 - val_loss: 0.6808\n",
      "Epoch 58/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4373 - val_loss: 0.6786\n",
      "Epoch 59/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4470 - val_loss: 0.6952\n",
      "Epoch 60/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4650 - val_loss: 0.7028\n",
      "Epoch 61/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4458 - val_loss: 0.6978\n",
      "Epoch 62/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.4497 - val_loss: 0.6978\n",
      "Epoch 63/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4421 - val_loss: 0.6923\n",
      "Epoch 64/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 0.4467 - val_loss: 0.6883\n",
      "Epoch 65/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4439 - val_loss: 0.6956\n",
      "Epoch 66/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.4455 - val_loss: 0.6941\n",
      "Epoch 67/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4355 - val_loss: 0.6903\n",
      "Epoch 68/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4481 - val_loss: 0.6950\n",
      "Epoch 69/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4518 - val_loss: 0.6908\n",
      "Epoch 70/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.4209 - val_loss: 0.6915\n",
      "Epoch 71/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4360 - val_loss: 0.7048\n",
      "Epoch 72/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.4394 - val_loss: 0.7055\n",
      "Epoch 73/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4310 - val_loss: 0.6914\n",
      "Epoch 74/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.4506 - val_loss: 0.7002\n",
      "Epoch 75/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.4493 - val_loss: 0.7018\n",
      "Epoch 76/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4454 - val_loss: 0.7058\n",
      "Epoch 77/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.4345 - val_loss: 0.7113\n",
      "Epoch 78/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4403 - val_loss: 0.6978\n",
      "Epoch 79/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.4472 - val_loss: 0.6869\n",
      "Epoch 80/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.4313 - val_loss: 0.6885\n",
      "Epoch 81/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4398 - val_loss: 0.7018\n",
      "Epoch 82/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4273 - val_loss: 0.7053\n",
      "Epoch 83/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4356 - val_loss: 0.7120\n",
      "Epoch 84/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4355 - val_loss: 0.7119\n",
      "Epoch 85/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4445 - val_loss: 0.7173\n",
      "Epoch 86/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.4186 - val_loss: 0.7186\n",
      "Epoch 87/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4362 - val_loss: 0.7111\n",
      "Epoch 88/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4438 - val_loss: 0.7108\n",
      "Epoch 89/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.4293 - val_loss: 0.7046\n",
      "Epoch 90/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4499 - val_loss: 0.7017\n",
      "Epoch 91/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.4425 - val_loss: 0.7008\n",
      "Epoch 92/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4417 - val_loss: 0.6995\n",
      "Epoch 93/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4337 - val_loss: 0.6998\n",
      "Epoch 94/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.4262 - val_loss: 0.6973\n",
      "Epoch 95/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4292 - val_loss: 0.7062\n",
      "Epoch 96/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4413 - val_loss: 0.7057\n",
      "Epoch 97/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4378 - val_loss: 0.7253\n",
      "Epoch 98/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4304 - val_loss: 0.6889\n",
      "Epoch 99/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4317 - val_loss: 0.7033\n",
      "Epoch 100/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.4400 - val_loss: 0.7154\n",
      "current time:  2024-06-28_19-25\n",
      "\n",
      "\n",
      "37:mean_squared_error-label_sub 82.2%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.7024 - val_loss: 0.7147\n",
      "Epoch 2/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6348 - val_loss: 0.7059\n",
      "Epoch 3/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6133 - val_loss: 0.6789\n",
      "Epoch 4/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5834 - val_loss: 0.7000\n",
      "Epoch 5/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5581 - val_loss: 0.6675\n",
      "Epoch 6/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5547 - val_loss: 0.6858\n",
      "Epoch 7/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5306 - val_loss: 0.6795\n",
      "Epoch 8/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5251 - val_loss: 0.6666\n",
      "Epoch 9/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.5174 - val_loss: 0.6741\n",
      "Epoch 10/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5230 - val_loss: 0.6743\n",
      "Epoch 11/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5048 - val_loss: 0.6632\n",
      "Epoch 12/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5164 - val_loss: 0.6765\n",
      "Epoch 13/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.5054 - val_loss: 0.6818\n",
      "Epoch 14/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4987 - val_loss: 0.6770\n",
      "Epoch 15/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.4981 - val_loss: 0.6941\n",
      "Epoch 16/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.4941 - val_loss: 0.6780\n",
      "Epoch 17/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4867 - val_loss: 0.6806\n",
      "Epoch 18/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.4747 - val_loss: 0.6895\n",
      "Epoch 19/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.4823 - val_loss: 0.6758\n",
      "Epoch 20/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.4852 - val_loss: 0.6975\n",
      "Epoch 21/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4780 - val_loss: 0.6793\n",
      "Epoch 22/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4729 - val_loss: 0.6883\n",
      "Epoch 23/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4606 - val_loss: 0.6946\n",
      "Epoch 24/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4656 - val_loss: 0.6973\n",
      "Epoch 25/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4648 - val_loss: 0.6949\n",
      "Epoch 26/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4662 - val_loss: 0.6850\n",
      "Epoch 27/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4695 - val_loss: 0.6848\n",
      "Epoch 28/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4701 - val_loss: 0.6923\n",
      "Epoch 29/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4440 - val_loss: 0.7161\n",
      "Epoch 30/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4677 - val_loss: 0.7037\n",
      "Epoch 31/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4566 - val_loss: 0.6991\n",
      "Epoch 32/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4507 - val_loss: 0.6849\n",
      "Epoch 33/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4541 - val_loss: 0.6882\n",
      "Epoch 34/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4527 - val_loss: 0.7029\n",
      "Epoch 35/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4461 - val_loss: 0.6788\n",
      "Epoch 36/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4532 - val_loss: 0.6930\n",
      "Epoch 37/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4500 - val_loss: 0.7041\n",
      "Epoch 38/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4421 - val_loss: 0.6955\n",
      "Epoch 39/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4349 - val_loss: 0.6896\n",
      "Epoch 40/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4370 - val_loss: 0.6900\n",
      "Epoch 41/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4374 - val_loss: 0.7017\n",
      "Epoch 42/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4545 - val_loss: 0.6869\n",
      "Epoch 43/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.4402 - val_loss: 0.7000\n",
      "Epoch 44/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4319 - val_loss: 0.6906\n",
      "Epoch 45/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4520 - val_loss: 0.6931\n",
      "Epoch 46/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.4481 - val_loss: 0.7060\n",
      "Epoch 47/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4497 - val_loss: 0.7083\n",
      "Epoch 48/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4305 - val_loss: 0.7135\n",
      "Epoch 49/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4286 - val_loss: 0.7087\n",
      "Epoch 50/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4476 - val_loss: 0.6949\n",
      "Epoch 51/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4449 - val_loss: 0.7078\n",
      "Epoch 52/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4576 - val_loss: 0.7056\n",
      "Epoch 53/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4369 - val_loss: 0.6970\n",
      "Epoch 54/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4432 - val_loss: 0.6909\n",
      "Epoch 55/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4250 - val_loss: 0.6956\n",
      "Epoch 56/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4344 - val_loss: 0.6991\n",
      "Epoch 57/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4330 - val_loss: 0.7169\n",
      "Epoch 58/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4374 - val_loss: 0.6994\n",
      "Epoch 59/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4366 - val_loss: 0.6887\n",
      "Epoch 60/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4391 - val_loss: 0.7006\n",
      "Epoch 61/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4360 - val_loss: 0.6849\n",
      "Epoch 62/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4403 - val_loss: 0.6977\n",
      "Epoch 63/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.4422 - val_loss: 0.6965\n",
      "Epoch 64/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4294 - val_loss: 0.7008\n",
      "Epoch 65/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4343 - val_loss: 0.6914\n",
      "Epoch 66/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4205 - val_loss: 0.6916\n",
      "Epoch 67/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4343 - val_loss: 0.6880\n",
      "Epoch 68/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4301 - val_loss: 0.6967\n",
      "Epoch 69/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4362 - val_loss: 0.7086\n",
      "Epoch 70/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4347 - val_loss: 0.7053\n",
      "Epoch 71/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.4183 - val_loss: 0.7018\n",
      "Epoch 72/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4419 - val_loss: 0.7035\n",
      "Epoch 73/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4295 - val_loss: 0.7056\n",
      "Epoch 74/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4412 - val_loss: 0.7109\n",
      "Epoch 75/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4347 - val_loss: 0.6925\n",
      "Epoch 76/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4286 - val_loss: 0.7004\n",
      "Epoch 77/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4298 - val_loss: 0.6900\n",
      "Epoch 78/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4298 - val_loss: 0.7012\n",
      "Epoch 79/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4384 - val_loss: 0.6997\n",
      "Epoch 80/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4349 - val_loss: 0.7137\n",
      "Epoch 81/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4256 - val_loss: 0.7112\n",
      "Epoch 82/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4285 - val_loss: 0.7056\n",
      "Epoch 83/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4301 - val_loss: 0.6992\n",
      "Epoch 84/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4263 - val_loss: 0.7184\n",
      "Epoch 85/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4248 - val_loss: 0.7036\n",
      "Epoch 86/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4261 - val_loss: 0.6982\n",
      "Epoch 87/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4174 - val_loss: 0.6981\n",
      "Epoch 88/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4262 - val_loss: 0.6983\n",
      "Epoch 89/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4287 - val_loss: 0.7129\n",
      "Epoch 90/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4205 - val_loss: 0.6974\n",
      "Epoch 91/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.4316 - val_loss: 0.6973\n",
      "Epoch 92/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4280 - val_loss: 0.6962\n",
      "Epoch 93/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.4191 - val_loss: 0.7033\n",
      "Epoch 94/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4340 - val_loss: 0.6991\n",
      "Epoch 95/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4329 - val_loss: 0.7008\n",
      "Epoch 96/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4211 - val_loss: 0.7060\n",
      "Epoch 97/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4341 - val_loss: 0.7026\n",
      "Epoch 98/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.4249 - val_loss: 0.6935\n",
      "Epoch 99/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4144 - val_loss: 0.6942\n",
      "Epoch 100/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4218 - val_loss: 0.6953\n",
      "current time:  2024-06-28_19-26\n",
      "\n",
      "\n",
      "38:mean_squared_error-label_sub 84.4%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.7222 - val_loss: 0.7424\n",
      "Epoch 2/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6374 - val_loss: 0.6841\n",
      "Epoch 3/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6046 - val_loss: 0.6997\n",
      "Epoch 4/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5802 - val_loss: 0.6928\n",
      "Epoch 5/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5878 - val_loss: 0.6836\n",
      "Epoch 6/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5557 - val_loss: 0.6770\n",
      "Epoch 7/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5376 - val_loss: 0.6956\n",
      "Epoch 8/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5483 - val_loss: 0.6735\n",
      "Epoch 9/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5265 - val_loss: 0.6768\n",
      "Epoch 10/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5246 - val_loss: 0.6826\n",
      "Epoch 11/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5192 - val_loss: 0.6744\n",
      "Epoch 12/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5121 - val_loss: 0.6739\n",
      "Epoch 13/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4958 - val_loss: 0.6736\n",
      "Epoch 14/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5079 - val_loss: 0.6972\n",
      "Epoch 15/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4913 - val_loss: 0.6695\n",
      "Epoch 16/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4964 - val_loss: 0.6913\n",
      "Epoch 17/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4879 - val_loss: 0.6855\n",
      "Epoch 18/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4977 - val_loss: 0.6896\n",
      "Epoch 19/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4778 - val_loss: 0.6957\n",
      "Epoch 20/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4795 - val_loss: 0.6842\n",
      "Epoch 21/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4832 - val_loss: 0.6957\n",
      "Epoch 22/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4724 - val_loss: 0.7124\n",
      "Epoch 23/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4628 - val_loss: 0.6987\n",
      "Epoch 24/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4529 - val_loss: 0.7043\n",
      "Epoch 25/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4635 - val_loss: 0.6883\n",
      "Epoch 26/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4660 - val_loss: 0.6893\n",
      "Epoch 27/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4463 - val_loss: 0.6859\n",
      "Epoch 28/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4574 - val_loss: 0.6811\n",
      "Epoch 29/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4549 - val_loss: 0.6949\n",
      "Epoch 30/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4726 - val_loss: 0.6850\n",
      "Epoch 31/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4592 - val_loss: 0.7046\n",
      "Epoch 32/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4509 - val_loss: 0.6850\n",
      "Epoch 33/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4543 - val_loss: 0.6864\n",
      "Epoch 34/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4534 - val_loss: 0.6820\n",
      "Epoch 35/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4426 - val_loss: 0.6905\n",
      "Epoch 36/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4400 - val_loss: 0.6798\n",
      "Epoch 37/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4508 - val_loss: 0.7086\n",
      "Epoch 38/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4525 - val_loss: 0.6880\n",
      "Epoch 39/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4463 - val_loss: 0.6960\n",
      "Epoch 40/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4397 - val_loss: 0.6995\n",
      "Epoch 41/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4437 - val_loss: 0.6871\n",
      "Epoch 42/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4467 - val_loss: 0.7007\n",
      "Epoch 43/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4495 - val_loss: 0.6866\n",
      "Epoch 44/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4472 - val_loss: 0.6971\n",
      "Epoch 45/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4352 - val_loss: 0.7075\n",
      "Epoch 46/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4436 - val_loss: 0.6874\n",
      "Epoch 47/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4273 - val_loss: 0.7207\n",
      "Epoch 48/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4428 - val_loss: 0.7127\n",
      "Epoch 49/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4325 - val_loss: 0.7238\n",
      "Epoch 50/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4390 - val_loss: 0.7097\n",
      "Epoch 51/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4344 - val_loss: 0.6863\n",
      "Epoch 52/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4483 - val_loss: 0.7011\n",
      "Epoch 53/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4361 - val_loss: 0.7050\n",
      "Epoch 54/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4323 - val_loss: 0.6949\n",
      "Epoch 55/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4356 - val_loss: 0.6978\n",
      "Epoch 56/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4185 - val_loss: 0.7227\n",
      "Epoch 57/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4354 - val_loss: 0.6960\n",
      "Epoch 58/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4429 - val_loss: 0.7056\n",
      "Epoch 59/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4360 - val_loss: 0.7015\n",
      "Epoch 60/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4374 - val_loss: 0.6989\n",
      "Epoch 61/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4345 - val_loss: 0.6958\n",
      "Epoch 62/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4131 - val_loss: 0.6940\n",
      "Epoch 63/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4206 - val_loss: 0.7335\n",
      "Epoch 64/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4361 - val_loss: 0.7172\n",
      "Epoch 65/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4267 - val_loss: 0.6878\n",
      "Epoch 66/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4310 - val_loss: 0.7033\n",
      "Epoch 67/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4283 - val_loss: 0.7059\n",
      "Epoch 68/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4335 - val_loss: 0.7005\n",
      "Epoch 69/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4267 - val_loss: 0.7135\n",
      "Epoch 70/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4314 - val_loss: 0.7151\n",
      "Epoch 71/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4365 - val_loss: 0.6933\n",
      "Epoch 72/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4251 - val_loss: 0.7068\n",
      "Epoch 73/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4381 - val_loss: 0.6857\n",
      "Epoch 74/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4231 - val_loss: 0.7181\n",
      "Epoch 75/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4256 - val_loss: 0.6910\n",
      "Epoch 76/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4439 - val_loss: 0.6951\n",
      "Epoch 77/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4227 - val_loss: 0.7003\n",
      "Epoch 78/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4230 - val_loss: 0.7150\n",
      "Epoch 79/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4331 - val_loss: 0.6842\n",
      "Epoch 80/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4281 - val_loss: 0.7132\n",
      "Epoch 81/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4267 - val_loss: 0.7040\n",
      "Epoch 82/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4233 - val_loss: 0.7058\n",
      "Epoch 83/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4229 - val_loss: 0.6946\n",
      "Epoch 84/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4257 - val_loss: 0.6993\n",
      "Epoch 85/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4165 - val_loss: 0.6898\n",
      "Epoch 86/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4241 - val_loss: 0.6910\n",
      "Epoch 87/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4266 - val_loss: 0.7092\n",
      "Epoch 88/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4318 - val_loss: 0.6851\n",
      "Epoch 89/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4269 - val_loss: 0.6905\n",
      "Epoch 90/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4234 - val_loss: 0.6996\n",
      "Epoch 91/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4189 - val_loss: 0.7045\n",
      "Epoch 92/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4205 - val_loss: 0.7295\n",
      "Epoch 93/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4292 - val_loss: 0.7149\n",
      "Epoch 94/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4155 - val_loss: 0.7120\n",
      "Epoch 95/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4251 - val_loss: 0.6931\n",
      "Epoch 96/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4228 - val_loss: 0.6848\n",
      "Epoch 97/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4195 - val_loss: 0.7072\n",
      "Epoch 98/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4163 - val_loss: 0.6948\n",
      "Epoch 99/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4280 - val_loss: 0.6992\n",
      "Epoch 100/100\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4060 - val_loss: 0.7039\n",
      "current time:  2024-06-28_19-28\n",
      "\n",
      "\n",
      "39:mean_squared_error-label_sub 86.7%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7075 - val_loss: 0.7265\n",
      "Epoch 2/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6433 - val_loss: 0.7191\n",
      "Epoch 3/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6354 - val_loss: 0.6882\n",
      "Epoch 4/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6027 - val_loss: 0.6845\n",
      "Epoch 5/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5850 - val_loss: 0.6755\n",
      "Epoch 6/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5678 - val_loss: 0.6694\n",
      "Epoch 7/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5559 - val_loss: 0.6769\n",
      "Epoch 8/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5477 - val_loss: 0.6754\n",
      "Epoch 9/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5306 - val_loss: 0.6836\n",
      "Epoch 10/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5241 - val_loss: 0.6682\n",
      "Epoch 11/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5163 - val_loss: 0.6825\n",
      "Epoch 12/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5234 - val_loss: 0.6732\n",
      "Epoch 13/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5117 - val_loss: 0.6634\n",
      "Epoch 14/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5029 - val_loss: 0.6775\n",
      "Epoch 15/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5304 - val_loss: 0.6755\n",
      "Epoch 16/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5003 - val_loss: 0.6648\n",
      "Epoch 17/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5081 - val_loss: 0.6808\n",
      "Epoch 18/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4881 - val_loss: 0.6723\n",
      "Epoch 19/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4990 - val_loss: 0.6834\n",
      "Epoch 20/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4891 - val_loss: 0.6750\n",
      "Epoch 21/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4938 - val_loss: 0.6809\n",
      "Epoch 22/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4857 - val_loss: 0.6763\n",
      "Epoch 23/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4869 - val_loss: 0.6744\n",
      "Epoch 24/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4809 - val_loss: 0.6796\n",
      "Epoch 25/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4711 - val_loss: 0.6815\n",
      "Epoch 26/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4935 - val_loss: 0.6822\n",
      "Epoch 27/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4591 - val_loss: 0.6879\n",
      "Epoch 28/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4683 - val_loss: 0.6865\n",
      "Epoch 29/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4938 - val_loss: 0.6862\n",
      "Epoch 30/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4679 - val_loss: 0.6868\n",
      "Epoch 31/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4729 - val_loss: 0.6854\n",
      "Epoch 32/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4744 - val_loss: 0.6836\n",
      "Epoch 33/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4704 - val_loss: 0.7017\n",
      "Epoch 34/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4682 - val_loss: 0.6850\n",
      "Epoch 35/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4730 - val_loss: 0.6890\n",
      "Epoch 36/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4502 - val_loss: 0.6907\n",
      "Epoch 37/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4645 - val_loss: 0.7022\n",
      "Epoch 38/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4578 - val_loss: 0.6891\n",
      "Epoch 39/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4554 - val_loss: 0.7065\n",
      "Epoch 40/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4729 - val_loss: 0.7035\n",
      "Epoch 41/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4655 - val_loss: 0.7108\n",
      "Epoch 42/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4449 - val_loss: 0.6996\n",
      "Epoch 43/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4663 - val_loss: 0.6926\n",
      "Epoch 44/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4590 - val_loss: 0.7042\n",
      "Epoch 45/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4445 - val_loss: 0.7033\n",
      "Epoch 46/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4521 - val_loss: 0.7036\n",
      "Epoch 47/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4551 - val_loss: 0.7061\n",
      "Epoch 48/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4559 - val_loss: 0.7102\n",
      "Epoch 49/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4487 - val_loss: 0.6996\n",
      "Epoch 50/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4531 - val_loss: 0.7164\n",
      "Epoch 51/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4545 - val_loss: 0.7080\n",
      "Epoch 52/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4407 - val_loss: 0.6938\n",
      "Epoch 53/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4564 - val_loss: 0.6991\n",
      "Epoch 54/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4573 - val_loss: 0.6982\n",
      "Epoch 55/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4584 - val_loss: 0.7006\n",
      "Epoch 56/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4501 - val_loss: 0.7116\n",
      "Epoch 57/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4501 - val_loss: 0.7005\n",
      "Epoch 58/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4531 - val_loss: 0.7092\n",
      "Epoch 59/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4473 - val_loss: 0.7133\n",
      "Epoch 60/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4324 - val_loss: 0.7076\n",
      "Epoch 61/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4475 - val_loss: 0.6896\n",
      "Epoch 62/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4440 - val_loss: 0.7077\n",
      "Epoch 63/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4497 - val_loss: 0.7028\n",
      "Epoch 64/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4267 - val_loss: 0.7022\n",
      "Epoch 65/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4415 - val_loss: 0.7252\n",
      "Epoch 66/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4475 - val_loss: 0.6986\n",
      "Epoch 67/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4436 - val_loss: 0.6981\n",
      "Epoch 68/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4508 - val_loss: 0.7165\n",
      "Epoch 69/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4462 - val_loss: 0.7040\n",
      "Epoch 70/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4255 - val_loss: 0.7086\n",
      "Epoch 71/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4486 - val_loss: 0.7072\n",
      "Epoch 72/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4489 - val_loss: 0.7039\n",
      "Epoch 73/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4375 - val_loss: 0.7010\n",
      "Epoch 74/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4300 - val_loss: 0.7087\n",
      "Epoch 75/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4509 - val_loss: 0.7196\n",
      "Epoch 76/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4491 - val_loss: 0.7078\n",
      "Epoch 77/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4328 - val_loss: 0.7012\n",
      "Epoch 78/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4311 - val_loss: 0.7090\n",
      "Epoch 79/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4382 - val_loss: 0.7131\n",
      "Epoch 80/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4399 - val_loss: 0.7074\n",
      "Epoch 81/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4429 - val_loss: 0.7048\n",
      "Epoch 82/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4201 - val_loss: 0.7105\n",
      "Epoch 83/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4322 - val_loss: 0.7025\n",
      "Epoch 84/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4329 - val_loss: 0.7118\n",
      "Epoch 85/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4324 - val_loss: 0.7097\n",
      "Epoch 86/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4334 - val_loss: 0.7134\n",
      "Epoch 87/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4349 - val_loss: 0.7126\n",
      "Epoch 88/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4264 - val_loss: 0.7112\n",
      "Epoch 89/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4374 - val_loss: 0.6950\n",
      "Epoch 90/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4436 - val_loss: 0.7060\n",
      "Epoch 91/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4263 - val_loss: 0.7042\n",
      "Epoch 92/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4308 - val_loss: 0.7027\n",
      "Epoch 93/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4442 - val_loss: 0.7040\n",
      "Epoch 94/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4225 - val_loss: 0.7109\n",
      "Epoch 95/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4320 - val_loss: 0.7042\n",
      "Epoch 96/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4435 - val_loss: 0.7033\n",
      "Epoch 97/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4392 - val_loss: 0.7137\n",
      "Epoch 98/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4349 - val_loss: 0.7146\n",
      "Epoch 99/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4461 - val_loss: 0.7145\n",
      "Epoch 100/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4351 - val_loss: 0.7110\n",
      "current time:  2024-06-28_19-28\n",
      "\n",
      "\n",
      "40:mean_squared_error-label_sub 88.9%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7267 - val_loss: 0.7190\n",
      "Epoch 2/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6360 - val_loss: 0.7064\n",
      "Epoch 3/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5946 - val_loss: 0.6826\n",
      "Epoch 4/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5908 - val_loss: 0.6822\n",
      "Epoch 5/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5628 - val_loss: 0.6947\n",
      "Epoch 6/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5462 - val_loss: 0.6719\n",
      "Epoch 7/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5507 - val_loss: 0.6618\n",
      "Epoch 8/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5234 - val_loss: 0.6776\n",
      "Epoch 9/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5378 - val_loss: 0.6847\n",
      "Epoch 10/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5378 - val_loss: 0.6805\n",
      "Epoch 11/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5180 - val_loss: 0.6733\n",
      "Epoch 12/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4993 - val_loss: 0.6891\n",
      "Epoch 13/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5120 - val_loss: 0.6917\n",
      "Epoch 14/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4984 - val_loss: 0.6918\n",
      "Epoch 15/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4996 - val_loss: 0.6839\n",
      "Epoch 16/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4903 - val_loss: 0.6850\n",
      "Epoch 17/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4900 - val_loss: 0.7101\n",
      "Epoch 18/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4910 - val_loss: 0.7214\n",
      "Epoch 19/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4927 - val_loss: 0.6944\n",
      "Epoch 20/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4791 - val_loss: 0.6939\n",
      "Epoch 21/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4783 - val_loss: 0.6964\n",
      "Epoch 22/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4777 - val_loss: 0.6877\n",
      "Epoch 23/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4796 - val_loss: 0.7044\n",
      "Epoch 24/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4737 - val_loss: 0.7046\n",
      "Epoch 25/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4899 - val_loss: 0.6896\n",
      "Epoch 26/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4669 - val_loss: 0.7004\n",
      "Epoch 27/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4622 - val_loss: 0.7082\n",
      "Epoch 28/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4718 - val_loss: 0.7005\n",
      "Epoch 29/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4600 - val_loss: 0.7118\n",
      "Epoch 30/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4568 - val_loss: 0.6832\n",
      "Epoch 31/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4582 - val_loss: 0.7020\n",
      "Epoch 32/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4611 - val_loss: 0.6998\n",
      "Epoch 33/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4645 - val_loss: 0.6994\n",
      "Epoch 34/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4658 - val_loss: 0.7052\n",
      "Epoch 35/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4386 - val_loss: 0.7277\n",
      "Epoch 36/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4562 - val_loss: 0.7109\n",
      "Epoch 37/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4599 - val_loss: 0.7033\n",
      "Epoch 38/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4492 - val_loss: 0.7090\n",
      "Epoch 39/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4428 - val_loss: 0.7239\n",
      "Epoch 40/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4432 - val_loss: 0.7143\n",
      "Epoch 41/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4418 - val_loss: 0.7031\n",
      "Epoch 42/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4494 - val_loss: 0.7108\n",
      "Epoch 43/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4404 - val_loss: 0.7337\n",
      "Epoch 44/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4425 - val_loss: 0.7098\n",
      "Epoch 45/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4423 - val_loss: 0.7236\n",
      "Epoch 46/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4376 - val_loss: 0.7129\n",
      "Epoch 47/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4359 - val_loss: 0.7099\n",
      "Epoch 48/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4354 - val_loss: 0.7136\n",
      "Epoch 49/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4416 - val_loss: 0.7049\n",
      "Epoch 50/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4416 - val_loss: 0.7214\n",
      "Epoch 51/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4331 - val_loss: 0.6969\n",
      "Epoch 52/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4357 - val_loss: 0.7135\n",
      "Epoch 53/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4356 - val_loss: 0.7169\n",
      "Epoch 54/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4244 - val_loss: 0.7008\n",
      "Epoch 55/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4426 - val_loss: 0.7104\n",
      "Epoch 56/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4465 - val_loss: 0.7012\n",
      "Epoch 57/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4399 - val_loss: 0.7080\n",
      "Epoch 58/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4397 - val_loss: 0.7058\n",
      "Epoch 59/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4481 - val_loss: 0.7015\n",
      "Epoch 60/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4450 - val_loss: 0.7071\n",
      "Epoch 61/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4456 - val_loss: 0.7071\n",
      "Epoch 62/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4238 - val_loss: 0.7053\n",
      "Epoch 63/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4315 - val_loss: 0.7274\n",
      "Epoch 64/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4488 - val_loss: 0.7183\n",
      "Epoch 65/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4398 - val_loss: 0.7017\n",
      "Epoch 66/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4381 - val_loss: 0.7116\n",
      "Epoch 67/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4340 - val_loss: 0.7432\n",
      "Epoch 68/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4283 - val_loss: 0.7265\n",
      "Epoch 69/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4255 - val_loss: 0.7283\n",
      "Epoch 70/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4382 - val_loss: 0.7084\n",
      "Epoch 71/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4370 - val_loss: 0.7280\n",
      "Epoch 72/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4229 - val_loss: 0.7119\n",
      "Epoch 73/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4354 - val_loss: 0.7143\n",
      "Epoch 74/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4326 - val_loss: 0.7035\n",
      "Epoch 75/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4327 - val_loss: 0.7104\n",
      "Epoch 76/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4222 - val_loss: 0.7229\n",
      "Epoch 77/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4413 - val_loss: 0.7212\n",
      "Epoch 78/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4324 - val_loss: 0.7052\n",
      "Epoch 79/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4286 - val_loss: 0.7073\n",
      "Epoch 80/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4427 - val_loss: 0.7114\n",
      "Epoch 81/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4229 - val_loss: 0.7155\n",
      "Epoch 82/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4396 - val_loss: 0.7180\n",
      "Epoch 83/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4225 - val_loss: 0.7131\n",
      "Epoch 84/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4256 - val_loss: 0.7234\n",
      "Epoch 85/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4283 - val_loss: 0.7336\n",
      "Epoch 86/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4252 - val_loss: 0.7146\n",
      "Epoch 87/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4322 - val_loss: 0.7182\n",
      "Epoch 88/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4276 - val_loss: 0.7131\n",
      "Epoch 89/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4166 - val_loss: 0.7093\n",
      "Epoch 90/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4260 - val_loss: 0.7194\n",
      "Epoch 91/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4327 - val_loss: 0.7037\n",
      "Epoch 92/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4327 - val_loss: 0.7127\n",
      "Epoch 93/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4311 - val_loss: 0.7093\n",
      "Epoch 94/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4298 - val_loss: 0.7019\n",
      "Epoch 95/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4359 - val_loss: 0.7198\n",
      "Epoch 96/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4334 - val_loss: 0.7192\n",
      "Epoch 97/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4174 - val_loss: 0.7184\n",
      "Epoch 98/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4206 - val_loss: 0.7262\n",
      "Epoch 99/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4282 - val_loss: 0.7226\n",
      "Epoch 100/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4479 - val_loss: 0.7000\n",
      "current time:  2024-06-28_19-28\n",
      "\n",
      "\n",
      "41:mean_squared_error-label_sub 91.1%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7283 - val_loss: 0.7191\n",
      "Epoch 2/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6436 - val_loss: 0.7006\n",
      "Epoch 3/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6300 - val_loss: 0.6799\n",
      "Epoch 4/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5858 - val_loss: 0.6824\n",
      "Epoch 5/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5554 - val_loss: 0.6777\n",
      "Epoch 6/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5747 - val_loss: 0.6715\n",
      "Epoch 7/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5368 - val_loss: 0.6660\n",
      "Epoch 8/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5400 - val_loss: 0.6658\n",
      "Epoch 9/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5271 - val_loss: 0.6682\n",
      "Epoch 10/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5260 - val_loss: 0.6717\n",
      "Epoch 11/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5324 - val_loss: 0.6728\n",
      "Epoch 12/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5164 - val_loss: 0.6714\n",
      "Epoch 13/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5142 - val_loss: 0.6720\n",
      "Epoch 14/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5057 - val_loss: 0.6779\n",
      "Epoch 15/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4982 - val_loss: 0.6936\n",
      "Epoch 16/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4934 - val_loss: 0.6804\n",
      "Epoch 17/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4857 - val_loss: 0.6753\n",
      "Epoch 18/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4891 - val_loss: 0.6764\n",
      "Epoch 19/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4906 - val_loss: 0.6768\n",
      "Epoch 20/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4885 - val_loss: 0.6750\n",
      "Epoch 21/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4634 - val_loss: 0.6833\n",
      "Epoch 22/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4736 - val_loss: 0.6987\n",
      "Epoch 23/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4703 - val_loss: 0.6998\n",
      "Epoch 24/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4588 - val_loss: 0.6844\n",
      "Epoch 25/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4724 - val_loss: 0.7026\n",
      "Epoch 26/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4556 - val_loss: 0.6907\n",
      "Epoch 27/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4499 - val_loss: 0.6986\n",
      "Epoch 28/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4515 - val_loss: 0.6881\n",
      "Epoch 29/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4405 - val_loss: 0.6859\n",
      "Epoch 30/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4647 - val_loss: 0.6904\n",
      "Epoch 31/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4449 - val_loss: 0.6795\n",
      "Epoch 32/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4510 - val_loss: 0.6808\n",
      "Epoch 33/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4342 - val_loss: 0.7000\n",
      "Epoch 34/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4481 - val_loss: 0.6928\n",
      "Epoch 35/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4457 - val_loss: 0.6804\n",
      "Epoch 36/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4449 - val_loss: 0.6944\n",
      "Epoch 37/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4367 - val_loss: 0.6969\n",
      "Epoch 38/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4428 - val_loss: 0.6982\n",
      "Epoch 39/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4268 - val_loss: 0.6884\n",
      "Epoch 40/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4458 - val_loss: 0.6905\n",
      "Epoch 41/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4314 - val_loss: 0.6876\n",
      "Epoch 42/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4339 - val_loss: 0.6915\n",
      "Epoch 43/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4417 - val_loss: 0.6941\n",
      "Epoch 44/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4302 - val_loss: 0.6955\n",
      "Epoch 45/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4291 - val_loss: 0.6880\n",
      "Epoch 46/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4405 - val_loss: 0.6965\n",
      "Epoch 47/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4294 - val_loss: 0.7019\n",
      "Epoch 48/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4357 - val_loss: 0.7046\n",
      "Epoch 49/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4280 - val_loss: 0.7091\n",
      "Epoch 50/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4268 - val_loss: 0.7008\n",
      "Epoch 51/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4452 - val_loss: 0.6899\n",
      "Epoch 52/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4258 - val_loss: 0.7193\n",
      "Epoch 53/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4255 - val_loss: 0.7182\n",
      "Epoch 54/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4325 - val_loss: 0.6946\n",
      "Epoch 55/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4325 - val_loss: 0.6938\n",
      "Epoch 56/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4325 - val_loss: 0.7069\n",
      "Epoch 57/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4228 - val_loss: 0.7062\n",
      "Epoch 58/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4282 - val_loss: 0.7067\n",
      "Epoch 59/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4383 - val_loss: 0.6954\n",
      "Epoch 60/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4313 - val_loss: 0.6933\n",
      "Epoch 61/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4335 - val_loss: 0.7043\n",
      "Epoch 62/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4313 - val_loss: 0.7059\n",
      "Epoch 63/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4309 - val_loss: 0.6926\n",
      "Epoch 64/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4382 - val_loss: 0.6848\n",
      "Epoch 65/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4385 - val_loss: 0.7146\n",
      "Epoch 66/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4371 - val_loss: 0.6908\n",
      "Epoch 67/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4386 - val_loss: 0.7039\n",
      "Epoch 68/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4248 - val_loss: 0.7193\n",
      "Epoch 69/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4109 - val_loss: 0.7122\n",
      "Epoch 70/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4266 - val_loss: 0.7056\n",
      "Epoch 71/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4235 - val_loss: 0.7071\n",
      "Epoch 72/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4304 - val_loss: 0.7064\n",
      "Epoch 73/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4169 - val_loss: 0.6975\n",
      "Epoch 74/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4167 - val_loss: 0.7187\n",
      "Epoch 75/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4288 - val_loss: 0.7169\n",
      "Epoch 76/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4263 - val_loss: 0.6894\n",
      "Epoch 77/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4242 - val_loss: 0.6892\n",
      "Epoch 78/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4262 - val_loss: 0.7109\n",
      "Epoch 79/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4131 - val_loss: 0.6899\n",
      "Epoch 80/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4248 - val_loss: 0.7090\n",
      "Epoch 81/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4113 - val_loss: 0.6834\n",
      "Epoch 82/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4155 - val_loss: 0.7238\n",
      "Epoch 83/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4285 - val_loss: 0.7179\n",
      "Epoch 84/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4331 - val_loss: 0.7029\n",
      "Epoch 85/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4209 - val_loss: 0.7089\n",
      "Epoch 86/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4255 - val_loss: 0.7119\n",
      "Epoch 87/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4139 - val_loss: 0.7120\n",
      "Epoch 88/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4166 - val_loss: 0.7306\n",
      "Epoch 89/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4162 - val_loss: 0.6928\n",
      "Epoch 90/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4247 - val_loss: 0.6979\n",
      "Epoch 91/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4219 - val_loss: 0.7176\n",
      "Epoch 92/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4245 - val_loss: 0.7057\n",
      "Epoch 93/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4175 - val_loss: 0.7083\n",
      "Epoch 94/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4185 - val_loss: 0.7061\n",
      "Epoch 95/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4139 - val_loss: 0.7176\n",
      "Epoch 96/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4296 - val_loss: 0.7164\n",
      "Epoch 97/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4259 - val_loss: 0.7008\n",
      "Epoch 98/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4190 - val_loss: 0.6988\n",
      "Epoch 99/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4099 - val_loss: 0.6943\n",
      "Epoch 100/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4116 - val_loss: 0.7021\n",
      "current time:  2024-06-28_19-29\n",
      "\n",
      "\n",
      "42:mean_squared_error-label_sub 93.3%, ensemble: dna_encoded, nodes: [128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.7321 - val_loss: 0.7301\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6746 - val_loss: 0.7221\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6478 - val_loss: 0.7119\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6518 - val_loss: 0.6959\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6116 - val_loss: 0.6943\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6020 - val_loss: 0.6947\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6004 - val_loss: 0.6848\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5738 - val_loss: 0.6813\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5668 - val_loss: 0.6959\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5693 - val_loss: 0.6759\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5478 - val_loss: 0.6770\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5445 - val_loss: 0.6845\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5505 - val_loss: 0.6707\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5288 - val_loss: 0.6745\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5377 - val_loss: 0.6676\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5330 - val_loss: 0.6714\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5187 - val_loss: 0.6655\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5135 - val_loss: 0.6688\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5313 - val_loss: 0.6705\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5188 - val_loss: 0.6724\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5177 - val_loss: 0.6755\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5059 - val_loss: 0.6717\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5096 - val_loss: 0.6692\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4934 - val_loss: 0.6660\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5057 - val_loss: 0.6714\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4991 - val_loss: 0.6923\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5186 - val_loss: 0.6673\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5162 - val_loss: 0.6737\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5071 - val_loss: 0.6726\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5001 - val_loss: 0.6796\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4907 - val_loss: 0.6780\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5007 - val_loss: 0.6832\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4836 - val_loss: 0.6813\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4851 - val_loss: 0.6765\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4633 - val_loss: 0.6847\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4866 - val_loss: 0.6793\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4743 - val_loss: 0.6865\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4960 - val_loss: 0.6775\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4764 - val_loss: 0.6837\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4954 - val_loss: 0.6807\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4747 - val_loss: 0.6990\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4953 - val_loss: 0.6886\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4796 - val_loss: 0.6863\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4832 - val_loss: 0.6813\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4855 - val_loss: 0.6934\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4695 - val_loss: 0.6865\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4878 - val_loss: 0.6844\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4763 - val_loss: 0.6791\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4698 - val_loss: 0.6832\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4516 - val_loss: 0.6822\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4610 - val_loss: 0.6939\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4634 - val_loss: 0.6864\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4564 - val_loss: 0.6997\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4741 - val_loss: 0.6915\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4592 - val_loss: 0.6879\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4524 - val_loss: 0.6858\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4641 - val_loss: 0.6993\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5072 - val_loss: 0.6827\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4541 - val_loss: 0.6955\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4822 - val_loss: 0.6984\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4697 - val_loss: 0.7085\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4642 - val_loss: 0.7007\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4716 - val_loss: 0.6940\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4615 - val_loss: 0.6869\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4690 - val_loss: 0.6801\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4622 - val_loss: 0.6884\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4506 - val_loss: 0.6872\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4500 - val_loss: 0.6883\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4530 - val_loss: 0.6943\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4466 - val_loss: 0.6916\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4626 - val_loss: 0.6842\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4638 - val_loss: 0.6909\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4669 - val_loss: 0.6919\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4552 - val_loss: 0.7032\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4591 - val_loss: 0.6960\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4575 - val_loss: 0.7014\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4650 - val_loss: 0.6953\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4585 - val_loss: 0.7002\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4520 - val_loss: 0.6951\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4524 - val_loss: 0.6868\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4337 - val_loss: 0.6910\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4568 - val_loss: 0.7100\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4711 - val_loss: 0.7071\n",
      "Epoch 84/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4462 - val_loss: 0.7304\n",
      "Epoch 85/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4847 - val_loss: 0.6842\n",
      "Epoch 86/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4602 - val_loss: 0.6914\n",
      "Epoch 87/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4485 - val_loss: 0.6919\n",
      "Epoch 88/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4461 - val_loss: 0.6917\n",
      "Epoch 89/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4546 - val_loss: 0.6938\n",
      "Epoch 90/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4490 - val_loss: 0.7058\n",
      "Epoch 91/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4612 - val_loss: 0.7272\n",
      "Epoch 92/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4788 - val_loss: 0.6988\n",
      "Epoch 93/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4458 - val_loss: 0.6911\n",
      "Epoch 94/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4400 - val_loss: 0.6868\n",
      "Epoch 95/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4509 - val_loss: 0.6924\n",
      "Epoch 96/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4536 - val_loss: 0.6913\n",
      "Epoch 97/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4467 - val_loss: 0.6862\n",
      "Epoch 98/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4470 - val_loss: 0.6894\n",
      "Epoch 99/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4428 - val_loss: 0.6887\n",
      "Epoch 100/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4575 - val_loss: 0.7031\n",
      "current time:  2024-06-28_19-29\n",
      "\n",
      "\n",
      "43:mean_squared_error-label_sub 95.6%, ensemble: dna_encoded, nodes: [256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7246 - val_loss: 0.7272\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6919 - val_loss: 0.7274\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6469 - val_loss: 0.7118\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6358 - val_loss: 0.6883\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6078 - val_loss: 0.6756\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5856 - val_loss: 0.6754\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5759 - val_loss: 0.6719\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5799 - val_loss: 0.6665\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5672 - val_loss: 0.6761\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5446 - val_loss: 0.6596\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5507 - val_loss: 0.6582\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5289 - val_loss: 0.6621\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5400 - val_loss: 0.6820\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5260 - val_loss: 0.6691\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5258 - val_loss: 0.6686\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5233 - val_loss: 0.6694\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5222 - val_loss: 0.6777\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5288 - val_loss: 0.6741\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5257 - val_loss: 0.6753\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5187 - val_loss: 0.6719\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5255 - val_loss: 0.6651\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5110 - val_loss: 0.6701\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5069 - val_loss: 0.6696\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4944 - val_loss: 0.6710\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4975 - val_loss: 0.6762\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5043 - val_loss: 0.6893\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4837 - val_loss: 0.6835\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4920 - val_loss: 0.6823\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4870 - val_loss: 0.6686\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4715 - val_loss: 0.6804\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4762 - val_loss: 0.6784\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4915 - val_loss: 0.6782\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4789 - val_loss: 0.6823\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4778 - val_loss: 0.6715\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4842 - val_loss: 0.6871\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4870 - val_loss: 0.6851\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4653 - val_loss: 0.6956\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4865 - val_loss: 0.6812\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4931 - val_loss: 0.6936\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4819 - val_loss: 0.6901\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4621 - val_loss: 0.6963\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4716 - val_loss: 0.6978\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4710 - val_loss: 0.6972\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4776 - val_loss: 0.6961\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4738 - val_loss: 0.6932\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4634 - val_loss: 0.7021\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4566 - val_loss: 0.6936\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4626 - val_loss: 0.6964\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4469 - val_loss: 0.6973\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4592 - val_loss: 0.6953\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4642 - val_loss: 0.7096\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4537 - val_loss: 0.7123\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4618 - val_loss: 0.7204\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4621 - val_loss: 0.6973\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4554 - val_loss: 0.7033\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4597 - val_loss: 0.7034\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4575 - val_loss: 0.7025\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4671 - val_loss: 0.7063\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4450 - val_loss: 0.7143\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4542 - val_loss: 0.7134\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4610 - val_loss: 0.7162\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4478 - val_loss: 0.7127\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4501 - val_loss: 0.7019\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4525 - val_loss: 0.7030\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4413 - val_loss: 0.7066\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4455 - val_loss: 0.7060\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4412 - val_loss: 0.7042\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4485 - val_loss: 0.6939\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4580 - val_loss: 0.7028\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4430 - val_loss: 0.6909\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4404 - val_loss: 0.6999\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4630 - val_loss: 0.6961\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4452 - val_loss: 0.7063\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4485 - val_loss: 0.7022\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4363 - val_loss: 0.7068\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4567 - val_loss: 0.7081\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4429 - val_loss: 0.7051\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4414 - val_loss: 0.7196\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4424 - val_loss: 0.7034\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4415 - val_loss: 0.7083\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4388 - val_loss: 0.6987\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4481 - val_loss: 0.7101\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4493 - val_loss: 0.7068\n",
      "Epoch 84/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4403 - val_loss: 0.7059\n",
      "Epoch 85/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4319 - val_loss: 0.7112\n",
      "Epoch 86/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4324 - val_loss: 0.7098\n",
      "Epoch 87/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4317 - val_loss: 0.7071\n",
      "Epoch 88/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4534 - val_loss: 0.7079\n",
      "Epoch 89/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4507 - val_loss: 0.7099\n",
      "Epoch 90/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4375 - val_loss: 0.7091\n",
      "Epoch 91/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4407 - val_loss: 0.7135\n",
      "Epoch 92/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4333 - val_loss: 0.7056\n",
      "Epoch 93/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4386 - val_loss: 0.7116\n",
      "Epoch 94/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4244 - val_loss: 0.7074\n",
      "Epoch 95/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4409 - val_loss: 0.7010\n",
      "Epoch 96/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4355 - val_loss: 0.7039\n",
      "Epoch 97/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4380 - val_loss: 0.7015\n",
      "Epoch 98/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4426 - val_loss: 0.7094\n",
      "Epoch 99/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4289 - val_loss: 0.7143\n",
      "Epoch 100/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4294 - val_loss: 0.7120\n",
      "current time:  2024-06-28_19-29\n",
      "\n",
      "\n",
      "44:mean_squared_error-label_sub 97.8%, ensemble: dna_encoded, nodes: [512, 256, 128, 64, 32, 16]\n",
      "Current target label: label_sub\n",
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7421 - val_loss: 0.7247\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6782 - val_loss: 0.7277\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6446 - val_loss: 0.7029\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6203 - val_loss: 0.6879\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5951 - val_loss: 0.6711\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5660 - val_loss: 0.6608\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5676 - val_loss: 0.6854\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5719 - val_loss: 0.6665\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5526 - val_loss: 0.6700\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5542 - val_loss: 0.6786\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5368 - val_loss: 0.6768\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5216 - val_loss: 0.6675\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5126 - val_loss: 0.6836\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5379 - val_loss: 0.6849\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5249 - val_loss: 0.6743\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5054 - val_loss: 0.6845\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5263 - val_loss: 0.6752\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5275 - val_loss: 0.6663\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5128 - val_loss: 0.6833\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4978 - val_loss: 0.6805\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4969 - val_loss: 0.6836\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5084 - val_loss: 0.6828\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4716 - val_loss: 0.6860\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4873 - val_loss: 0.6878\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4790 - val_loss: 0.7014\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5236 - val_loss: 0.6868\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5145 - val_loss: 0.6998\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5006 - val_loss: 0.6906\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4816 - val_loss: 0.6865\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4985 - val_loss: 0.6827\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4857 - val_loss: 0.6951\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4779 - val_loss: 0.6834\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4775 - val_loss: 0.6938\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4763 - val_loss: 0.6849\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4719 - val_loss: 0.6765\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4593 - val_loss: 0.6878\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4741 - val_loss: 0.6907\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4772 - val_loss: 0.7191\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4763 - val_loss: 0.6892\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4914 - val_loss: 0.7016\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4578 - val_loss: 0.6833\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4609 - val_loss: 0.6968\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4485 - val_loss: 0.6851\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4537 - val_loss: 0.7120\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4691 - val_loss: 0.6991\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4633 - val_loss: 0.6858\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4442 - val_loss: 0.6991\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4418 - val_loss: 0.6910\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4592 - val_loss: 0.6911\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4592 - val_loss: 0.6999\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4420 - val_loss: 0.6908\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4497 - val_loss: 0.6795\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4440 - val_loss: 0.6933\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4452 - val_loss: 0.6915\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4520 - val_loss: 0.7011\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4494 - val_loss: 0.7063\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4426 - val_loss: 0.6904\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4509 - val_loss: 0.6973\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4452 - val_loss: 0.6926\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4624 - val_loss: 0.7127\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4683 - val_loss: 0.6903\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4486 - val_loss: 0.7050\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4409 - val_loss: 0.6974\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4409 - val_loss: 0.7056\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4460 - val_loss: 0.7077\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4589 - val_loss: 0.7133\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4533 - val_loss: 0.6946\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4568 - val_loss: 0.6867\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4419 - val_loss: 0.6960\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4461 - val_loss: 0.7134\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4338 - val_loss: 0.7008\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4404 - val_loss: 0.7036\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4388 - val_loss: 0.7076\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4483 - val_loss: 0.7010\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4272 - val_loss: 0.7094\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4614 - val_loss: 0.7275\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4489 - val_loss: 0.7020\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4479 - val_loss: 0.6988\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4354 - val_loss: 0.7142\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4283 - val_loss: 0.6975\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4365 - val_loss: 0.7032\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4367 - val_loss: 0.7060\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4313 - val_loss: 0.6961\n",
      "Epoch 84/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4348 - val_loss: 0.7021\n",
      "Epoch 85/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4406 - val_loss: 0.6957\n",
      "Epoch 86/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4341 - val_loss: 0.6983\n",
      "Epoch 87/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4228 - val_loss: 0.7036\n",
      "Epoch 88/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4339 - val_loss: 0.7110\n",
      "Epoch 89/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4248 - val_loss: 0.6994\n",
      "Epoch 90/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4300 - val_loss: 0.7098\n",
      "Epoch 91/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4423 - val_loss: 0.7055\n",
      "Epoch 92/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4364 - val_loss: 0.7025\n",
      "Epoch 93/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4299 - val_loss: 0.7070\n",
      "Epoch 94/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4222 - val_loss: 0.6874\n",
      "Epoch 95/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4342 - val_loss: 0.6924\n",
      "Epoch 96/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4309 - val_loss: 0.6954\n",
      "Epoch 97/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4370 - val_loss: 0.6886\n",
      "Epoch 98/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4259 - val_loss: 0.7053\n",
      "Epoch 99/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4348 - val_loss: 0.7084\n",
      "Epoch 100/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4268 - val_loss: 0.7023\n",
      "current time:  2024-06-28_19-30\n",
      "Start time:  2024-06-28_19-05\n",
      "End time:  2024-06-28_19-30\n"
     ]
    }
   ],
   "source": [
    "time_start = time.strftime(\"%Y-%m-%d_%H-%M\", time.gmtime())\n",
    "dir_name = f'all_data_sub-regression_models {time_start}'\n",
    "dir_path = f'./{dir_name}'\n",
    "\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "else:\n",
    "    print('Directory already exists - Overwriting data')\n",
    "    \n",
    "combinations.to_pickle(f'{dir_path}/model_id_info.pkl')\n",
    "\n",
    "    \n",
    "EPOCHS = 100\n",
    "\n",
    "for i,row in combinations.iterrows():\n",
    "    if os.path.exists(f'{dir_path}/model-{row.model_id}'):\n",
    "        print(f'{dir_path}/model-{row.model_id} already trained')\n",
    "        continue\n",
    "    print(f'\\n\\n{row.model_id}:{row.loss}-{row.label_type} {round(i/len(combinations)*100,1)}%, ensemble: {row.ensemble}, nodes: {row.nodes}')\n",
    "        \n",
    "    t = norm_data[row.cols + ['rxn_id',row.label_type]]\n",
    "    train = t[t['rxn_id'].isin(row['train_ids'])]\n",
    "    test = t[t['rxn_id'].isin(row['test_ids'])]\n",
    "    \n",
    "    train,test,X_train,X_test,y_train,y_test = prep_data(train,test,target=row.label_type)\n",
    "    model = make_model(learning_rate=row['learning_rate'],nodes=row['nodes'])\n",
    "\n",
    "    history = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            batch_size=int(row['batch']),\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=(X_test, y_test))\n",
    "\n",
    "    model.save(f'{dir_path}/model-{row.model_id}.keras')\n",
    "        \n",
    "    print('current time: ',time.strftime(\"%Y-%m-%d_%H-%M\", time.gmtime()))\n",
    "\n",
    "print('Start time: ',time_start)\n",
    "print('End time: ',time.strftime(\"%Y-%m-%d_%H-%M\", time.gmtime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a477a-66ff-4b0f-9dc4-bfb06f09d604",
   "metadata": {},
   "source": [
    "### Read in all model data and keep in memory to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baca9d9b-b932-4007-a1b0-f9d84835248d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-0.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-1.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-10.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-11.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-12.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-13.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-14.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-15.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-16.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-17.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-18.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-19.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-2.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-20.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-21.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-22.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-23.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-24.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-25.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-26.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-27.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-28.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-29.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-3.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-30.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-31.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-32.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-33.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-34.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-35.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-36.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-37.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-38.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-39.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-4.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-40.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-41.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-42.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-43.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-44.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-5.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-6.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-7.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-8.keras\n",
      "./all_data_sub-regression_models 2024-06-28_19-05\\model-9.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>model_id</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>loss</th>\n",
       "      <th>label_type</th>\n",
       "      <th>batch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>nodes</th>\n",
       "      <th>cols</th>\n",
       "      <th>test_ids</th>\n",
       "      <th>train_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...</td>\n",
       "      <td>[2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...</td>\n",
       "      <td>[2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...</td>\n",
       "      <td>[2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...</td>\n",
       "      <td>[2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...</td>\n",
       "      <td>[2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...</td>\n",
       "      <td>[1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...</td>\n",
       "      <td>[1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...</td>\n",
       "      <td>[1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...</td>\n",
       "      <td>[1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>dna_encoded</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>label_sub</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16]</td>\n",
       "      <td>[Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...</td>\n",
       "      <td>[2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...</td>\n",
       "      <td>[1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold  model_id     ensemble                loss label_type  batch  \\\n",
       "0      0         0  dna_encoded  mean_squared_error  label_sub     10   \n",
       "1      0         1  dna_encoded  mean_squared_error  label_sub     10   \n",
       "2      0         2  dna_encoded  mean_squared_error  label_sub     10   \n",
       "3      0         3  dna_encoded  mean_squared_error  label_sub     50   \n",
       "4      0         4  dna_encoded  mean_squared_error  label_sub     50   \n",
       "..   ...       ...          ...                 ...        ...    ...   \n",
       "40     4        40  dna_encoded  mean_squared_error  label_sub     50   \n",
       "41     4        41  dna_encoded  mean_squared_error  label_sub     50   \n",
       "42     4        42  dna_encoded  mean_squared_error  label_sub    200   \n",
       "43     4        43  dna_encoded  mean_squared_error  label_sub    200   \n",
       "44     4        44  dna_encoded  mean_squared_error  label_sub    200   \n",
       "\n",
       "    learning_rate                        nodes  \\\n",
       "0           0.001            [128, 64, 32, 16]   \n",
       "1           0.001       [256, 128, 64, 32, 16]   \n",
       "2           0.001  [512, 256, 128, 64, 32, 16]   \n",
       "3           0.001            [128, 64, 32, 16]   \n",
       "4           0.001       [256, 128, 64, 32, 16]   \n",
       "..            ...                          ...   \n",
       "40          0.001       [256, 128, 64, 32, 16]   \n",
       "41          0.001  [512, 256, 128, 64, 32, 16]   \n",
       "42          0.001            [128, 64, 32, 16]   \n",
       "43          0.001       [256, 128, 64, 32, 16]   \n",
       "44          0.001  [512, 256, 128, 64, 32, 16]   \n",
       "\n",
       "                                                 cols  \\\n",
       "0   [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "1   [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "2   [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "3   [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "4   [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "..                                                ...   \n",
       "40  [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "41  [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "42  [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "43  [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "44  [Mg, SecYE, K, PEG, lipid, DNA_name-AqpZ, DNA_...   \n",
       "\n",
       "                                             test_ids  \\\n",
       "0   [1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...   \n",
       "1   [1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...   \n",
       "2   [1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...   \n",
       "3   [1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...   \n",
       "4   [1538.0, 23.0, 2947.0, 1002.0, 1161.0, 2930.0,...   \n",
       "..                                                ...   \n",
       "40  [2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...   \n",
       "41  [2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...   \n",
       "42  [2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...   \n",
       "43  [2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...   \n",
       "44  [2755.0, 3418.0, 3082.0, 542.0, 2044.0, 2876.0...   \n",
       "\n",
       "                                            train_ids  \n",
       "0   [2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....  \n",
       "1   [2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....  \n",
       "2   [2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....  \n",
       "3   [2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....  \n",
       "4   [2984.0, 1911.0, 3399.0, 2755.0, 3091.0, 2522....  \n",
       "..                                                ...  \n",
       "40  [1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...  \n",
       "41  [1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...  \n",
       "42  [1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...  \n",
       "43  [1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...  \n",
       "44  [1538.0, 2984.0, 1911.0, 3399.0, 23.0, 3091.0,...  \n",
       "\n",
       "[45 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = 'all_data_sub-regression_models 2024-06-28_19-05'\n",
    "paths = [p for p in glob.glob(f'./{dir_path}/*') if '.pkl' not in p]\n",
    "paths\n",
    "model_dict = {}\n",
    "for path in paths:\n",
    "    print(path)\n",
    "    model_num = int(os.path.basename(path).split('-')[-1].split('.')[0])\n",
    "    current_model = keras.models.load_model(path)\n",
    "    model_dict.update({model_num: current_model})\n",
    "    \n",
    "model_data = pd.read_pickle(glob.glob(f'./{dir_path}/*.pkl')[0])\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22b404-fa1c-4e63-804c-e36779175433",
   "metadata": {},
   "source": [
    "### Predict on all possible reaction compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "926519bf-54cb-4b84-81bb-b693919c750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../General_data/screen_active_data.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "debe306b-2703-4d44-a46a-6bcc085b286a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNA_name</th>\n",
       "      <th>lipid</th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>PEG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AqpZ</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AqpZ</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AqpZ</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqpZ</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AqpZ</td>\n",
       "      <td>14</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15746</th>\n",
       "      <td>Vol</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15747</th>\n",
       "      <td>Vol</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15748</th>\n",
       "      <td>Vol</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15749</th>\n",
       "      <td>Vol</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15750</th>\n",
       "      <td>Vol</td>\n",
       "      <td>18</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5506 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DNA_name  lipid     Mg  SecYE    K   PEG\n",
       "0         AqpZ     14  8.000  0.000   85 2.000\n",
       "1         AqpZ     14  8.000  0.000   85 2.000\n",
       "2         AqpZ     14  8.000  0.000   85 2.000\n",
       "3         AqpZ     14  8.000  0.000   85 2.000\n",
       "4         AqpZ     14  8.000  0.000   85 2.000\n",
       "...        ...    ...    ...    ...  ...   ...\n",
       "15746      Vol     18 20.000  1.250  135 2.000\n",
       "15747      Vol     18 20.000  1.250  135 2.000\n",
       "15748      Vol     18 20.000  1.250  135 2.000\n",
       "15749      Vol     18 20.000  1.250  135 2.000\n",
       "15750      Vol     18 20.000  1.250  135 2.000\n",
       "\n",
       "[5506 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = data[data['Liposome_name'] != 'no_lipo'].copy()\n",
    "\n",
    "\n",
    "lipo_dict = {'DOPC':18,'DPPC':16,'DMPC':14,'no_lipo':0}\n",
    "\n",
    "pred_df['lipid'] = pred_df['Liposome_name'].apply(lambda x: lipo_dict[x])\n",
    "pred_df = pred_df[['DNA_name','lipid','Mg','SecYE','K','PEG']].copy()\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2daa85c3-6ae5-4df2-85b6-ed31afa2c18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11340\n"
     ]
    }
   ],
   "source": [
    "all_unique = []\n",
    "lengths = []\n",
    "for col in pred_df.columns:\n",
    "    lengths.append(len(pred_df[col].unique()))\n",
    "    all_unique.append(list(pred_df[col].unique()))\n",
    "print(np.prod(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e7cc910-6426-45e8-be22-f7520d1a6e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rxn_id</th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>PEG</th>\n",
       "      <th>lipid</th>\n",
       "      <th>DNA_name</th>\n",
       "      <th>DNA_name-AqpZ</th>\n",
       "      <th>DNA_name-Aux</th>\n",
       "      <th>DNA_name-B2AR</th>\n",
       "      <th>...</th>\n",
       "      <th>DNA_name-Mol</th>\n",
       "      <th>DNA_name-MscL</th>\n",
       "      <th>DNA_name-MtlA</th>\n",
       "      <th>DNA_name-Neu</th>\n",
       "      <th>DNA_name-OR1A1</th>\n",
       "      <th>DNA_name-OR1D2</th>\n",
       "      <th>DNA_name-OR1E1</th>\n",
       "      <th>DNA_name-OR2AG1</th>\n",
       "      <th>DNA_name-SecYE-G</th>\n",
       "      <th>DNA_name-Vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11335</th>\n",
       "      <td>11335</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11336</th>\n",
       "      <td>11336</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11337</th>\n",
       "      <td>11337</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11338</th>\n",
       "      <td>11338</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11339</th>\n",
       "      <td>11339</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11340 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rxn_id    Mg  SecYE     K   PEG  lipid DNA_name  DNA_name-AqpZ  \\\n",
       "0           0 0.000  0.000 0.000 1.000  0.000     AqpZ          1.000   \n",
       "1           1 0.000  0.000 0.000 0.000  0.000     AqpZ          1.000   \n",
       "2           2 0.000  0.000 0.000 0.500  0.000     AqpZ          1.000   \n",
       "3           3 0.000  0.000 0.500 1.000  0.000     AqpZ          1.000   \n",
       "4           4 0.000  0.000 0.500 0.000  0.000     AqpZ          1.000   \n",
       "...       ...   ...    ...   ...   ...    ...      ...            ...   \n",
       "11335   11335 1.000  0.500 0.500 0.000  0.500      Vol          0.000   \n",
       "11336   11336 1.000  0.500 0.500 0.500  0.500      Vol          0.000   \n",
       "11337   11337 1.000  0.500 1.000 1.000  0.500      Vol          0.000   \n",
       "11338   11338 1.000  0.500 1.000 0.000  0.500      Vol          0.000   \n",
       "11339   11339 1.000  0.500 1.000 0.500  0.500      Vol          0.000   \n",
       "\n",
       "       DNA_name-Aux  DNA_name-B2AR  ...  DNA_name-Mol  DNA_name-MscL  \\\n",
       "0             0.000          0.000  ...         0.000          0.000   \n",
       "1             0.000          0.000  ...         0.000          0.000   \n",
       "2             0.000          0.000  ...         0.000          0.000   \n",
       "3             0.000          0.000  ...         0.000          0.000   \n",
       "4             0.000          0.000  ...         0.000          0.000   \n",
       "...             ...            ...  ...           ...            ...   \n",
       "11335         0.000          0.000  ...         0.000          0.000   \n",
       "11336         0.000          0.000  ...         0.000          0.000   \n",
       "11337         0.000          0.000  ...         0.000          0.000   \n",
       "11338         0.000          0.000  ...         0.000          0.000   \n",
       "11339         0.000          0.000  ...         0.000          0.000   \n",
       "\n",
       "       DNA_name-MtlA  DNA_name-Neu  DNA_name-OR1A1  DNA_name-OR1D2  \\\n",
       "0              0.000         0.000           0.000           0.000   \n",
       "1              0.000         0.000           0.000           0.000   \n",
       "2              0.000         0.000           0.000           0.000   \n",
       "3              0.000         0.000           0.000           0.000   \n",
       "4              0.000         0.000           0.000           0.000   \n",
       "...              ...           ...             ...             ...   \n",
       "11335          0.000         0.000           0.000           0.000   \n",
       "11336          0.000         0.000           0.000           0.000   \n",
       "11337          0.000         0.000           0.000           0.000   \n",
       "11338          0.000         0.000           0.000           0.000   \n",
       "11339          0.000         0.000           0.000           0.000   \n",
       "\n",
       "       DNA_name-OR1E1  DNA_name-OR2AG1  DNA_name-SecYE-G  DNA_name-Vol  \n",
       "0               0.000            0.000             0.000         0.000  \n",
       "1               0.000            0.000             0.000         0.000  \n",
       "2               0.000            0.000             0.000         0.000  \n",
       "3               0.000            0.000             0.000         0.000  \n",
       "4               0.000            0.000             0.000         0.000  \n",
       "...               ...              ...               ...           ...  \n",
       "11335           0.000            0.000             0.000         1.000  \n",
       "11336           0.000            0.000             0.000         1.000  \n",
       "11337           0.000            0.000             0.000         1.000  \n",
       "11338           0.000            0.000             0.000         1.000  \n",
       "11339           0.000            0.000             0.000         1.000  \n",
       "\n",
       "[11340 rows x 35 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos = list(itertools.product(*all_unique))\n",
    "all_combos = pd.DataFrame(combos,columns=pred_df.columns)\n",
    "all_combos = all_combos.reset_index().rename(columns={'index':'rxn_id'})\n",
    "\n",
    "prot_feat = all_combos[['DNA_name']].drop_duplicates().reset_index(drop=True)\n",
    "dna_encoded = add_one_hot(prot_feat,'DNA_name')\n",
    "dna_encoded.columns\n",
    "dna_encoded = all_combos[['rxn_id','DNA_name']].set_index('DNA_name').join(dna_encoded.set_index('DNA_name')).reset_index()\n",
    "\n",
    "data_bounded = all_combos[['Mg', 'SecYE', 'K', 'PEG','lipid']]\n",
    "X_bounded = np.array(data_bounded)\n",
    "MMscalerX = MinMaxScaler()\n",
    "X_bounded = MMscalerX.fit_transform(X_bounded)\n",
    "data_bounded = pd.DataFrame(X_bounded,columns=data_bounded.columns)\n",
    "data_bounded['rxn_id'] = all_combos['rxn_id']\n",
    "\n",
    "all_features = data_bounded.set_index('rxn_id').join(dna_encoded.set_index('rxn_id')).reset_index()\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5c093e3-5dc5-43e1-987f-f5bbacde562f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rxn_id</th>\n",
       "      <th>pred</th>\n",
       "      <th>model_id</th>\n",
       "      <th>ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>0</td>\n",
       "      <td>dna_encoded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0</td>\n",
       "      <td>dna_encoded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0</td>\n",
       "      <td>dna_encoded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>0</td>\n",
       "      <td>dna_encoded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0</td>\n",
       "      <td>dna_encoded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510295</th>\n",
       "      <td>11335</td>\n",
       "      <td>0.929</td>\n",
       "      <td>44</td>\n",
       "      <td>dna_encoded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510296</th>\n",
       "      <td>11336</td>\n",
       "      <td>0.243</td>\n",
       "      <td>44</td>\n",
       "      <td>dna_encoded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510297</th>\n",
       "      <td>11337</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>44</td>\n",
       "      <td>dna_encoded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510298</th>\n",
       "      <td>11338</td>\n",
       "      <td>1.121</td>\n",
       "      <td>44</td>\n",
       "      <td>dna_encoded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510299</th>\n",
       "      <td>11339</td>\n",
       "      <td>0.760</td>\n",
       "      <td>44</td>\n",
       "      <td>dna_encoded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rxn_id   pred  model_id     ensemble\n",
       "0            0 -0.421         0  dna_encoded\n",
       "1            1 -0.178         0  dna_encoded\n",
       "2            2 -0.242         0  dna_encoded\n",
       "3            3 -0.364         0  dna_encoded\n",
       "4            4  0.448         0  dna_encoded\n",
       "...        ...    ...       ...          ...\n",
       "510295   11335  0.929        44  dna_encoded\n",
       "510296   11336  0.243        44  dna_encoded\n",
       "510297   11337 -0.037        44  dna_encoded\n",
       "510298   11338  1.121        44  dna_encoded\n",
       "510299   11339  0.760        44  dna_encoded\n",
       "\n",
       "[510300 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds = []\n",
    "\n",
    "for i,row in model_data.iterrows():\n",
    "    temp = all_features[['rxn_id']].copy()\n",
    "    preds = model_dict[row['model_id']].predict(all_features[row['cols']])\n",
    "    temp['pred'] = preds\n",
    "    temp['model_id'] = row['model_id']\n",
    "    temp['ensemble'] = row['ensemble']\n",
    "    all_preds.append(temp)\n",
    "    \n",
    "all_preds = pd.concat(all_preds).reset_index(drop=True)\n",
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ad57210-4b04-4bf6-bfb2-45b30c8bf73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rxn_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>PEG</th>\n",
       "      <th>lipid</th>\n",
       "      <th>DNA_name</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>-0.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>-0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>-0.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>-0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>0.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510295</th>\n",
       "      <td>11335</td>\n",
       "      <td>44</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510296</th>\n",
       "      <td>11336</td>\n",
       "      <td>44</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>135</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510297</th>\n",
       "      <td>11337</td>\n",
       "      <td>44</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>2.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510298</th>\n",
       "      <td>11338</td>\n",
       "      <td>44</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>1.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510299</th>\n",
       "      <td>11339</td>\n",
       "      <td>44</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510300 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rxn_id  model_id     Mg  SecYE    K   PEG  lipid DNA_name   pred\n",
       "0            0         0  8.000  0.000   85 2.000     14     AqpZ -0.421\n",
       "1            1         0  8.000  0.000   85 0.000     14     AqpZ -0.178\n",
       "2            2         0  8.000  0.000   85 1.000     14     AqpZ -0.242\n",
       "3            3         0  8.000  0.000  135 2.000     14     AqpZ -0.364\n",
       "4            4         0  8.000  0.000  135 0.000     14     AqpZ  0.448\n",
       "...        ...       ...    ...    ...  ...   ...    ...      ...    ...\n",
       "510295   11335        44 20.000  0.625  135 0.000     16      Vol  0.929\n",
       "510296   11336        44 20.000  0.625  135 1.000     16      Vol  0.243\n",
       "510297   11337        44 20.000  0.625  185 2.000     16      Vol -0.037\n",
       "510298   11338        44 20.000  0.625  185 0.000     16      Vol  1.121\n",
       "510299   11339        44 20.000  0.625  185 1.000     16      Vol  0.760\n",
       "\n",
       "[510300 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = all_preds.set_index('rxn_id').join(all_combos.set_index('rxn_id'))[['model_id','Mg','SecYE','K','PEG','lipid','DNA_name','pred']].reset_index()\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec5531d0-e002-40fb-80b9-807196975c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rxn_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>PEG</th>\n",
       "      <th>lipid</th>\n",
       "      <th>DNA_name</th>\n",
       "      <th>pred</th>\n",
       "      <th>pmol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>3.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>5.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>4.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>3.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>0.448</td>\n",
       "      <td>8.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510295</th>\n",
       "      <td>11335</td>\n",
       "      <td>44</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510296</th>\n",
       "      <td>11336</td>\n",
       "      <td>44</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>135</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-0.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510297</th>\n",
       "      <td>11337</td>\n",
       "      <td>44</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>2.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510298</th>\n",
       "      <td>11338</td>\n",
       "      <td>44</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>1.121</td>\n",
       "      <td>0.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510299</th>\n",
       "      <td>11339</td>\n",
       "      <td>44</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510300 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rxn_id  model_id     Mg  SecYE    K   PEG  lipid DNA_name   pred  \\\n",
       "0            0         0  8.000  0.000   85 2.000     14     AqpZ -0.421   \n",
       "1            1         0  8.000  0.000   85 0.000     14     AqpZ -0.178   \n",
       "2            2         0  8.000  0.000   85 1.000     14     AqpZ -0.242   \n",
       "3            3         0  8.000  0.000  135 2.000     14     AqpZ -0.364   \n",
       "4            4         0  8.000  0.000  135 0.000     14     AqpZ  0.448   \n",
       "...        ...       ...    ...    ...  ...   ...    ...      ...    ...   \n",
       "510295   11335        44 20.000  0.625  135 0.000     16      Vol  0.929   \n",
       "510296   11336        44 20.000  0.625  135 1.000     16      Vol  0.243   \n",
       "510297   11337        44 20.000  0.625  185 2.000     16      Vol -0.037   \n",
       "510298   11338        44 20.000  0.625  185 0.000     16      Vol  1.121   \n",
       "510299   11339        44 20.000  0.625  185 1.000     16      Vol  0.760   \n",
       "\n",
       "         pmol  \n",
       "0       3.573  \n",
       "1       5.047  \n",
       "2       4.658  \n",
       "3       3.918  \n",
       "4       8.846  \n",
       "...       ...  \n",
       "510295  0.122  \n",
       "510296 -0.249  \n",
       "510297 -0.401  \n",
       "510298  0.226  \n",
       "510299  0.030  \n",
       "\n",
       "[510300 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_converted = []\n",
    "\n",
    "for dna,dna_df in preds.groupby('DNA_name'):\n",
    "    temp = dna_df.copy()\n",
    "    # temp['pmol'] = scaler_dict[dna].inverse_transform(np.array(temp[['pred']]))\n",
    "    temp['pmol'] = scaler_dict_sub[dna].inverse_transform(np.array(temp[['pred']]))\n",
    "    preds_converted.append(temp)\n",
    "    \n",
    "preds_converted = pd.concat(preds_converted).reset_index(drop=True)\n",
    "preds_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "162be594-6680-403c-acfe-8939f3c7cae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conar\\AppData\\Local\\Temp\\ipykernel_22224\\1455284662.py:1: FutureWarning: The provided callable <function mean at 0x000001D9FF81D080> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  means = preds_converted[['rxn_id','pmol']].groupby('rxn_id').agg(np.mean)\n",
      "C:\\Users\\conar\\AppData\\Local\\Temp\\ipykernel_22224\\1455284662.py:2: FutureWarning: The provided callable <function std at 0x000001D9FF81D1C0> is currently using DataFrameGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
      "  stdevs = preds_converted[['rxn_id','pmol']].groupby('rxn_id').agg(np.std)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>PEG</th>\n",
       "      <th>lipid</th>\n",
       "      <th>DNA_name</th>\n",
       "      <th>pmol_mean</th>\n",
       "      <th>pmol_stdev</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rxn_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>3.621</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>5.912</td>\n",
       "      <td>2.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>7.136</td>\n",
       "      <td>2.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>4.044</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>8.662</td>\n",
       "      <td>2.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11335</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11336</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>135</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11337</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>2.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11338</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11339</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11340 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mg  SecYE    K   PEG  lipid DNA_name  pmol_mean  pmol_stdev\n",
       "rxn_id                                                                \n",
       "0       8.000  0.000   85 2.000     14     AqpZ      3.621       0.540\n",
       "1       8.000  0.000   85 0.000     14     AqpZ      5.912       2.846\n",
       "2       8.000  0.000   85 1.000     14     AqpZ      7.136       2.675\n",
       "3       8.000  0.000  135 2.000     14     AqpZ      4.044       0.595\n",
       "4       8.000  0.000  135 0.000     14     AqpZ      8.662       2.659\n",
       "...       ...    ...  ...   ...    ...      ...        ...         ...\n",
       "11335  20.000  0.625  135 0.000     16      Vol      0.152       0.192\n",
       "11336  20.000  0.625  135 1.000     16      Vol     -0.205       0.149\n",
       "11337  20.000  0.625  185 2.000     16      Vol     -0.352       0.137\n",
       "11338  20.000  0.625  185 0.000     16      Vol      0.136       0.222\n",
       "11339  20.000  0.625  185 1.000     16      Vol     -0.051       0.190\n",
       "\n",
       "[11340 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = preds_converted[['rxn_id','pmol']].groupby('rxn_id').agg(np.mean)\n",
    "stdevs = preds_converted[['rxn_id','pmol']].groupby('rxn_id').agg(np.std)\n",
    "calcs = means.join(stdevs,lsuffix='_mean',rsuffix='_stdev')\n",
    "preds = all_combos.set_index('rxn_id').join(calcs)[['Mg','SecYE','K','PEG','lipid','DNA_name','pmol_mean','pmol_stdev']]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28241d2d-77b8-47ab-b7d8-82b42116ae83",
   "metadata": {},
   "source": [
    "### Get all active learning selected reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2c6b3fc-870b-4ebf-8ae0-5a36d161d14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>PEG</th>\n",
       "      <th>lipid</th>\n",
       "      <th>DNA_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>135</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>185</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>14.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18</td>\n",
       "      <td>Vol</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>322</td>\n",
       "      <td>14.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>185</td>\n",
       "      <td>1.000</td>\n",
       "      <td>18</td>\n",
       "      <td>Vol</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>323</td>\n",
       "      <td>14.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18</td>\n",
       "      <td>Vol</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>324</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18</td>\n",
       "      <td>Vol</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>325</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18</td>\n",
       "      <td>Vol</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_id     Mg  SecYE    K   PEG  lipid DNA_name   label\n",
       "0            0  8.000  0.000   85 0.000     14     AqpZ  active\n",
       "1            1  8.000  0.000  135 0.000     14     AqpZ  active\n",
       "2            2  8.000  0.000  135 1.000     14     AqpZ  active\n",
       "3            3  8.000  0.000  185 0.000     14     AqpZ  active\n",
       "4            4  8.000  0.000  185 1.000     14     AqpZ  active\n",
       "..         ...    ...    ...  ...   ...    ...      ...     ...\n",
       "321        321 14.000  0.000  185 0.000     18      Vol  active\n",
       "322        322 14.000  0.000  185 1.000     18      Vol  active\n",
       "323        323 14.000  0.625  185 0.000     18      Vol  active\n",
       "324        324 20.000  0.000  185 0.000     18      Vol  active\n",
       "325        325 20.000  0.625  185 0.000     18      Vol  active\n",
       "\n",
       "[326 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('../General_data/screen_active_data.pkl')\n",
    "\n",
    "lipo_dict = {'DOPC':18,'DPPC':16,'DMPC':14,'no_lipo':0}\n",
    "\n",
    "data['lipid'] = data['Liposome_name'].apply(lambda x: lipo_dict[x])\n",
    "\n",
    "active = data[data['label'] == 'active']\n",
    "active = active[active['Liposome_name'] != 'no_lipo']\n",
    "active = active[['Mg','SecYE','K','PEG','lipid','DNA_name','label']].drop_duplicates()\n",
    "active = active.reset_index(drop=True).reset_index().rename(columns={'index':'unique_id'})\n",
    "active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40c9bbca-0f30-4cd1-a27f-64a31faf242e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mg</th>\n",
       "      <th>SecYE</th>\n",
       "      <th>K</th>\n",
       "      <th>PEG</th>\n",
       "      <th>lipid</th>\n",
       "      <th>DNA_name</th>\n",
       "      <th>rxn_id</th>\n",
       "      <th>pmol_mean</th>\n",
       "      <th>pmol_stdev</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>0</td>\n",
       "      <td>3.621</td>\n",
       "      <td>0.540</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>1</td>\n",
       "      <td>5.912</td>\n",
       "      <td>2.846</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>2</td>\n",
       "      <td>7.136</td>\n",
       "      <td>2.675</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>135</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>3</td>\n",
       "      <td>4.044</td>\n",
       "      <td>0.595</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>AqpZ</td>\n",
       "      <td>4</td>\n",
       "      <td>8.662</td>\n",
       "      <td>2.659</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11335</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>11335</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.192</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11336</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>135</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>11336</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.149</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11337</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>2.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>11337</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>0.137</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11338</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>11338</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.222</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11339</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>185</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16</td>\n",
       "      <td>Vol</td>\n",
       "      <td>11339</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.190</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11340 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mg  SecYE    K   PEG  lipid DNA_name  rxn_id  pmol_mean  pmol_stdev  \\\n",
       "0      8.000  0.000   85 2.000     14     AqpZ       0      3.621       0.540   \n",
       "1      8.000  0.000   85 0.000     14     AqpZ       1      5.912       2.846   \n",
       "2      8.000  0.000   85 1.000     14     AqpZ       2      7.136       2.675   \n",
       "3      8.000  0.000  135 2.000     14     AqpZ       3      4.044       0.595   \n",
       "4      8.000  0.000  135 0.000     14     AqpZ       4      8.662       2.659   \n",
       "...      ...    ...  ...   ...    ...      ...     ...        ...         ...   \n",
       "11335 20.000  0.625  135 0.000     16      Vol   11335      0.152       0.192   \n",
       "11336 20.000  0.625  135 1.000     16      Vol   11336     -0.205       0.149   \n",
       "11337 20.000  0.625  185 2.000     16      Vol   11337     -0.352       0.137   \n",
       "11338 20.000  0.625  185 0.000     16      Vol   11338      0.136       0.222   \n",
       "11339 20.000  0.625  185 1.000     16      Vol   11339     -0.051       0.190   \n",
       "\n",
       "        label  \n",
       "0      random  \n",
       "1      active  \n",
       "2      random  \n",
       "3      random  \n",
       "4      active  \n",
       "...       ...  \n",
       "11335  random  \n",
       "11336  random  \n",
       "11337  random  \n",
       "11338  random  \n",
       "11339  random  \n",
       "\n",
       "[11340 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = preds.reset_index().set_index(['Mg', 'SecYE', 'K', 'PEG','lipid','DNA_name']).join(active.set_index(['Mg', 'SecYE', 'K', 'PEG','lipid','DNA_name'])).reset_index()\n",
    "combined = combined.drop(columns=['unique_id'])\n",
    "combined['label'] = combined['label'].fillna('random')\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91ff3c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conar\\AppData\\Local\\Temp\\ipykernel_22224\\3801738662.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  percentage = grouped.apply(lambda x: (x['pmol_mean'] > 0.5).mean() * 100)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 708.661x354.331 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group by DNA_name and label\n",
    "grouped = combined.groupby(['DNA_name', 'label'])\n",
    "\n",
    "# Calculate the percentage of each DNA that is above 0.5 pmol_mean for each label type\n",
    "percentage = grouped.apply(lambda x: (x['pmol_mean'] > 0.5).mean() * 100)\n",
    "percentage = percentage.reset_index().rename(columns={0: 'percentage'})\n",
    "percentage\n",
    "exclude = ['AqpZ','Mito','MscL']\n",
    "percentage = percentage[~percentage['DNA_name'].isin(exclude)].copy()\n",
    "percentage = percentage.rename(columns={'label':'sampling'})\n",
    "fig,ax = plt.subplots(figsize=[18*cm,9*cm])\n",
    "\n",
    "sns.barplot(data=percentage,x='DNA_name',y='percentage',hue='sampling',palette='Set1',ax=ax)\n",
    "plt.xticks(rotation=45, ha='center')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Percentage above 0.5 pmol (%)')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f490fa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837.9343536814232 350.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diff\n",
       "0.000       7\n",
       "5000.000    2\n",
       "1366.667    1\n",
       "-23.328     1\n",
       "94.554      1\n",
       "66.234      1\n",
       "294.872     1\n",
       "2700.000    1\n",
       "877.778     1\n",
       "708.163     1\n",
       "528.571     1\n",
       "601.786     1\n",
       "778.659     1\n",
       "1128.125    1\n",
       "367.857     1\n",
       "108.421     1\n",
       "350.000     1\n",
       "1000.000    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unstacked = percentage.set_index(['DNA_name','sampling']).unstack().reset_index().droplevel(0,axis=1).rename(columns={'':'DNA_name'})\n",
    "unstacked['diff'] = (unstacked['active'] - unstacked['pred']) / unstacked['pred'] * 100\n",
    "unstacked['diff'] = unstacked['diff'].fillna(0)\n",
    "unstacked['diff'] = unstacked['diff'].clip(-100,5000)\n",
    "unstacked\n",
    "mean = unstacked['diff'].mean()\n",
    "median = unstacked['diff'].median()\n",
    "print(mean,median)\n",
    "unstacked['diff'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "86b15983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='diff', ylabel='Count'>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x354.331 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clipped = unstacked.copy()\n",
    "clipped['diff'] = clipped['diff'].clip(-100,1000)\n",
    "fig,ax = plt.subplots(figsize=[9*cm,9*cm])\n",
    "\n",
    "sns.histplot(data=clipped,x='diff',ax=ax,bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ded7c94a-e417-4c52-b24b-07c397e0c0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Percentage difference in ΔYield')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x354.331 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_comps = []\n",
    "for dna,dna_df in combined.groupby('DNA_name'):\n",
    "    a = dna_df[dna_df['label'] == 'active']\n",
    "    a_mean = np.median(a['pmol_mean'])\n",
    "    r_mean = np.median(dna_df['pmol_mean'])\n",
    "    all_comps.append([dna,a_mean,r_mean])\n",
    "all_comps = pd.DataFrame(all_comps,columns=['DNA_name','active','random'])\n",
    "all_comps\n",
    "all_comps['diff'] = (all_comps['active'] - all_comps['random']) / abs(all_comps['random']) * 100\n",
    "all_comps\n",
    "fig,ax = plt.subplots(figsize=[9*cm,9*cm])\n",
    "temp = all_comps.copy()\n",
    "exclude = ['AqpZ','Mito','MscL']\n",
    "high = temp[temp['DNA_name'].isin(exclude)].copy()\n",
    "temp = temp[~temp['DNA_name'].isin(exclude)].copy()\n",
    "temp['active'] = temp['active'].clip(0,10) \n",
    "temp['diff'] = temp['diff'].clip(-1,1000)\n",
    "sns.scatterplot(data=temp,x='active',y='diff',ax=ax,color='black')\n",
    "plt.axhline(100, color='red',linewidth=1,linestyle='--')\n",
    "plt.xlabel('Median Active Learning ΔYield (pmol)')\n",
    "plt.ylabel('Percentage difference in ΔYield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c47e5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 708.661x354.331 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = temp[['DNA_name','active','random']].set_index('DNA_name').stack().reset_index().rename(columns={'level_1':'sampling',0:'pmol'})\n",
    "fig,ax = plt.subplots(figsize=[18*cm,9*cm])\n",
    "\n",
    "sns.barplot(data=df,x='DNA_name',y='pmol',hue='sampling',palette='Set1',ax=ax)\n",
    "plt.xticks(rotation=45, ha='center')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Median Expected ΔYield (pmol)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5c17d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 236.22x354.331 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = high[['DNA_name','active','random']].set_index('DNA_name').stack().reset_index().rename(columns={'level_1':'sampling',0:'pmol'})\n",
    "fig,ax = plt.subplots(figsize=[6*cm,9*cm])\n",
    "\n",
    "sns.barplot(data=df,x='DNA_name',y='pmol',hue='sampling',palette='Set1',ax=ax)\n",
    "plt.xticks(rotation=45, ha='center')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Median Expected ΔYield (pmol)')\n",
    "plt.ylim(0,20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d325c39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754.08966"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_comps['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9593acf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='diff', ylabel='Count'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x354.331 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_comps\n",
    "clipped = all_comps.copy()\n",
    "clipped['diff'] = clipped['diff'].clip(-100,1000)\n",
    "fig,ax = plt.subplots(figsize=[9*cm,9*cm])\n",
    "\n",
    "sns.histplot(data=clipped,x='diff',ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72f20110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conar\\AppData\\Local\\Temp\\ipykernel_9096\\76132699.py:2: FutureWarning: The provided callable <function mean at 0x000001E66067D080> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  no_lipo = no_lipo[['DNA_name','pmol']].groupby('DNA_name').agg(np.mean).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Change in yield with active learning (%)')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x354.331 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_lipo = data[data['Liposome_name'] == 'no_lipo'].copy()\n",
    "no_lipo = no_lipo[['DNA_name','pmol']].groupby('DNA_name').agg(np.mean).reset_index()\n",
    "no_lipo = no_lipo.rename(columns={'pmol':'background'})\n",
    "temp = all_comps.merge(no_lipo,left_on='DNA_name',right_on='DNA_name',how='left').copy()\n",
    "temp['pmol_active'] = temp['active'] - temp['background']\n",
    "temp['pmol_random'] = temp['random'] - temp['background']\n",
    "temp['diff'] = (temp['pmol_active'] - temp['pmol_random']) / abs(temp['pmol_random']) * 100\n",
    "exclude = ['AqpZ','Mito','MscL']\n",
    "temp = temp[~temp['DNA_name'].isin(exclude)].copy()\n",
    "# temp.describe()\n",
    "fig,ax = plt.subplots(figsize=[9*cm,9*cm])\n",
    "temp['diff'] = temp['diff'].clip(-100,1000)\n",
    "sns.scatterplot(data=temp,x='pmol_active',y='diff',ax=ax, color='black')\n",
    "plt.xlabel('ΔYield (pmol)')\n",
    "plt.ylabel('Change in yield with active learning (%)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7877038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 708.661x354.331 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = temp[['DNA_name','pmol_active','pmol_random']].set_index('DNA_name').stack().reset_index().rename(columns={'level_1':'sampling',0:'pmol'})\n",
    "fig,ax = plt.subplots(figsize=[18*cm,9*cm])\n",
    "\n",
    "sns.barplot(data=df,x='DNA_name',y='pmol',hue='sampling',palette='Set1',ax=ax)\n",
    "plt.xticks(rotation=45, ha='center')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Expected Yield (pmol)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "058e53c3-a7dd-4943-bfb3-39d53a4fd17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAFMCAYAAABLWT5cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgnklEQVR4nO3de1RVZf4G8Iebh+tBuSiocLgYYN7HnMlJB6wss0wTL3kZ1EnMKWe8JCU2I1BLcSSZ0aaLtlaipVkrKyfMGjK11FEbs9EGUFEQ4pICykE4HOGc9/eHP/d4PIjwctnbeD5r7bV83/2efb684uO7z2VvByGEABERtYij2gUQEd2JGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSnNUuoK1YrVaUlJTAy8sLDg4OapdDRHcoIQSqq6vRs2dPODreen35swnPkpISBAUFqV0GEf1MFBUVoXfv3rfc/7MJTy8vLwDXfmC9Xq9yNUR0pzIajQgKClIy5VZ+NuF5/VRdr9czPImo1W738h/fMCIiksDwJCKSwPAkIpLA8CQiksDwJCKSwPAkIpKganimp6dj9uzZdv179uxp8pP9RERqUyWhLBYLVq9ejYSEBLt9RqMRc+fOBe8OQkRapkp4zpo1CwcOHEB8fLzdvsWLF2PixIkqVEVE1HyqfMMoLS0NgYGBSE5ORkFBgdL/2WefIS8vDxkZGUhPT2/yGGazGWazWWkbjUapWgoLC1FeXi712Lbm5+eH4OBgtcsgomZQJTwDAwPt+i5duoRFixZh9+7dzboqUmpqKlJSUlpVR2FhIaKi+sJkqm3VcdqKm5s7cnNzGKBEdwDNfLf9D3/4AxYsWIDw8HCb1eitJCYmYsmSJUr7+pf5W6K8vBwmUy1+9bsk6ANDWlhx2zKWFuDI2ykoLy9neBLdATQTnjt27EBmZiZWrFgBq9UKAOjatSsyMzMxYsQIu/E6nQ46na5NnlsfGAKf4Mg2ORYRdQ6aCU+TyaT8uaCgAKGhobh8+bJ6BRERNYEfpiQikqDqyjM5ObnR/pCQEH7Ok4g0jStPIiIJDE8iIgkMTyIiCQxPIiIJDE8iIgkMTyIiCQxPIiIJDE8iIgkMTyIiCQxPIiIJDE8iIgkMTyIiCQxPIiIJDE8iIgkMTyIiCQxPIiIJDE8iIgkMTyIiCQxPIiIJDE8iIgkMTyIiCQxPIiIJDE8iIgkMTyIiCQxPIiIJDE8iIgkMTyIiCQxPIiIJqoZneno6Zs+erbTfeusthIeHw9vbG9HR0cjOzlavOCKiJqgSnhaLBatXr0ZCQoLSd+jQIbz44ovYuXMnKisrMWbMGEyYMEGN8oiIbkuV8Jw1axYOHDiA+Ph4pa+4uBgJCQno378/nJycsGDBApw5cwYVFRVqlEhE1CRnNZ40LS0NgYGBSE5ORkFBAQBg8uTJNmN27dqFwMBA+Pr6NnoMs9kMs9mstI1GY7vVS0R0M1VWnoGBgU3uP3LkCJ5++mmsW7fulmNSU1Ph7e2tbEFBQW1dJhHRLWnu3fbMzEw89NBDWLt2rd1q9EaJiYmoqqpStqKiog6skog6O1VO229l06ZNWLx4MbZt24ZHH320ybE6nQ46na6DKiMisqWZ8Pzmm2+wYMECfPnllxg+fLja5RARNUkzp+3r1q1DXV0dRo8eDU9PT2UrLCxUuzQiIjuqrjyTk5OVP3/44YfqFUJE1EKaWXkSEd1JGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREElQNz/T0dMyePVtp79q1C5GRkfDw8MC4ceNw8eJF9YojImqCKuFpsViwevVqJCQkKH1lZWWYMWMGNmzYgIqKCgQEBGD+/PlqlEdEdFvOajzprFmzcPnyZcTHx6Ourg4A8PHHH2PEiBGIiYkBAKxevRoBAQEwGo3Q6/VqlElEdEuqrDzT0tKQmZmJgIAApS83NxdRUVFK29fXF97e3sjLy2v0GGazGUaj0WYjIuooqoRnYGCgXV9NTQ3c3d1t+tzd3VFbW9voMVJTU+Ht7a1sQUFB7VIrEVFjNPNuu7u7O0wmk01fbW0tPD09Gx2fmJiIqqoqZSsqKuqIMomIAKj0mmdjoqKi8MUXXyjt8vJyVFVVoU+fPo2O1+l00Ol0HVUeEZENzaw8x48fj/379yMrKwt1dXVYvnw5xo0bd8uVJxGRmjQTnr169cL777+PhQsXonv37iguLsbGjRvVLouIqFGqnrYnJyfbtB9++GFkZ2erUwwRUQtoZuVJRHQnYXgSEUlgeBIRSWB4EhFJYHgSEUlgeBIRSWB4EhFJYHgSEUlgeBIRSWB4EhFJYHgSEUlgeBIRSWB4EhFJYHgSEUlgeBIRSWB4EhFJYHgSEUlgeBIRSWB4EhFJYHgSEUlgeBIRSWB4EhFJYHgSEUlgeBIRSWB4EhFJYHgSEUlgeBIRSdBceO7fvx8DBw6EXq/HsGHDcPToUbVLIiKy0+LwLCsra7Q/Jyen1cVYLBbExsZi7dq1qKqqwpw5czB16tRWH5eIqK21ODwjIiLs+qqrq/GrX/2q1cVcunQJFRUVqK+vhxACTk5OcHV1bfVxiYjamnNzBp0/fx79+vWDyWRSQu1mDz/8cKuL8fPzw9y5c/Hoo4/CyckJbm5u2LNnT6NjzWYzzGaz0jYaja1+fiKi5mpWeBoMBpw7dw61tbWIjo7G119/DSEEHBwcAAA6nQ4BAQGtLsZisUCv1+OLL75AdHQ03nzzTUyePBk5OTlwd3e3GZuamoqUlJRWPycRkYxmn7Z3794dISEhOH/+PAwGA0JCQmAwGGAwGNokOAFgx44dyM3NxUMPPQSdToeFCxfC1dUVX375pd3YxMREVFVVKVtRUVGb1EBE1Bwtfs1z9+7diIyMhLOzM5ycnODk5ARHR8dGT+Vb6scff8TVq1dt+lxcXODi4mI3VqfTQa/X22xERB2lxeG5ePFixMXF4dSpUzh37hzOnTuH/Px8nDt3rtXFPPDAAzhw4AA+/vhjWK1WbNq0CRUVFbjvvvtafWwiorbUrNc8b1RaWoply5a1yUrzZoMGDcK7776LP/3pT5g9ezb69euHzz77jKtKItKcFq88p06dio0bN7ZHLQCA2NhY/Pe//0VVVRUOHTqEIUOGtNtzERHJanF4njx5Es8++yz0ej3CwsJsNiKizqLFp+2rV69ujzqIiO4oLQ7P6Ojo9qiDiOiO0uLwdHR0VD4cfzOLxdLqgoiI7gQtDs/8/Hybdnl5OdavX8+PExFRp9Li8DQYDHbtjRs3Ijw8HPPmzWuzwoiItKxNrud57NgxCCHa4lBERHeEFq88Q0NDbV7zbGhoQFlZGV5++eU2LYyISMtaHJ4ZGRk2bUdHR4SFhaFXr15tVRMRkea1+LQ9OjoagwYNQnFxMY4cOYKzZ882euEOIqKfsxaH57FjxxAREYHXXnsNx48fx5tvvomIiAgcPny4PeojItKkFp+2L1q0CGvWrMHs2bOVvk2bNmHhwoU4cuRIW9ZGRKRZLV55/vDDD4iLi7Ppi4uLa5MbwBER3SlaHJ4GgwFfffWVTd9XX32F0NDQNiuKiEjrWnzavmrVKjzxxBMYP348DAYDCgoK8Omnn2L79u3tUR8RkSa1aOVZX1+PsLAwHDp0CKGhoaioqEBUVBQOHjyIsWPHtleNRESa0+yVZ2lpKe6//34MHToU7777LgYMGICKigoMGzYMH3zwAbKystrsRnBERFrX7JXnCy+8gFGjRmHLli1Kn6+vL86cOYPBgwcjMTGxXQokItKiZq88s7KycPr0aTg62uatk5MT1q5di8GDB7d1bUREmtXslWddXR08PDwa3efv7w+TydRmRRERaV2zw7Nfv37Yt29fo/v27duHkJCQNiqJiEj7mh2eS5cuRVxcHD7//HNYrVYAgNVqxeeff45Zs2bhj3/8Y7sVSUSkNc1+zXPChAn48ccfMXnyZAgh0K1bN1RWVsLZ2RkpKSmYM2dOe9ZJRKQpLfqQ/IIFCzBnzhwcOnQIFRUV6NGjB4YPHw5XV9f2qo+ISJNa/A0jDw8PjB49uj1qISK6Y7TJbTiIiDobhicRkQTNhefZs2fxwAMPwNPTE5GRkdi9e7faJRER2dFUeFqtVkyYMAH3338/jEYj1q9fjylTpqCmpkbt0oiIbLT4DaP29K9//QsmkwnLly+Hg4MDHn74YRw4cABOTk5ql0ZEZENTK8/vv/8effv2xdNPPw1/f3/84he/QHV1daMfhTKbzTAajTYbEVFH0VR4Xrp0Cbt378bQoUNRXFyMhIQEjB8/HpWVlXZjU1NT4e3trWxBQUEqVExEnZWmwrNLly4wGAx4+umn0aVLF0ybNg29evXCwYMH7cYmJiaiqqpK2YqKilSomIg6K0295hkREWF3+m2xWCCEsBur0+mg0+k6qjQiIhuaWnmOHj0aTk5O+Nvf/gar1Yp3330XZWVlGDVqlNqlERHZ0FR4enh4YO/evfjkk0/QrVs3/OUvf8Enn3wCLy8vtUsjIrKhqdN2AOjbt+8trxtKRKQVmlp5EhHdKRieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBIYnkREEhieREQSGJ5ERBI0G57Z2dlwdXVFQUGB2qUQEdnRZHg2NDRgzpw5MJvNapdCRNQoTYZnamoqRowYoXYZRES35Kx2ATf7z3/+g/fffx/ffvst0tPTbznObDbbrEyNRmNHlNfucnJy1C5BYTabodPp1C5D4efnh+DgYLXLIAKgsfC8evUq5syZgw0bNsDNza3JsampqUhJSemgytqfqaoCgANmzpypdin/4+AACKF2FQo3N3fk5uYwQEkTNBWeL730EmJiYnDffffddmxiYiKWLFmitI1GI4KCgtqzvHZVX1sNQGDw9BfgHxqldjkoPfkv/PCPjZqpx1hagCNvp6C8vJzhSZqgqfD88MMPUVpairffflvpGzhwIN58801Mnz7dZqxOp9PUKWVb8eweDJ/gSLXLgLG0AIB26iHSGk2FZ25urk3bwcEBJ06cQEhIiDoFERHdgibfbSci0jpNrTxvJjT0ZgUR0Y248iQiksDwJCKSwPAkIpLA8CQiksDwJCKSwPAkIpLA8CQiksDwJCKSwPAkIpLA8CQiksDwJCKSwPAkIpLA8CQiksDwJCKSwPAkIpLA8CQiksDwJCKSwPAkIpLA8CQiksDwJCKSwPAkIpLA8CQiksDwJCKSwPAkIpLA8CQiksDwJCKSwPAkIpKgufDcuXMn+vXrB71ej3vuuQcHDx5UuyQiIjuaCs/8/HzExcXh9ddfx+XLl7F48WI8/vjjqK6uVrs0IiIbmgrPwsJCxMfHIzo6Go6OjpgxYwYA4PTp0ypXRkRky1ntAm4UHR2N6OhopX348GHU1tbirrvushtrNpthNpuVttFo7JAaSV05OTlqlwDg2u+fTqdTuwyFn58fgoOD1S6jU9FUeN4oLy8PsbGxePnll6HX6+32p6amIiUlRYXKSA2mqgoADpg5c6bapVzj4AAIoXYVCjc3d+Tm5jBAO5Amw/Po0aN47LHH8Mwzz2Dp0qWNjklMTMSSJUuUttFoRFBQUEeVSB2svrYagMDg6S/APzRK1VpKT/4LP/xjoyZqAQBjaQGOvJ2C8vJyhmcH0lx4fvHFF5gyZQrWrl2LuXPn3nKcTqfT1GkTdQzP7sHwCY5UtQZjaYFmaiH1aCo8z5w5g0mTJiEjIwOxsbFql0NEdEuaerd9w4YNqKmpwaxZs+Dp6als33zzjdqlERHZ0FR4vvLKK7Barbhy5YrNNnLkSLVLIyKyoanwJCK6UzA8iYgkMDyJiCQwPImIJDA8iYgkMDyJiCQwPImIJDA8iYgkMDyJiCQwPImIJDA8iYgkMDyJiCRo6pJ0RCRPK7coAbR1m5L2ukUJw5PoDqe5W5QAmrpNSXvdooThSXSH09ItSgBt3aakPW9RwvAk+pnQym1BOsttSviGERGRBIYnEZEEhicRkQSGJxGRBIYnEZEEhicRkQSGJxGRBIYnEZEEhicRkQSGJxGRBIYnEZEEzYXnkSNHMGTIEHh4eGDkyJE4e/as2iUREdnRVHjW1dXhiSeewPPPP49Lly5h9OjRmDp1qtplERHZ0VR47t27Fz4+Ppg2bRq6dOmCF198EWfPnkV2drbapRER2dDUJelyc3MRFfW/6/85OTkhPDwcubm5uPvuu23Gms1mmM1mpV1VVQUAMBqNzX6+K1euAAAqz59Cg9nUmtJbzVh6HgBQVXwGLs4OqtYCsJ47pRaA9TRZS1khgGv/1pubDdfHidtdzFloyMsvvyx++9vf2vSNHDlSvPPOO3Zjk5KSBABu3Lhxa5etqKioybzS1MrT3d0dJpPtCrC2thaenp52YxMTE7FkyRKlbbVaUVlZCV9fXzg4NP6/ndFoRFBQEIqKiqDX69u2+J8hzlfzca6aT+tzJYRAdXU1evbs2eQ4TYVnVFQUNm/erLQtFgvy8vIQGWl/NWqdTmd3g6muXbs263n0er0m/9K0ivPVfJyr5tPyXHl7e992jKbeMBo1ahR++uknbNmyBVevXsXKlSsRHh6Ovn37ql0aEZENTYWnm5sbdu3ahVdffRW+vr7IysrCBx98oHZZRER2NHXaDgBDhw7Ft99+2y7H1ul0SEpK0sz9pLWO89V8nKvm+7nMlYMQGrm5MhHRHURTp+1ERHcKhicRkQSGJxGRBIYnEZGEThOevNRd05YuXQpXV1d4enrC09MTfn5+AIBdu3YhMjISHh4eGDduHC5evKhypepKT0/H7NmzlXZT89PZ5+7muZo0aRLc3NyU37GhQ4cq+zIyMhAcHAwvLy/ExcXZfdNQk9rum+naZTKZRGBgoNi2bZswm80iJSVFDB06VO2yNOXBBx8UH330kU1faWmp8Pb2Fnv37hUmk0nMnTtXTJw4UaUK1dXQ0CBSU1OFo6OjmDVrlhCi6fnpzHPX2FwJIUSfPn3Ed999Zzf++PHjws/PT5w4cUIYjUYxduxYsWTJkg6sWE6n+KjS7t27kZCQgB9++AHAta99+vn54eDBg3ZXa+qsunfvjsOHDyMsLEzpe+ONN7Br1y5kZmYCACoqKhAQEICKigrNfq2uvcycOROXL19G7969UVdXh4yMjCbnZ+vWrZ127hqbqytXrsDX1xdGo9Hu850vvPACampq8Pe//x0AcOzYMTzyyCO4cOGCGuU3W6c4bW/qUncElJaWoqKiAosXL4a/vz/uvfdeHD582G7efH194e3tjby8PBWrVUdaWhoyMzMREBCg9DU1P5157hqbq5MnT8LDwwNjx46Fv78/HnzwQeXf381zFRkZiYsXL6KysrLDa2+JThGeNTU1cHd3t+lzd3dHbW2tShVpS3l5OWJiYrBs2TIUFxdj7ty5eOyxx2A0Gjlv/y8wMNCur6nfq878O3erubr33nvx6quvoqioCPfddx8ef/xx1NfX283V9T9rfa46RXi25FJ3ndGAAQOwZ88eDB8+HF26dMHcuXMRGBiI/fv3c96a0NTvFX/nbD344IP47LPPcPfdd8PV1RXJycn46aefkJOTYzdX10NT63PVKcIzKioKp0+fVtpNXequMzp48CDeeOMNmz6z2YxFixbZzFt5eTmqqqrQp0+fji5Rk27+vbpxfpra1xllZmZi+/btSttisaChoQGurq52c3Xq1Cn06NGj2ZeYVEunCE9e6q5pOp0OCQkJOHDgABoaGrB+/XqYzWbExsZi//79yMrKQl1dHZYvX45x48ZpfkXQUcaPH3/L+WlqX2d09epVLFy4EDk5OTCbzUhMTMSAAQMQERGBqVOnYtu2bfjuu+9QXV2NFStWYPr06WqXfHtqv93fUf7973+Le+65R3h6eooRI0aIvLw8tUvSlM2bN4vw8HDh7u4ufv3rX4sTJ04IIYT4/PPPRd++fYWXl5cYO3asuHjxosqVqispKcnm4zdNzU9nn7ub52rNmjWid+/ewsPDQ4wZM0YUFhYq+7Zs2SLCwsKEXq8XM2fOFLW1tSpU3DKd4qNKRERtrVOcthMRtTWGJxGRBIYnEZEEhicRkQSGJxGRBIYnEZEEhicRkQSGJ2lWQUGB2iUQ3RLDsxNzcHCAh4cHPD094eXlBR8fH8yYMQOXL19WuzQcP34co0ePbtbYjIwMxMTEAABWrVqF+fPnAwDOnz+Pfv36wcvLC5s3b8Zjjz0GDw8PZf+d4p///Ceee+45AMDmzZvh7+8Pg8GArKwsZUxaWhpef/11m8ctXboUu3fv7tBaOxW1v+JE6gEg8vPzlXZVVZUYNWqUePLJJ9Ur6v/t3btXGAyGZo3dtGmTiI6OtuvfsmWL6N+/v7BYLKKwsFAAEBcuXGjbQtuZ2WwW/fv3F+Xl5UIIIXx9fcUPP/wgPv30UzFs2DAhhBCVlZXil7/8paivr7d5bEVFhejfv78wm80dXndnwJUnKfR6PWJjY3Hy5EkAwJUrVzBv3jwEBATAYDAgLS1NGRsSEoL4+Hj4+PggLS0NJpMJ8+fPh4+PD3r06IGkpCRl7LZt2xAVFQUfHx9MnDhRuUJ4RkYGxo8fj4kTJ8LT0xODBg3C0aNHUVNTg0ceeQSFhYWNXlmnoaEBCxcuRNeuXREeHo4jR44o+5KTkzF79mzs2LED8fHxyM7OhqenJyIiIgAAoaGh2LdvHy5cuIApU6bAz88Pd911F9555x3lGA4ODvj973+Pbt26Yfv27U3OQ0xMDJKSkhAVFYWuXbtiypQpMJvNAK5dPX7KlCnw9vZGUFCQzZWr/vrXvyIsLAzdu3fHU089hStXrjT6d7Jt2zYMGjQIvr6+AAAXFxcAgBACTk5OAK6ttp977jk4OzvbPNbHxweDBg3Ce++91+ixqZXUTm9SD25aeRYUFIjhw4eLZ599VgghRHx8vJgwYYKoqqoS+fn5IioqSmzfvl0IIYTBYBCTJk0SdXV1wmg0iueee07ExMSI8vJyUVJSIsLCwsRHH30kDhw4IPz9/cV3330nTCaTWLRokRgzZowQ4tqK0cHBQezcuVPU1dWJefPmidGjRwshml55pqeni4EDB4qysjJRUFAgwsPDlZXnjRejuHFFmp+fL278dR89erR45plnRF1dnfj+++9FQECAOHz4sDIvixYtEnV1daKmpqbJeYiOjhb9+vUTJSUloqioSPTu3Vts3bpVCCFEbGysmDZtmrhy5YrIzc0VPj4+4tixY2Lr1q3irrvuEnl5eaK6ulpMnjxZzJ8/v9GfNSYmRuzYsUNpv/fee6J3794iIiJCfP3116KwsFCMHDlSWK3WRh//4YcfilGjRjW6j1qH4dmJARBeXl7C29tb6PV60bt3b/HUU08Jo9EorFarcHV1FadPn1bGb9iwQQk+g8Egtm3bpuwLCgoSe/bsUdqnTp0SZWVlYt68eWL58uVKf01NjXBychJlZWVi06ZN4u6771b2ZWVlidDQUCFE0+E5YsQI8fbbbyvtdevWtSg8S0pKhLOzs6ipqVGOkZiYqAQYAHHo0CEhhLjtPERHR4s1a9Yo+2bMmCFSUlKEyWQSLi4u4uzZs8q+EydOiEuXLomHHnpIbNy40Wau3Nzc7AKwoaFBuLq6ioKCgkbnQQghZs2aJb766ivx2muvicGDB4tp06bZ/Fz5+fnC1dVVWCyWWx6D5Dg3tSqln78TJ04gJCTErv/ChQuoq6vDsGHDlD6r1YrQ0FClfeM9an766Sf06tVLaV8/TS4qKsI777yD1157Tdnn4uKC8+fPAwD8/f2VfmdnZ1it1tvWfPNzGQyG2z7mRkVFRbBYLOjZs6fSZ7FYMGrUKKV9/We7ePHibeehsZ/h0qVLqK+vt6lzwIAByvMvXrwYCQkJNse8cOECevToofRVVFSgrq7OZp5vdPLkSZSXl6Nfv36Ii4vDqVOnsGzZMrz11ltYuHAhgGu3xKirq0NFRYVNndR6DE9qlK+vL1xcXHD69Gl0794dwP/+MV/n4OCg/LlXr14oKSlRrs6/c+dOODs7IyAgAMnJyXj++eeVsbm5uejTpw+ys7OlagsICEBhYaHSLi0tbfHjPTw8UFlZCUfHay/7l5WVKa8h3vizNWceGtO9e3e4uLigpKRECdpNmzYhMjJSmZMpU6YAuHah4IKCAuX4112v7Vb/oSxfvhwrV67EuXPnEBwcDHd3d/Tv3x/Hjx9XxlgsFptjUdvhjFKjnJycMHXqVCxbtgw1NTW4dOkSYmNjsWrVqkbHP/nkk1i5ciUuX76MkpISJCQkwGq1YsaMGXjjjTeQk5MDq9WKdevWYeTIkbh69WqTz6/T6VBbW6v847/R9OnTsXbtWvz4448oLi7G+vXrW/SzBQcHY8iQIUhKSsLVq1dRXFyM+++/HxkZGa2ehxsfN2nSJCQlJcFkMiE3NxfLli2Du7s7ZsyYgTVr1qCoqAj19fVYvnw5Jk6caHcMX19fuLq6oqyszG7fvn370K1bNwwaNAgGgwHnzp1DVVUVjh07ZrMqLisrg5ubm/KGE7Udhifd0vX7aIeHh6NPnz4ICQmxeaf5Rn/+858RGRmJqKgoDB06FHPnzsW4cePwwAMPYMWKFZgwYQK6du2Kbdu2ITMz0+7OkjcbOHAgDAYDunXrBqPRaLNv3rx5mDBhAgYOHIjhw4c3+/OgN9q+fTuys7PRs2dPDBkyBI888giWLFnS6nm4+XENDQ0ICgrCmDFjkJaWhsGDB+N3v/sdJk2ahN/85jfw8/PD8ePH8dFHH9ms5IFrq9/o6GgcPXrU7tgrVqzASy+9BODaqfmzzz6LkJAQnDlzBvPmzVPGHT161OblCGo7vJI8kYZlZGQgKysLW7dulXr89OnTMXbsWMycObONKyOGJ5GG1dfXY+DAgfjmm2/g5+fXosdevHgR0dHROHHihN1nQKn1eNpOpGEuLi5IT0/HypUrW/zYVatW4ZVXXmFwthOuPImIJHDlSUQkgeFJRCSB4UlEJIHhSUQkgeFJRCSB4UlEJIHhSUQkgeFJRCTh/wDlYWZRrj3i4gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 354.331x354.331 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "46.238182"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize=[9*cm,9*cm])\n",
    "all_comps['diff'] = (all_comps['active'] - all_comps['random']) / all_comps['random'] * 100\n",
    "sns.histplot(data=all_comps,x='diff',ax=ax)\n",
    "plt.xlabel('Percent difference (%)')\n",
    "plt.savefig(f'{fig_folder}/Backup-Active_vs_random_differences.svg',format='svg',dpi=300)\n",
    "\n",
    "plt.show()\n",
    "np.mean(all_comps['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a64abff8-83ec-40ba-95ff-596414a1022b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 708.661x354.331 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize=[18*cm,9*cm])\n",
    "temp = all_comps[['DNA_name','active','random']].set_index('DNA_name').stack().reset_index().rename(columns={'level_1':'sampling',0:'pmol'})\n",
    "temp = temp[~temp['DNA_name'].isin(['AqpZ','Mito','MscL'])].copy()\n",
    "sns.barplot(data=temp,x='DNA_name',y='pmol',hue='sampling',palette='Set1')\n",
    "plt.xticks(rotation=45, ha='center')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Expected Yield (pmol)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{fig_folder}/Backup-Active_vs_random_differences_proteins.svg',format='svg',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364c4d1-fb1c-4473-b981-c26b7d29f0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de5e53-6140-424b-9751-c5abcf6d5d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "737af5cb-c7a4-464c-90f8-1e7d5d950f47",
   "metadata": {},
   "source": [
    "### Use the models to predict on only the reactions that were in each model's test set which is specified in the model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19329cc6-bb24-46ef-bf62-d9c02f1bf9ee",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "\n",
    "for i,row in model_data.iterrows():\n",
    "    temp = all_features[all_features['rxn_id'].isin(list(row['test_ids']))].copy()\n",
    "    temp_norm = norm_data[norm_data['rxn_id'].isin(row['test_ids'])].copy()\n",
    "\n",
    "    preds = model_dict[row['model_id']].predict(temp_norm[row['cols']])\n",
    "    temp['pred'] = preds\n",
    "    temp['model_id'] = row['model_id']\n",
    "    temp['ensemble'] = row['ensemble']\n",
    "    test_preds.append(temp)\n",
    "    \n",
    "test_preds = pd.concat(test_preds).reset_index(drop=True)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f52f2d-4195-4016-b0ba-a0f7627b93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_preds = test_preds.set_index(['ensemble','model_id']).join(model_data.set_index(['ensemble','model_id'])).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a2ec1a-2b76-43af-ab2a-5345dcb5792d",
   "metadata": {},
   "source": [
    "### Convert the Z-scored data back to their pmol value using each proteins scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77efe066-273b-4097-9400-1fc4233bf8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_converted = []\n",
    "\n",
    "for [dna,label_type],dna_df in joined_preds.groupby(['DNA_name','label_type']):\n",
    "    temp = dna_df.copy()\n",
    "    if label_type == 'label':\n",
    "        temp['original_value'] = temp['pmol']\n",
    "        temp['original_label'] = scaler_dict[dna].transform(np.array(temp[['original_value']]))\n",
    "        temp['converted_pred'] = scaler_dict[dna].inverse_transform(np.array(temp[['pred']]))\n",
    "    elif label_type == 'label_sub':\n",
    "        temp['original_value'] = temp['pmol_sub']\n",
    "        temp['original_label'] = scaler_dict_sub[dna].transform(np.array(temp[['original_value']]))\n",
    "        temp['converted_pred'] = scaler_dict_sub[dna].inverse_transform(np.array(temp[['pred']]))\n",
    "    else:\n",
    "        print('Unknown label type:',label_type)\n",
    "        continue\n",
    "    test_converted.append(temp)\n",
    "    \n",
    "test_converted = pd.concat(test_converted).reset_index(drop=True)\n",
    "test_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ec88c-6616-4b3c-8190-651ba26b591a",
   "metadata": {},
   "source": [
    "### Evaluate model performance\n",
    "* Looks at each ensemble separately to compare their performance\n",
    "* Calculates R2 value from a linear regression based on:\n",
    "    * each model prediction on each replicate reaction\n",
    "    * the ensemble prediction and mean of replicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d53be-f131-43be-88c5-10567336fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['DNA_name','Mg', 'SecYE', 'K', 'PEG','lipid']\n",
    "\n",
    "obs_name = 'original_label'\n",
    "pred_name = 'pred'\n",
    "\n",
    "for ensemble,ensemble_df in test_converted[test_converted['ensemble'] == 'dna_encoded'].groupby(['ensemble','label_type']):\n",
    "    mae_train = median_absolute_error(ensemble_df[obs_name], ensemble_df[pred_name])\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(ensemble_df[pred_name], ensemble_df[obs_name])\n",
    "    \n",
    "    t = ensemble_df.groupby(group_cols)[[obs_name,pred_name]].agg(np.mean)\n",
    "    slope_mean, intercept_mean, r_value_mean, p_value_mean, std_err_mean = scipy.stats.linregress(t[pred_name], t[obs_name])\n",
    "    print(f'R_value for all:{r_value}')\n",
    "    scores = {\n",
    "        \"MAE on data set\": f\"{mae_train:.2f}\",\n",
    "        \"R2 of fit\": f\"{r_value_mean:.2f}\",\n",
    "    }\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=[6*cm,6*cm])\n",
    "    display = PredictionErrorDisplay.from_predictions(\n",
    "        ensemble_df[obs_name], ensemble_df[pred_name], kind=\"actual_vs_predicted\", ax=ax, scatter_kwargs={\"alpha\": 0.5,'s':5}\n",
    "    )\n",
    "    \n",
    "    sns.scatterplot(data=t.sample(300),x=pred_name,y=obs_name,color='black',alpha=0.5,s=10)\n",
    "    \n",
    "    for name, score in scores.items():\n",
    "        ax.plot([], [], \" \", label=f\"{name}: {score}\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    plt.xticks([-2,0,2,4])\n",
    "    plt.yticks([-2,0,2,4])\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('Predicted Z score')\n",
    "    plt.ylabel('Observed Z score')\n",
    "\n",
    "    plt.savefig(f'{fig_folder}/Fig3B-pred_vs_actual-Prot_ids.svg',format='svg',dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "ensemble_df[['ensemble', 'model_id', 'DNA_name', 'rxn_id', 'lipid', 'Mg', 'SecYE',\n",
    "       'K', 'PEG', 'pmol', 'pmol_sub','pred','original_value', 'original_label', 'converted_pred']].set_index('ensemble').to_excel(f'{data_folder}/Fig3B-prot_id_predictions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53757976-e9c0-4146-9a78-570faa34ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "group_cols = ['DNA_name','Mg', 'SecYE', 'K', 'PEG','lipid']\n",
    "\n",
    "obs_name = 'original_label'\n",
    "pred_name = 'pred'\n",
    "\n",
    "for ensemble,ensemble_df in test_converted[test_converted['ensemble'] == 'no_prot_features'].groupby(['ensemble','label_type']):\n",
    "    mae_train = median_absolute_error(ensemble_df[obs_name], ensemble_df[pred_name])\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(ensemble_df[pred_name], ensemble_df[obs_name])\n",
    "    \n",
    "    t = ensemble_df.groupby(group_cols)[[obs_name,pred_name]].agg(np.mean)\n",
    "    slope_mean, intercept_mean, r_value_mean, p_value_mean, std_err_mean = scipy.stats.linregress(t[pred_name], t[obs_name])\n",
    "    \n",
    "    scores = {\n",
    "        \"MAE on data set\": f\"{mae_train:.2f}\",\n",
    "        \"R2 of fit\": f\"{r_value_mean:.2f}\",\n",
    "    }\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=[9*cm,9*cm])\n",
    "    display = PredictionErrorDisplay.from_predictions(\n",
    "        ensemble_df[obs_name], ensemble_df[pred_name], kind=\"actual_vs_predicted\", ax=ax, scatter_kwargs={\"alpha\": 0.5,'s':20}\n",
    "    )\n",
    "    \n",
    "    sns.scatterplot(data=t.sample(300),x=pred_name,y=obs_name,color='black',alpha=0.5,s=30)\n",
    "    \n",
    "    for name, score in scores.items():\n",
    "        ax.plot([], [], \" \", label=f\"{name}: {score}\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    plt.xticks([-2,0,2,4])\n",
    "    plt.yticks([-2,0,2,4])\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('Predicted Z score')\n",
    "    plt.ylabel('Observed Z score')\n",
    "\n",
    "    plt.savefig(f'{fig_folder}/Supp_fig-pred_vs_actual-rxn_features.svg',format='svg',dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "ensemble_df[['ensemble', 'model_id', 'DNA_name', 'rxn_id', 'lipid', 'Mg', 'SecYE',\n",
    "       'K', 'PEG', 'pmol', 'pmol_sub','pred','original_value', 'original_label', 'converted_pred']].set_index('ensemble').to_excel(f'{data_folder}/Supp_fig-rxn_feature_predictions.xlsx')\n",
    "plt.rcParams['font.size'] = 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b7c891-c121-4fc8-be78-114a3f4881ec",
   "metadata": {},
   "source": [
    "### Investigate the ensemble performance on individual proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791bc228-889e-4012-9b8a-5f437bcc2f91",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_cols = ['DNA_name','Mg', 'SecYE', 'K', 'PEG','lipid']\n",
    "\n",
    "obs_name = 'original_label'\n",
    "pred_name = 'pred'\n",
    "\n",
    "all_r_vals = []\n",
    "\n",
    "temp = test_converted[test_converted['ensemble'] == 'dna_encoded']\n",
    "for dna,dna_df in temp.groupby('DNA_name'):\n",
    "    mae_train = median_absolute_error(dna_df[obs_name], dna_df[pred_name])\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(dna_df[pred_name], dna_df[obs_name])\n",
    "    \n",
    "    t = dna_df.groupby(group_cols)[[obs_name,pred_name]].agg(np.mean)\n",
    "    slope_mean, intercept_mean, r_value_mean, p_value_mean, std_err_mean = scipy.stats.linregress(t[pred_name], t[obs_name])\n",
    "    \n",
    "    def abline(slope, intercept,ax,color='red'):\n",
    "        \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "        axes = plt.gca()\n",
    "        x_vals = np.array(axes.get_xlim())\n",
    "        y_vals = intercept + slope * x_vals\n",
    "        ax.plot(x_vals, y_vals, '--',color=color)\n",
    "\n",
    "    scores = {\n",
    "        \"MAE on data set\": f\"{mae_train:.2f} pmol\",\n",
    "        \"R2 of fit\": f\"{r_value:.2f}\",\n",
    "        \"R2 of mean fit\": f\"{r_value_mean:.2f}\",\n",
    "    }\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(5, 5))\n",
    "    display = PredictionErrorDisplay.from_predictions(\n",
    "        dna_df[obs_name], dna_df[pred_name], kind=\"actual_vs_predicted\", ax=ax, scatter_kwargs={\"alpha\": 0.5}\n",
    "    )\n",
    "    ax.set_title(f\"{dna}: Predicted versus observed yields\")\n",
    "    for name, score in scores.items():\n",
    "        ax.plot([], [], \" \", label=f\"{name}: {score}\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    # plt.plot([-5,25],[-5,25],color='black',ls='--')\n",
    "    plt.axvline(0,color='grey')\n",
    "    plt.axhline(0,color='grey')\n",
    "    abline(slope, intercept,ax)\n",
    "    upper = round(np.max(dna_df[obs_name])*1.25)+1\n",
    "    lower = round(np.min(dna_df[obs_name])*0.75)-1\n",
    "    # upper = 10\n",
    "    # lower = 0\n",
    "    \n",
    "    sns.scatterplot(data=t,x=pred_name,y=obs_name,color='black')\n",
    "    abline(slope_mean, intercept_mean,ax,color='grey')\n",
    "    plt.xlim([lower,upper])\n",
    "    plt.ylim([lower,upper])\n",
    "    plt.axvline(1)\n",
    "    plt.axhline(1)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    all_r_vals.append([dna,r_value,r_value_mean])\n",
    "    \n",
    "# all_r_vals = pd.concat(all_r_vals)\n",
    "# all_r_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a62fff-4394-40f2-94c9-7c668779b088",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compare the active learning reactions to the screening data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f5b3f5-099b-4443-83f7-b44538e5983e",
   "metadata": {},
   "source": [
    "## Prepare data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164940d7-733e-406c-8202-3b92b12a991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../General_data/screen_active_data.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef090156-b3d8-4fe7-a631-aa650e01e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = []\n",
    "\n",
    "for rxn_id,rxn_df in data.groupby('rxn_id'):\n",
    "    lipo = rxn_df[rxn_df['Liposome_conc'] != 0].copy()\n",
    "    nolipo = rxn_df[rxn_df['Liposome_conc'] == 0].copy()\n",
    "    nolipo_mean = np.mean(nolipo['pmol'])\n",
    "    if len(nolipo) == 0:\n",
    "        print(rxn_id)\n",
    "        continue\n",
    "    lipo['pmol_sub'] = lipo['pmol'] - nolipo_mean\n",
    "    nolipo['pmol_sub'] = nolipo['pmol'] - nolipo_mean\n",
    "    \n",
    "    sub_df.append(lipo)\n",
    "    sub_df.append(nolipo)\n",
    "    \n",
    "sub_df = pd.concat(sub_df)\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7562f183-435e-429a-80e7-4ec02aef9fd1",
   "metadata": {},
   "source": [
    "## Calculate the difference in active learning and screening reaction populations for each protein\n",
    "* Calculates the significance of the change to active learning using a t-test\n",
    "* Defines significance as a p-value less than 0.05\n",
    "* Identifies 21 proteins as significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf9e0bd-c1d7-4813-8e0e-1e731c0050b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lipo_all = sub_df[sub_df['Liposome_name'] != 'no_lipo'].copy()\n",
    "means = lipo_all.groupby('rxn_id')[['pmol','pmol_sub']].agg(np.mean)\n",
    "lipo_all = means.join(lipo_all[['label','rxn_id','DNA_name','Mg','K','PEG','SecYE','Liposome_name','pmol','pmol_sub']].set_index('rxn_id'),lsuffix='_mean').drop_duplicates()\n",
    "\n",
    "p_vals = []\n",
    "for dna,dna_df in lipo_all.groupby('DNA_name'):\n",
    "    a = dna_df[dna_df['label'] == 'active']\n",
    "    s = dna_df[dna_df['label'] == 'screen']\n",
    "    \n",
    "    pval = -np.log(ttest_ind(a['pmol_sub'],s['pmol_sub'])[1])\n",
    "\n",
    "    a_mean = a['pmol_sub'].mean()\n",
    "    s_mean = s['pmol_sub'].mean()\n",
    "    \n",
    "    diff = a_mean - s_mean\n",
    "\n",
    "    p_vals.append([dna,diff,pval])\n",
    "    \n",
    "p_vals = pd.DataFrame(p_vals,columns=['DNA_name','diff','pval'])\n",
    "p_vals['pval'] = p_vals['pval'].clip(0,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fccaf28-d983-4790-a65d-3460e808118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_thresh = 0.1\n",
    "y_thresh = -np.log(0.05)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=[6*cm,6*cm])\n",
    "\n",
    "sns.scatterplot(data=p_vals,x='diff',y='pval',alpha=0.4,color='black')\n",
    "sns.scatterplot(data=p_vals[(p_vals['diff'] > x_thresh) & (p_vals['pval'] > y_thresh)],x='diff',y='pval',alpha=0.4,color='blue')\n",
    "\n",
    "plt.axvline(x_thresh,color='black',ls='--')\n",
    "plt.axhline(y_thresh,color='black',ls='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47cecd-1731-4d09-9c97-5aeb1fbf3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=p_vals,x='pval',bins=50)\n",
    "plt.axvline(-np.log(0.05),color='k',ls='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302a373-a6d1-4e5c-8bd5-0f070954fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant = p_vals[p_vals['pval'] > -np.log(0.05)]['DNA_name'].tolist()\n",
    "significant = [x for x in significant if x != 'Cx43']\n",
    "len(significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e0b54-6079-4d83-b53a-363361e719ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "high = ['AqpZ','MscL','Mito']\n",
    "\n",
    "def assign_group(dna):\n",
    "    if dna in high:\n",
    "        return 'high'\n",
    "    elif dna in significant:\n",
    "        return 'significant'\n",
    "    else:\n",
    "        return 'insignificant'\n",
    "    \n",
    "lipo_all['group'] = lipo_all['DNA_name'].apply(assign_group)\n",
    "lipo_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618bccff-0904-4466-af55-b0224ccc3881",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fig 3C - Plot the different reactions for both the screening and active learning reactions\n",
    "* The average of each reaction composition is plotted instead of all replicates to make it possible to include all reactions conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b8a3c7-c9d6-43c3-a850-2037d163a0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lipo_means = lipo_all.reset_index().drop_duplicates(subset='rxn_id').drop(columns=['pmol','pmol_sub']).rename(columns={'pmol_mean':'pmol','pmol_sub_mean':'pmol_sub'})\n",
    "\n",
    "medians = lipo_means.groupby(['DNA_name','label'])[['pmol_sub']].agg(np.median)\n",
    "\n",
    "medians = medians.unstack()\n",
    "medians.columns = ['active','screen']\n",
    "medians['diff'] = medians['active'] - medians['screen']\n",
    "medians['percent'] = (medians['active'] - medians['screen']) / medians['screen']\n",
    "medians['label'] = 'Median'\n",
    "\n",
    "means = lipo_means.groupby(['DNA_name','label'])[['pmol_sub']].agg(np.mean)\n",
    "means = means.unstack()\n",
    "means.columns = ['active','screen']\n",
    "means['diff'] = means['active'] - means['screen']\n",
    "means['percent'] = (means['active'] - means['screen']) / means['screen']\n",
    "means['label'] = 'Mean'\n",
    "\n",
    "maxs = lipo_means.groupby(['DNA_name','label'])[['pmol_sub']].agg(np.max)\n",
    "maxs = maxs.unstack()\n",
    "maxs.columns = ['active','screen']\n",
    "maxs['diff'] = maxs['active'] - maxs['screen']\n",
    "maxs['percent'] = (maxs['active'] - maxs['screen']) / maxs['screen']\n",
    "maxs['label'] = 'Max'\n",
    "\n",
    "mins = lipo_means.groupby(['DNA_name','label'])[['pmol_sub']].agg(np.min)\n",
    "mins = mins.unstack()\n",
    "mins.columns = ['active','screen']\n",
    "mins['diff'] = mins['active'] - mins['screen']\n",
    "mins['percent'] = (mins['active'] - mins['screen']) / mins['screen']\n",
    "mins['label'] = 'Min'\n",
    "\n",
    "stdevs = lipo_means.groupby(['DNA_name','label'])[['pmol_sub']].agg(np.std)\n",
    "stdevs = stdevs.unstack()\n",
    "stdevs.columns = ['active','screen']\n",
    "stdevs['diff'] = stdevs['active'] - stdevs['screen']\n",
    "stdevs['percent'] = (stdevs['active'] - stdevs['screen']) / stdevs['screen']\n",
    "stdevs['label'] = 'Stdev'\n",
    "\n",
    "calcs = pd.concat([medians,means,maxs,mins]).reset_index()\n",
    "calcs['percent'] = calcs['percent'].clip(-2,2)\n",
    "\n",
    "meta = pd.read_excel('../General_data/protein_metadata.xlsx')\n",
    "calcs = calcs.set_index('DNA_name').join(meta.set_index('DNA_name')).reset_index()\n",
    "\n",
    "high = ['AqpZ','MscL','Mito']\n",
    "fig,ax = plt.subplots(figsize=[6*cm,6*cm])\n",
    "\n",
    "current = calcs[(~calcs['DNA_name'].isin(high))]\n",
    "\n",
    "sns.swarmplot(data=current,x='label',y='diff',ax=ax,s=3,palette='viridis')\n",
    "plt.axhline(0,c='k',ls='--',lw=0.75)\n",
    "plt.xlabel('Statistic')\n",
    "plt.ylabel('Difference (pmol)')\n",
    "# plt.savefig(f'{fig_folder}/all_stats_comparison.svg',format='svg',dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e785f59-8886-4f19-b208-81aa3effcfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = lipo_means[lipo_means['group'] == 'high'].groupby(['DNA_name','label'])[['pmol_sub']].agg(np.median).reset_index()\n",
    "t = t[t['label'] == 'active'].sort_values('pmol_sub')\n",
    "high_dna_order = t['DNA_name'].tolist()\n",
    "\n",
    "PROPS = {\n",
    "    'boxprops':{'edgecolor':'black','facecolor':'#e0e0e0'},\n",
    "    'medianprops':{'color':'black'},\n",
    "    'whiskerprops':{'color':'black'},\n",
    "    'capprops':{'color':'black'},\n",
    "    'flierprops':{'color':'none'}\n",
    "}\n",
    "\n",
    "current = lipo_means[lipo_means['DNA_name'].isin(high)]\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize=[3*cm,6*cm])\n",
    "\n",
    "sns.stripplot(data=current,x='DNA_name',y='pmol_sub',hue='label',hue_order=['screen','active'],ax=ax,palette='Set1',order=high_dna_order[:],\\\n",
    "              dodge=True,edgecolor=\"black\",linewidth=0.3,alpha=0.8,s=2,jitter=0.2)\n",
    "\n",
    "sns.boxplot(data=current,x='DNA_name',y='pmol_sub',hue='label',ax=ax,\\\n",
    "            hue_order=['screen','active'],palette='Set1',order=high_dna_order[:],saturation=1,linewidth=0.75,**PROPS,fliersize=2,notch=False)\n",
    "\n",
    "plt.axhline(0,c='k',ls='--',lw=0.5)\n",
    "ax.get_legend().remove()\n",
    "plt.xticks(rotation=45, ha='center')\n",
    "\n",
    "plt.savefig(f'{fig_folder}/Fig3C-active_boxplots_high_w_heat.svg',format='svg',dpi=300)\n",
    "\n",
    "plt.show()\n",
    "current.to_excel(f'{data_folder}/Fig3C-high_averages.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c646cb0d-2316-438e-bc4a-f07aa7c85603",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = calcs[['DNA_name','label','diff']].set_index(['DNA_name','label']).unstack()\n",
    "comps.columns = comps.columns.droplevel()\n",
    "comps = comps.T\n",
    "\n",
    "comps = comps[high_dna_order]\n",
    "fig,ax = plt.subplots(figsize=[3*cm,3*cm])\n",
    "\n",
    "ax = sns.heatmap(comps,cmap='coolwarm_r',ax=ax,center=0,vmin=-1,vmax=1,linewidth=.5)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0, ha='right')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.savefig(f'{fig_folder}/Fig3C-changes-high-heatmap.svg',format='svg',dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "comps.to_excel(f'{data_folder}/Fig3C-High_active_heatmap.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056cba1d-6184-45fd-ad39-b8d3b77e5bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = lipo_means[lipo_means['group'] == 'significant'].groupby(['DNA_name','label'])[['pmol_sub']].agg(np.median).reset_index()\n",
    "\n",
    "t = t[t['label'] == 'active'].sort_values('pmol_sub')\n",
    "sig_dna_order = t['DNA_name'].tolist()\n",
    "\n",
    "fig,ax = plt.subplots(figsize=[16*cm,6*cm])\n",
    "PROPS = {\n",
    "    'boxprops':{'edgecolor':'black','facecolor':'#e0e0e0'},\n",
    "    'medianprops':{'color':'black'},\n",
    "    'whiskerprops':{'color':'black'},\n",
    "    'capprops':{'color':'black'},\n",
    "    'flierprops':{'color':'none'}\n",
    "}\n",
    "current = lipo_means[lipo_means['group'] == 'significant']\n",
    "\n",
    "sns.stripplot(data=current,x='DNA_name',y='pmol_sub',hue='label',hue_order=['screen','active'],ax=ax,palette='Set1',order=sig_dna_order[:],\\\n",
    "              dodge=True,edgecolor=\"black\",linewidth=0.3,alpha=0.8,s=2,jitter=0.2)\n",
    "\n",
    "sns.boxplot(data=current,x='DNA_name',y='pmol_sub',hue='label',ax=ax,\\\n",
    "            hue_order=['screen','active'],palette='Set1',order=sig_dna_order[:],saturation=1,linewidth=0.75,**PROPS,fliersize=2,notch=False)\n",
    "\n",
    "plt.axhline(0,c='k',ls='--',lw=0.5)\n",
    "ax.get_legend().remove()\n",
    "plt.xticks(rotation=45, ha='center')\n",
    "plt.xlabel('')\n",
    "\n",
    "plt.savefig(f'{fig_folder}/Fig_3C-active_boxplots_sign-w_heat.svg',format='svg',dpi=300)\n",
    "plt.show()\n",
    "current.to_excel(f'{data_folder}/Fig3C-significant_averages.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0313df4d-dd37-4b7b-a075-350ea73ceff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = calcs[['DNA_name','label','diff']].set_index(['DNA_name','label']).unstack()\n",
    "comps.columns = comps.columns.droplevel()\n",
    "comps = comps.T\n",
    "comps = comps[sig_dna_order]\n",
    "fig,ax = plt.subplots(figsize=[18*cm,4*cm])\n",
    "\n",
    "ax = sns.heatmap(comps,cmap='coolwarm_r',ax=ax,center=0,vmin=-1,vmax=1,linewidth=.5)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0, ha='right')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.savefig(f'{fig_folder}/Fig3C-changes-heatmap.svg',format='svg',dpi=300)\n",
    "\n",
    "plt.show()\n",
    "comps.to_excel(f'{data_folder}/Fig3C-Significant_active_heatmap.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286cc132-9bb8-4b00-8ce7-1a5760075629",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = lipo_means[lipo_means['group'] == 'insignificant'].groupby(['DNA_name','label'])[['pmol_sub']].agg(np.median).reset_index()\n",
    "t = t[t['label'] == 'active'].sort_values('pmol_sub')\n",
    "insig_dna_order = t['DNA_name'].tolist()\n",
    "\n",
    "fig,ax = plt.subplots(figsize=[8*cm,6*cm])\n",
    "\n",
    "current = lipo_means[lipo_means['group'] == 'insignificant']\n",
    "\n",
    "sns.stripplot(data=current,x='DNA_name',y='pmol_sub',hue='label',hue_order=['screen','active'],ax=ax,palette='Set1',order=insig_dna_order[:],\\\n",
    "              dodge=True,edgecolor=\"black\",linewidth=0.3,alpha=0.8,s=2,jitter=0.2)\n",
    "\n",
    "sns.boxplot(data=current,x='DNA_name',y='pmol_sub',hue='label',ax=ax,\\\n",
    "            hue_order=['screen','active'],palette='Set1',order=insig_dna_order[:],saturation=1,linewidth=0.75,**PROPS,fliersize=2,notch=False)\n",
    "\n",
    "plt.axhline(0,c='k',ls='--',lw=0.5)\n",
    "ax.get_legend().remove()\n",
    "plt.xticks(rotation=45, ha='center')\n",
    "\n",
    "plt.axhline(0,c='k',ls='--')\n",
    "plt.savefig(f'{fig_folder}/Supp_fig-active_boxplots_insignificant.svg',format='svg',dpi=300)\n",
    "\n",
    "plt.show()\n",
    "current.to_excel(f'{data_folder}/Supp_Fig-Insignificant_averages.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef0ccc-588a-41e4-855f-05793bfacd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = calcs[['DNA_name','label','diff']].set_index(['DNA_name','label']).unstack()\n",
    "comps.columns = comps.columns.droplevel()\n",
    "comps = comps.T\n",
    "comps = comps[insig_dna_order]\n",
    "fig,ax = plt.subplots(figsize=[6*cm,3*cm])\n",
    "\n",
    "ax = sns.heatmap(comps,cmap='coolwarm_r',ax=ax,center=0,vmin=-1,vmax=1,linewidth=.5)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0, ha='right')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.savefig(f'{fig_folder}/Supp_fig-changes-insign-heatmap.svg',format='svg',dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "comps.to_excel(f'{data_folder}/Supp_Fig-insignificant_active_heatmap.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e61c897-af5e-4c63-bd67-ce8c13cbc876",
   "metadata": {},
   "source": [
    "### Fig 3D - Calculate trajectories between the standard and best performing reaction composition\n",
    "* Extract the reaction ids for the standard reactions and the top performing for each protein\n",
    "* Normalize the reaction component concentrations and the resulting yields\n",
    "    * A min-max scaler is used on the yield so that it always sets the highest value to one and then the standard reaction is some fraction of it\n",
    "* Calculate the Euclidean distance between each reaction component concentration and the different yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a845d1-1922-4a5d-9679-b65f39066089",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = {\n",
    "    'Mg':[12,14],\n",
    "    'K':[85],\n",
    "    'PEG':[2],\n",
    "    'Liposome_name':['DOPC'],\n",
    "    'SecYE':[0],\n",
    "}\n",
    "\n",
    "standard_df = lipo_means.copy()\n",
    "for key in standard.keys():\n",
    "    standard_df = standard_df[standard_df[key].isin(standard[key])]\n",
    "dup = standard_df[(standard_df['DNA_name'].isin(['AqpZ','Glut','CD47','MscL']))]\n",
    "non_dup = standard_df[(~standard_df['DNA_name'].isin(['AqpZ','Glut','CD47','MscL']))]\n",
    "dup = dup[dup['Mg'] == 14].copy()\n",
    "standard_df = pd.concat([non_dup,dup])\n",
    "standard_df = standard_df[['rxn_id','DNA_name','Mg','K','PEG','Liposome_name','SecYE','pmol_sub']]\n",
    "\n",
    "temp_df = []\n",
    "temp_array = []\n",
    "for dna,dna_df in standard_df.groupby('DNA_name'):\n",
    "    if len(dna_df) == 1:\n",
    "        temp_df.append(dna_df)\n",
    "    else:\n",
    "        mean = np.mean(dna_df['pmol_sub'])\n",
    "        t = dna_df.copy()\n",
    "        t['pmol_sub'] = mean\n",
    "        t = t.iloc[0]\n",
    "        temp_array.append(t)\n",
    "standard_df = pd.concat(temp_df)\n",
    "temp_array = pd.DataFrame(temp_array)\n",
    "\n",
    "standard_df = pd.concat([standard_df,temp_array])\n",
    "len(standard_df['DNA_name'].unique())\n",
    "standard_ids = standard_df[['rxn_id','DNA_name']]\n",
    "standard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66d747-44d1-4aac-9ca3-c1f8cf4b0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = []\n",
    "\n",
    "for dna,dna_df in lipo_means.groupby('DNA_name'):\n",
    "    best.append(dna_df.sort_values('pmol_sub',ascending=False).iloc[0])\n",
    "best = pd.DataFrame(best)\n",
    "best = best[['rxn_id','DNA_name','Mg','K','PEG','Liposome_name','SecYE','pmol_sub']]\n",
    "best_ids = best[['rxn_id','DNA_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dfa5b5-6bdf-493f-8c71-a899bb157590",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9228ce-6a3e-4183-b5cb-8b5405dca4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = lipo_means.copy()\n",
    "\n",
    "lipo_dict = {'DOPC':18,'DPPC':16,'DMPC':14,'no_lipo':0}\n",
    "all_features['lipid'] = all_features['Liposome_name'].apply(lambda x: lipo_dict[x])\n",
    "all_features\n",
    "\n",
    "data_bounded = all_features[['Mg', 'SecYE', 'K', 'PEG','lipid']]\n",
    "X_bounded = np.array(data_bounded)\n",
    "MMscalerX = MinMaxScaler()\n",
    "\n",
    "X_bounded = MMscalerX.fit_transform(X_bounded)\n",
    "data_bounded = pd.DataFrame(X_bounded,columns=data_bounded.columns)\n",
    "data_bounded['rxn_id'] = all_features['rxn_id'].tolist()\n",
    "data_bounded = data_bounded.set_index('rxn_id')\n",
    "data_bounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f201c-377d-4a8d-b8b9-9b30fd27d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'pmol_sub'\n",
    "\n",
    "transformed = []\n",
    "scaler_dict = {}\n",
    "\n",
    "all_features = lipo_means.copy()\n",
    "all_features\n",
    "for dna, dna_df in all_features.groupby('DNA_name'):\n",
    "    temp = dna_df.copy()\n",
    "    y_scaled = np.array(temp[[y_col]])\n",
    "    scalerY = MinMaxScaler()\n",
    "    y_scaled = scalerY.fit_transform(y_scaled)\n",
    "    temp['pmol_sub'] = y_scaled\n",
    "    transformed.append(temp)\n",
    "    scaler_dict.update({dna:scalerY})\n",
    "transformed = pd.concat(transformed)\n",
    "transformed = transformed[['rxn_id',y_col]].set_index('rxn_id')\n",
    "transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e2675-0fcd-4ed7-9ee3-3ab3387228c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = data_bounded.join(transformed).reset_index()\n",
    "norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95378194-317a-44ea-a187-5715c4e4ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_trajectory(row):\n",
    "    return np.sqrt(((row['value_final'] - row['value_init'])**2) + ((row['pmol_sub_final'] - row['pmol_sub_init'])**2))\n",
    "\n",
    "\n",
    "final = best_ids.set_index('rxn_id').join(norm_data.set_index('rxn_id')).reset_index().drop(columns=['rxn_id'])\n",
    "final = final.set_index(['DNA_name','pmol_sub']).stack().reset_index().rename(columns={'level_2':'variable',0:'value'})\n",
    "final\n",
    "initial = standard_ids.set_index('rxn_id').join(norm_data.set_index('rxn_id')).reset_index().drop(columns=['rxn_id'])\n",
    "initial = initial.set_index(['DNA_name','pmol_sub']).stack().reset_index().rename(columns={'level_2':'variable',0:'value'})\n",
    "\n",
    "comparison = initial.set_index(['DNA_name','variable']).join(final.set_index(['DNA_name','variable']),lsuffix='_init',rsuffix='_final').reset_index()\n",
    "comparison['distance'] = comparison.apply(calc_trajectory,axis=1)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb62200-e757-41ec-a00d-d444ce4eda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_comp = comparison[['DNA_name','variable','distance']].set_index(['DNA_name','variable']).unstack().T.reset_index()\n",
    "heat_comp = heat_comp.drop(columns=['level_0']).set_index('variable')\n",
    "\n",
    "heat_comp = heat_comp[sig_dna_order]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=[18*cm,3*cm])\n",
    "ax = sns.heatmap(heat_comp,cmap='viridis',ax=ax,linewidth=.5,vmin=0,vmax=1.33)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0, ha='right')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.savefig(f'{fig_folder}/Fig3D-trajectory_heatmap.svg',format='svg',dpi=300)\n",
    "\n",
    "plt.show()\n",
    "heat_comp.to_excel(f'{data_folder}/Fig3D-significant_trajectory.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72160111-d0f4-474e-9837-fa3f16444efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_comp = comparison[['DNA_name','variable','distance']].set_index(['DNA_name','variable']).unstack().T.reset_index()\n",
    "heat_comp = heat_comp.drop(columns=['level_0']).set_index('variable')\n",
    "\n",
    "heat_comp = heat_comp[high_dna_order]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=[3*cm,3*cm])\n",
    "ax = sns.heatmap(heat_comp,cmap='viridis',ax=ax,linewidth=.5,vmin=0,vmax=1.33)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0, ha='right')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.savefig(f'{fig_folder}/Fig3D-trajectory_heatmap_high.svg',format='svg',dpi=300)\n",
    "\n",
    "plt.show()\n",
    "heat_comp.to_excel(f'{data_folder}/Fig3D-high_trajectory.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02083ad-9c00-49ea-b0db-37c1320810e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_comp = comparison[['DNA_name','variable','distance']].set_index(['DNA_name','variable']).unstack().T.reset_index()\n",
    "heat_comp = heat_comp.drop(columns=['level_0']).set_index('variable')\n",
    "\n",
    "heat_comp = heat_comp[insig_dna_order]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=[6*cm,3*cm])\n",
    "ax = sns.heatmap(heat_comp,cmap='viridis',ax=ax,linewidth=.5,vmin=0,vmax=1.33)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0, ha='right')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.savefig(f'{fig_folder}/Supp_fig-trajectory_heatmap_insig.svg',format='svg',dpi=300)\n",
    "\n",
    "plt.show()\n",
    "heat_comp.to_excel(f'{data_folder}/Supp_Fig-insignificant_trajectory.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12026602-9aa1-4e55-8f0f-b47045992141",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=[3*cm,3*cm])\n",
    "\n",
    "t = comparison.copy()\n",
    "t = t[(t['DNA_name'] == 'Dia') & (t['variable'] == 'K')].iloc[0]\n",
    "pmol = [t['pmol_sub_init'],t['pmol_sub_final']]\n",
    "conc = [t['value_init'],t['value_final']]\n",
    "\n",
    "ax.plot(conc,pmol,color='grey')\n",
    "ax.scatter(conc,pmol,color='k')\n",
    "plt.xlim([-0.25,1.25])\n",
    "plt.ylim([-0.25,1.25])\n",
    "plt.savefig(f'{fig_folder}/Fig3D-trajectory_explanation.svg',format='svg',dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f916f5-e5ec-44fd-8a3b-3e69655dc219",
   "metadata": {},
   "source": [
    "### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7687cd-0968-4c1b-b265-9eb73f7f7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_comp = comparison[['DNA_name','variable','distance']].set_index(['DNA_name','variable']).unstack().T.reset_index()\n",
    "heat_comp = heat_comp.drop(columns=['level_0']).set_index('variable')\n",
    "\n",
    "heat_comp.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ffe2e9-aea0-4eb6-9604-315e4b1972cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(data=comparison[['DNA_name','variable','distance']],x='variable',y='distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6028faf-fc06-420c-bfa1-a7bc652dee1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a784306-54e4-49b6-8ccb-150c2744a3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
